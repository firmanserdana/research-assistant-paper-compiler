<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Biorobotics Research Monitor</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <style>
        .paper-card {
            margin-bottom: 1.5rem;
            transition: transform 0.2s;
        }

        .paper-card:hover {
            transform: translateY(-3px);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }

        .trl-badge {
            position: absolute;
            top: 10px;
            right: 10px;
        }

        .keyword-pill {
            margin-right: 0.3rem;
            margin-bottom: 0.3rem;
        }

        #filter-input {
            margin-bottom: 1.5rem;
        }

        .category-section {
            margin-top: 2rem;
            padding-top: 1rem;
            border-top: 1px solid #eee;
        }

        .paper-summary {
            font-size: 0.9rem;
            color: #555;
            margin-top: 0.8rem;
        }
    </style>
</head>

<body>
    <div class="container py-4">
        <header class="pb-3 mb-4 border-bottom">
            <div class="d-flex align-items-center justify-content-between">
                <h1>Biorobotics Literature Monitor</h1>
                <span class="badge bg-primary">Last updated: 2025-04-14 21:13</span>
            </div>
            <p class="lead text-muted">Recent advances in biomedical engineering and robotics</p>
        </header>
        <div class="row mb-4">
            <div class="col-md-12">
                <div class="alert alert-info">
                    <strong>1</strong> new papers have been added to the collection.
                    <span class="float-end">Total papers: <strong>39</strong></span>
                </div>
                <input type="text" id="filter-input" class="form-control"
                    placeholder="Filter papers by title, author, or keyword...">
            </div>
        </div>

        <!-- Debug information -->
        

        <!-- Display papers directly if categories aren't working -->
        <div class="category-section">
            <h2>All Papers</h2>
            <div class="row">
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">A direct spinal cordâ€“computer interface enables the control of the paralyzed hand through brain-derived muscle activity</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Daniela Souza Oliveira, Thomas Mehari Kinfe, Alessandro Del Vecchio
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates a non-invasive neural interface that allows individuals with complete cervical spinal cord injury to voluntarily control their paralyzed hand muscles by modulating spinal motor neuron activity[1][6]. The system decodes intended hand movements from high-density surface electromyography signals and maps them to a virtual hand, enabling proportional control of complex grasping motions despite years of paralysis[3][9]. This breakthrough has significant potential for restoring hand function in spinal cord injury patients through integration with assistive devices, representing an important advance for neuroprosthetics and biorobotics research.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">Spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">Electromyography</span>
                                
                                <span class="badge bg-secondary keyword-pill">Motor unit decomposition</span>
                                
                                <span class="badge bg-secondary keyword-pill">Brain-computer interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">Neuroprosthetics</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1093/brain/awad311" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1093/brain/awad311)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 6</span>
                            <h5 class="card-title">Neural control of finger movement via intracortical brain-machine interface</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Nason SR, Vaskov AK, Willsey MS, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates the first successful continuous decoding of precise finger movements from primary motor cortex activity in rhesus macaques using intracortical brain-machine interfaces[1][4]. The researchers developed a novel behavioral task paradigm and used a standard Kalman filter to reconstruct finger movements with high accuracy, enabling real-time brain control of a virtual hand[1][4]. This breakthrough represents a significant step towards developing more dexterous neural prosthetic devices, potentially allowing individuals with severe motor disabilities to regain fine motor control of fingers and hands[1][4].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">Intracortical brain-machine interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">Finger kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">Neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">Motor cortex</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1038/s41586-023-06094-5" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1038/s41586-023-06094-5)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">A flexible intracortical brain-computer interface for typing using attempted finger movements</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Willett FR, Avansino DT, Hochberg LR, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper presents a flexible intracortical brain-computer interface (BCI) for typing that decodes attempted finger movements, demonstrating high performance in both continuous "point-and-click" and discrete "keystroke" paradigms[1][4]. The system achieved typing speeds of 30-40 characters per minute with nearly 90% accuracy for point-and-click, and over 90% accuracy for 90 characters per minute in the keystroke paradigm[1][4]. This flexible BCI approach using finger movements could significantly advance assistive communication technologies for people with paralysis and inform future high-degree-of-freedom BCI designs[4].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">Brain-computer interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">Finger movements</span>
                                
                                <span class="badge bg-secondary keyword-pill">Neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">Typing</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1038/s41467-023-39723-8" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1038/s41467-023-39723-8)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Robust neural decoding for dexterous control of robotic hand prostheses</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Liu S, Liu M, Zhang D, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper presents a novel neural decoding approach that uses high-density electromyogram signals to predict finger-specific neural drive signals for continuous control of individual fingers in a robotic prosthetic hand[8]. The developed decoder demonstrated superior accuracy and robustness compared to conventional methods, enabling more dexterous and natural control of prosthetic hands[8]. This innovation has the potential to significantly improve the functionality and usability of upper limb prostheses for individuals with hand disabilities.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">Neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">Robotic hand</span>
                                
                                <span class="badge bg-secondary keyword-pill">Finger kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">Prosthetics</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1088/1741-2552/adc48e" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1088/1741-2552/adc48e)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 6</span>
                            <h5 class="card-title">Fusion of EEG and EMG signals for detecting pre-movement intentions in sitting and standing</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Not provided in the search results
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This study proposes a novel multimodal fusion method that combines EEG and EMG signals using functional connectivity to detect sitting and standing intentions before movement execution[1][5]. The method achieves high accuracy (94.33% in healthy subjects, 87.54% in SCI patients) in classifying pre-movement intentions, outperforming single-modality approaches and maintaining robustness under fatigue conditions[1]. This innovation has significant potential to improve the responsiveness and effectiveness of rehabilitation devices by enabling earlier and more accurate detection of motor intentions in both healthy individuals and those with spinal cord injuries[1][5].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">EEG-EMG fusion</span>
                                
                                <span class="badge bg-secondary keyword-pill">functional connectivity</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor intention detection</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">rehabilitation</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.3389/fnins.2025.1532099" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.3389/fnins.2025.1532099)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Sensing and decoding the neural drive to paralyzed muscles during attempted movements</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Not provided in the search results
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This study demonstrates the use of a wearable electrode array to record and decode motor unit firing rates from paralyzed muscles in a person with motor complete tetraplegia. Despite the absence of visible motion, the researchers were able to accurately classify attempted single-digit movements using myoelectric signals and motor unit firing rates, with classification accuracies over 75%[1][8]. This noninvasive approach for interfacing with spinal motor neurons below the injury level has significant potential for enabling control of assistive devices and tracking neuromotor recovery in individuals with spinal cord injuries[2][8].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">EMG</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor unit</span>
                                
                                <span class="badge bg-secondary keyword-pill">decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">neuroprosthetics</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1152/jn.00312.2021" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1152/jn.00312.2021)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Reclaiming Hand Functions after Complete Spinal Cord Injury with Minimally Invasive Brain-Computer Interface</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Not provided in the search results
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> I apologize, but I do not have enough information from the search results to provide a technical summary of the specific paper you mentioned. The search results do not contain details about a paper with that exact title, authors, or DOI. Without access to the actual paper or more specific information about its contents, I cannot accurately summarize its key innovation or potential impact for biorobotics research. If you have additional details about this paper, I'd be happy to try summarizing based on that information.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">Brain-computer interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand function</span>
                                
                                <span class="badge bg-secondary keyword-pill">rehabilitation</span>
                                
                                <span class="badge bg-secondary keyword-pill">epidural electrodes</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1101/2024.09.05.24313041" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1101/2024.09.05.24313041)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">High-Density Electromyography Based Control of Robotic Devices: On the Execution of Dexterous Manipulation Tasks</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Anany Dwivedi, Jaime Lara, Leo K. Cheng, Niranchan Paskaranandavadivel, Minas Liarokapis
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper presents a novel learning scheme that uses high-density electromyography (HD-EMG) sensors to decode dexterous in-hand manipulation motions based on myoelectric activations of forearm and hand muscles. The researchers developed custom HD-EMG electrode arrays to extract 89 EMG signals and used random forests to decode object motions, achieving accuracies up to 88% for motion-specific models. This approach enables intuitive control of robotic hands for complex manipulation tasks, potentially advancing human-robot interfaces and prosthetic control.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">High-density EMG</span>
                                
                                <span class="badge bg-secondary keyword-pill">dexterous manipulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">robotic control</span>
                                
                                <span class="badge bg-secondary keyword-pill">machine learning</span>
                                
                                <span class="badge bg-secondary keyword-pill">random forests</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/Not provided in the search results" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: Not provided in the search results)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Decoding and geometry of ten finger movements in human posterior parietal and motor cortex</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Guan C, Aflalo T, Zhang CY, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This study demonstrated high-accuracy decoding of individual finger movements from neural signals in the posterior parietal cortex (PPC) and motor cortex (MC) of tetraplegic participants, achieving up to 92% online accuracy for brain-machine interface control of contralateral fingers[1][2]. The researchers found a factorized neural code linking corresponding finger movements of both hands, and showed that PPC and MC signals can be used to control individual prosthetic fingers[3][4]. This work advances the development of dexterous neuroprosthetics for restoring hand function in people with tetraplegia.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">Brain-machine interfaces</span>
                                
                                <span class="badge bg-secondary keyword-pill">Neuroprosthetics</span>
                                
                                <span class="badge bg-secondary keyword-pill">Posterior parietal cortex</span>
                                
                                <span class="badge bg-secondary keyword-pill">Motor cortex</span>
                                
                                <span class="badge bg-secondary keyword-pill">Finger movements</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1088/1741-2552/acbf9a" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1088/1741-2552/acbf9a)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Decoding Joint-Level Hand Movements With Intracortical Neural Signals in a Human Brain-Computer Interface</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Hu X, Zhang J, Jiang N, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This study investigates the decoding of fine hand movements at the single-joint level using intracortical neural signals recorded from the motor cortex in a human brain-computer interface[6]. The research demonstrates the feasibility of decoding individual joint movements from neural activity, which could potentially enable more precise and natural control of prosthetic hands or robotic devices[6]. This advancement in neural decoding techniques may significantly impact biorobotics research by allowing for more dexterous and intuitive control of artificial limbs or assistive devices.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">Brain-computer interfaces</span>
                                
                                <span class="badge bg-secondary keyword-pill">Motor cortex</span>
                                
                                <span class="badge bg-secondary keyword-pill">Hand kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">Neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">Intracortical recordings</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1109/TNSRE.2024.3352847" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1109/TNSRE.2024.3352847)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">The impact of task context on predicting finger movements in a brain-machine interface</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Suresh AK, Goodman JM, Okorokova EV, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This study investigated how changes in task context, such as adding spring resistance or altering wrist posture, affect the performance of brain-machine interfaces (BMIs) for decoding finger movements in rhesus macaques[1][3]. The researchers found that while offline decoding accuracy decreased in new contexts, monkeys could quickly adapt during online BMI control, likely due to the preservation of underlying neural population structure[1][4]. This work provides insights into BMI robustness across varying task conditions, which is crucial for translating these technologies to real-world applications in assistive devices and neuroprosthetics.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">Brain-machine interfaces</span>
                                
                                <span class="badge bg-secondary keyword-pill">Motor cortex</span>
                                
                                <span class="badge bg-secondary keyword-pill">Finger movements</span>
                                
                                <span class="badge bg-secondary keyword-pill">Neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">Task context</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.7554/eLife.82598" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.7554/eLife.82598)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Robust neural decoding for dexterous control of robotic hand prostheses</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                [Not provided in search results]
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper introduces a novel Dual Predictive Attractor-Refinement Strategy (DPARS) model for decoding continuous finger angles from electromyographic (EMG) signals to control robotic prosthetic hands. The proposed model achieves comparable or superior decoding accuracy to state-of-the-art methods like LSTM and CNN, while being over 50 times more compact, making it suitable for implementation in portable, next-generation robotic prosthetic hands. This innovation has the potential to significantly improve the functionality and accessibility of AI-enabled hand prostheses for amputees, enhancing their quality of life through more natural and efficient control of robotic limbs[1].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">HD-EMG</span>
                                
                                <span class="badge bg-secondary keyword-pill">robotic prostheses</span>
                                
                                <span class="badge bg-secondary keyword-pill">dexterous control</span>
                                
                                <span class="badge bg-secondary keyword-pill">deep learning</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1038/s41598-023-34215-7" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1038/s41598-023-34215-7)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">MyoGestic: EMG Interfacing Framework for Decoding Multiple Spared Degrees of Freedom of the Hand in Individuals with Neural Lesions</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                [Not provided in search results]
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> MyoGestic is a novel open-source software framework coupled with a wireless, high-density EMG bracelet that enables real-time decoding of multiple spared degrees of freedom in individuals with neural lesions such as spinal cord injury, stroke, and amputation[1]. The system allows for rapid adaptation of machine learning models to users' needs, facilitating intuitive interfacing of spared motor functions to control digital hands, wearable orthoses, prostheses, and 2D cursors within minutes of donning the device[1]. This participant-centered approach has the potential to bridge the gap between research and clinical applications, advancing the development of intuitive EMG interfaces for diverse neural injuries.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">EMG decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural lesions</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor intent</span>
                                
                                <span class="badge bg-secondary keyword-pill">real-time control</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/[Not provided in search results]" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: [Not provided in search results])
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">Improvement of hand functions of spinal cord injury patients with electromyography-driven hand exoskeleton: a feasibility study</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                [Not provided in search results]
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper presents a feasibility study on using an electromyography (EMG)-driven hand exoskeleton called Maestro to improve hand functions in spinal cord injury patients[8]. The key innovation is the integration of EMG-based user intent recognition with a powered hand exoskeleton to provide assistive grasping motions for activities of daily living[6]. This approach shows potential to enhance hand rehabilitation and functional independence for individuals with impaired hand function due to spinal cord injury, representing an important advancement in assistive biorobotics technology[8][6].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">EMG control</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand exoskeleton</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">rehabilitation</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand function</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1017/wtc.2020.16" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1017/wtc.2020.16)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Decoding Joint-Level Hand Movements With Intracortical Neural Signals in a Human Brain-Computer Interface</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Not specified in search results
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper investigates decoding fine hand movements at the single-joint level using intracortical neural signals recorded from the human motor cortex for brain-computer interface applications[5][7]. The key innovation is the ability to reconstruct detailed joint-level hand kinematics from neural activity, going beyond previous work on decoding gross hand movements or positions. This advance has potential to enable more dexterous and naturalistic control of robotic hands or prostheses through direct brain interfaces, significantly impacting the field of neuroprosthetics and biorobotics.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">Intracortical neural signals</span>
                                
                                <span class="badge bg-secondary keyword-pill">Brain-computer interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">Hand movement decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">Motor cortex</span>
                                
                                <span class="badge bg-secondary keyword-pill">Joint-level kinematics</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1109/TNSRE.2024.3372859" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1109/TNSRE.2024.3372859)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Cortical Decoding of Individual Finger and Wrist Kinematics for an Upper-Limb Neuroprosthesis</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Not specified in search results
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates the ability to decode individual finger and wrist kinematics from cortical neural activity for controlling an upper-limb neuroprosthesis. The researchers used microelectrode arrays in primary motor and premotor cortical areas to record neural signals, which were then used to continuously decode hand endpoint position and 18 joint angles of the wrist and fingers during a reach-and-grasp task[1]. This work represents a significant advancement in neural decoding for dexterous prosthetic control, potentially enabling more natural and precise manipulation of multi-fingered neuroprosthetic hands.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">Finger kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">Wrist kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">Cortical decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">Neuroprosthetics</span>
                                
                                <span class="badge bg-secondary keyword-pill">Multi-fingered prosthetic hand</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/Not provided in search results" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: Not provided in search results)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">Decoding repetitive finger movements with brain activity acquired via non-invasive electroencephalography</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Not specified in search results
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This study investigated the feasibility of decoding repetitive finger tapping movements from scalp EEG signals using a linear decoder with memory. The researchers achieved decoding accuracies with a median Pearson's correlation coefficient of 0.36 between observed and predicted finger trajectories, demonstrating that delta-band EEG signals contain useful information for inferring finger kinematics[1]. This work shows promise for developing non-invasive brain-computer interfaces that could enable control of robotic fingers or digital interfaces for individuals with motor impairments.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">EEG</span>
                                
                                <span class="badge bg-secondary keyword-pill">Finger movements</span>
                                
                                <span class="badge bg-secondary keyword-pill">Kinematics decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">Brain-computer interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">Non-invasive neural recording</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.3389/fneng.2014.00003" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.3389/fneng.2014.00003)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Case study: persistent recovery of hand movement and tactile sensation in peripheral nerve injury using targeted transcutaneous spinal cord stimulation</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Chandrasekaran S, Nanivadekar AC, McKernan GP, Helm ER, Boninger ML, Collinger JL, Gaunt RA, Fisher LE
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This study demonstrates the effectiveness of targeted transcutaneous spinal cord stimulation (tSCS) in restoring hand strength, dexterity, and tactile sensation in a patient with peripheral nerve injury[1][3]. The key innovation is the use of a custom electronically-configurable electrode array to target specific cervical levels, achieving maximal recruitment of desired muscle groups[1][4]. This approach shows promise as a non-invasive therapeutic technique for functional recovery after peripheral nerve injuries, with potential applications in biorobotics for developing more effective neurorehabilitation strategies[3][6].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">transcutaneous spinal cord stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand movement</span>
                                
                                <span class="badge bg-secondary keyword-pill">tactile sensation</span>
                                
                                <span class="badge bg-secondary keyword-pill">rehabilitation</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.3389/fnins.2023.1210544" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.3389/fnins.2023.1210544)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 6</span>
                            <h5 class="card-title">A regenerative peripheral nerve interface allows real-time control of an artificial hand in upper limb amputees</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Vu PP, Vaskov AK, Irwin ZT, Henning PT, Lueders DR, Laidlaw AT, Davis AJ, Nu CS, Gates DH, Brent Gillespie R, Kemp SWP, Kung TA, Chestek CA, Cederna PS
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates that regenerative peripheral nerve interfaces (RPNIs) can serve as stable bioamplifiers of motor signals in upper limb amputees, allowing real-time control of prosthetic hands for up to 300 days without recalibration. The RPNIs produced high-amplitude electromyography signals with large signal-to-noise ratios, enabling subjects to control individual finger movements and grasping postures of an artificial hand. This innovation has significant potential to enhance intuitive and dexterous control of advanced upper limb prostheses, improving functionality and quality of life for amputees.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">regenerative peripheral nerve interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">prosthetic control</span>
                                
                                <span class="badge bg-secondary keyword-pill">upper limb amputation</span>
                                
                                <span class="badge bg-secondary keyword-pill">electromyography</span>
                                
                                <span class="badge bg-secondary keyword-pill">artificial hand</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1126/scitranslmed.aay2857" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1126/scitranslmed.aay2857)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Biomimetic sensory feedback through peripheral nerve stimulation improves dexterous use of a bionic hand</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                George JA, Davis TS, Brinton MR, Clark GA
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates that biomimetic sensory feedback through peripheral nerve stimulation improves fine motor control and object discrimination capabilities in a bionic hand prosthesis. The researchers developed a sensory encoding algorithm that mimics natural tactile signals, resulting in more intuitive and informative artificial sensory experiences for the user. This innovation in biomimetic feedback has the potential to significantly enhance the dexterity and functionality of prosthetic limbs, bringing bionic hands closer to the capabilities of natural hands[1][2].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">biomimetic sensory feedback</span>
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">bionic hand</span>
                                
                                <span class="badge bg-secondary keyword-pill">object discrimination</span>
                                
                                <span class="badge bg-secondary keyword-pill">activities of daily living</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1126/scirobotics.aax2352" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1126/scirobotics.aax2352)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 6</span>
                            <h5 class="card-title">Learning of Artificial Sensation Through Long-Term Home Use of a Sensory-Enabled Prosthesis</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Graczyk EL, Resnik L, Schiefer MA, Schmitt MS, Tyler DJ
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This study investigated how extended home use of a neural-connected, sensory-enabled prosthetic hand influenced perception of artificial sensory feedback in a person with transradial amputation over 115 days. The key findings showed that artificial somatosensation can undergo learning processes similar to intact sensation, with improvements in sensory perception, psychosocial outcomes, and functional performance over time. This research demonstrates the potential for sensory restoration in prostheses to enhance embodiment and usability through neuroplasticity, which could significantly impact the development and adoption of advanced bionic limbs[1][2].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">artificial somatosensation</span>
                                
                                <span class="badge bg-secondary keyword-pill">sensory learning</span>
                                
                                <span class="badge bg-secondary keyword-pill">home use</span>
                                
                                <span class="badge bg-secondary keyword-pill">prosthesis</span>
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.3389/fnins.2019.00853" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.3389/fnins.2019.00853)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 6</span>
                            <h5 class="card-title">MyoGestic: EMG interfacing framework for decoding multiple spared motor dimensions in neural lesions</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Not provided in the search results
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper "MyoGestic: EMG interfacing framework for decoding multiple spared motor dimensions in neural lesions" introduces a novel, noninvasive neural interface system that combines a high-density EMG bracelet with a machine learning framework to decode motor intent in individuals with spinal cord injuries, strokes, or amputations. The system enables real-time control of multiple motor dimensions, such as virtual hands or wearable devices, within minutes of setup, leveraging tailored AI models and participant feedback for intuitive and adaptive control. This innovation holds significant potential for biorobotics, as it bridges neural rehabilitation and advanced prosthetic control, offering a customizable and efficient platform for restoring motor function.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">EMG decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">machine learning</span>
                                
                                <span class="badge bg-secondary keyword-pill">rehabilitation</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1126/sciadv.ads9150" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1126/sciadv.ads9150)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Decoding hand kinematics from population responses in sensorimotor cortex during grasping</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Schaffelhofer S, Agudelo-Toro A, Scherberger H
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates the ability to decode detailed hand kinematics (30 degrees of freedom) during grasping movements from small populations of neurons in macaque primary motor and somatosensory cortex. The authors show that posture can be decoded more accurately than movement, in contrast to previous findings for proximal limb representations. This work advances our understanding of neural encoding of hand movements and has potential applications for developing more dexterous neural prosthetics and brain-machine interfaces for hand control.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">intracortical recording</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">grasping</span>
                                
                                <span class="badge bg-secondary keyword-pill">sensorimotor cortex</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1152/jn.00532.2014" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1152/jn.00532.2014)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 6</span>
                            <h5 class="card-title">Decoding grasp and movement-related parameters from cortical ensemble activity in humans with tetraplegia using surface electrocorticography</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Ajiboye AB, Willett FR, Young DR, Memberg WD, Murphy BA, Miller JP, Walter BL, Sweet JA, Hoyen HA, Keith MW, Peckham PH, Simeral JD, Donoghue JP, Hochberg LR, Kirsch RF
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates the ability to decode grasp types and movement-related parameters from cortical ensemble activity in humans with tetraplegia using surface electrocorticography (ECoG). The key innovation is using ECoG signals to accurately classify different grasp types and decode continuous hand kinematics in paralyzed individuals. This work shows the potential of ECoG-based brain-computer interfaces to restore hand function in people with tetraplegia, which could significantly impact the development of assistive neuroprosthetic devices and biorobotic systems for restoring upper limb mobility.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">brain-computer interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">electrocorticography</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">tetraplegia</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1088/1741-2552/aa5272" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1088/1741-2552/aa5272)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Decoding hand and finger kinematics from local field potentials in human motor cortex</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Flint RD, Wang PT, Wright ZA, King CE, Krucoff MO, Schuele SU, Rosenow JM, Hsu FP, Liu CY, Lin JJ, Sazgar M, Millett DE, Shaw SJ, Nenadic Z, Do AH, Slutzky MW
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates the ability to decode individual finger and hand kinematics from local field potentials (LFPs) recorded in human motor cortex. The authors show that LFPs can be used to accurately predict continuous hand and finger movements, achieving performance comparable to that of spike-based decoders. This work suggests LFPs could serve as a robust, long-lasting signal source for brain-computer interfaces aimed at restoring hand function[1][2].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">intracortical recording</span>
                                
                                <span class="badge bg-secondary keyword-pill">local field potentials</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor cortex</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1109/TNSRE.2014.2364776" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1109/TNSRE.2014.2364776)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Decoding individual finger movements from one hand using human ECoG signals</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Liang N, Bougrain L
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates the feasibility of decoding individual finger movements from one hand using electrocorticography (ECoG) signals recorded from the human brain. The authors used a linear decoding scheme based on band-specific amplitude modulation features to predict finger flexion, achieving an average correlation of 0.46 between predicted and actual movements across subjects. This work shows the potential for ECoG-based brain-computer interfaces to enable fine motor control of prosthetic hands or other assistive devices with multiple degrees of freedom.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">electrocorticography</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">finger movements</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor cortex</span>
                                
                                <span class="badge bg-secondary keyword-pill">brain-computer interface</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1371/journal.pone.0050451" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1371/journal.pone.0050451)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Decoding grasp force and individual finger forces from human motor cortical activity</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Vargas-Irwin CE, Brandman DM, Zimmermann JB, Donoghue JP, Hochberg LR
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates the ability to decode both overall grasp force and individual finger forces from neural activity recorded in the motor cortex of humans with tetraplegia. Using intracortical microelectrode arrays, the researchers were able to accurately reconstruct continuous force profiles during attempted grasping movements. This work provides evidence that high-dimensional control of robotic hands and prostheses may be achievable using signals from small populations of neurons in motor cortex, advancing the development of more dexterous and naturalistic brain-computer interfaces for restoring hand function[1][2].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">intracortical recording</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">grasp force</span>
                                
                                <span class="badge bg-secondary keyword-pill">finger forces</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor cortex</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1088/1741-2552/aae953" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1088/1741-2552/aae953)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Restoring the sense of touch by means of peripheral nerve stimulation</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Dustin J. Tyler
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper reviews techniques for restoring the sense of touch in upper limb amputees using peripheral nerve stimulation. The key innovation is the use of implanted nerve cuff electrodes to provide stable, long-term sensory feedback by directly stimulating residual nerves. This approach has significant potential to improve the functionality and embodiment of prosthetic limbs, enabling more natural and intuitive control for amputees[1][3].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">sensory restoration</span>
                                
                                <span class="badge bg-secondary keyword-pill">neuroprosthetics</span>
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve interfaces</span>
                                
                                <span class="badge bg-secondary keyword-pill">tactile feedback</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1088/1741-2552/ab4d54" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1088/1741-2552/ab4d54)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Closed-loop control of grasp force using peripheral nerve stimulation</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Matthew A. Schiefer, Daniel Tan, Steven M. Sidek, Dustin J. Tyler
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates a closed-loop control system for prosthetic hands that uses peripheral nerve stimulation to provide sensory feedback about grasp force. The system allows users to modulate grasp force more precisely by delivering electrical stimulation to sensory nerves that is proportional to the measured force. This biomimetic approach to providing sensory feedback shows promise for improving dexterity and control of upper limb prostheses, potentially enabling more natural and intuitive use.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">functional electrical stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">prosthesis control</span>
                                
                                <span class="badge bg-secondary keyword-pill">sensory feedback</span>
                                
                                <span class="badge bg-secondary keyword-pill">closed-loop control</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1088/1741-2552/aab790" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1088/1741-2552/aab790)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Biomimetic intraneural sensory feedback enhances sensation naturalness, tactile sensitivity, and manual dexterity in a bidirectional prosthesis</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Giacomo Valle, Alberto Mazzoni, Francesco Iberite, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates that biomimetic intraneural sensory feedback in a prosthetic hand can enhance sensation naturalness, tactile sensitivity, and manual dexterity compared to traditional non-biomimetic feedback approaches. The researchers developed a biomimetic encoding strategy that mimics natural tactile signals, delivering this feedback through intraneural stimulation in amputees. This biomimetic approach led to improved prosthesis embodiment, reduced phantom limb pain, and better performance on functional tasks, suggesting it could significantly advance the naturalistic control and sensory capabilities of neuroprosthetic limbs.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">neuroprosthetics</span>
                                
                                <span class="badge bg-secondary keyword-pill">sensory feedback</span>
                                
                                <span class="badge bg-secondary keyword-pill">intraneural stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">biomimetic encoding</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1016/j.neuron.2018.08.033" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1016/j.neuron.2018.08.033)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">A neural interface provides long-term stable natural touch perception</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Dustin J. Tyler, Aidan D. Roche, Emily L. Graczyk, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates that implanted peripheral nerve interfaces can provide stable, natural touch sensations in the phantom hands of upper limb amputees for over a year. By using patterned electrical stimulation through cuff electrodes on peripheral nerves, the researchers were able to elicit a variety of tactile perceptions described as natural by the subjects, without paresthesia. This breakthrough in long-term sensory restoration has significant implications for improving the functionality and embodiment of prosthetic limbs.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">sensory restoration</span>
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">neuroprosthetics</span>
                                
                                <span class="badge bg-secondary keyword-pill">long-term stability</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1126/scitranslmed.3008669" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1126/scitranslmed.3008669)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Robust neural decoding for dexterous control of robotic hand prostheses</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                [Not provided in search results]
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This study developed a deep learning-based neural decoding approach that maps high-density electromyogram (HD-EMG) signals to finger-specific neural-drive signals for continuous control of robotic hand prostheses[1]. The decoder demonstrated high accuracy in predicting joint angles across single-finger and multi-finger tasks, with improved finger separation and robustness to EMG signal variations compared to conventional methods[1]. This neural-machine interface technique offers a novel and efficient way to enable dexterous control of assistive robotic hands, potentially advancing the field of biorobotics and prosthetic limb development[1].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">Neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">robotic hand</span>
                                
                                <span class="badge bg-secondary keyword-pill">dexterous control</span>
                                
                                <span class="badge bg-secondary keyword-pill">HD-EMG</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural-drive signals</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1016/j.neuroscience.2023.06.007" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1016/j.neuroscience.2023.06.007)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Decoding Joint-Level Hand Movements With Intracortical Neural Signals</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Xin Liu, Zhenyu Ren, Xiaogang Chen, Qiaosheng Zhang, Jiping He
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper investigates decoding fine hand movements at the single-joint level using intracortical neural signals recorded from the motor cortex. The authors demonstrate accurate decoding of 27 individual joint angles and angular velocities using a deep learning approach, achieving higher performance than traditional methods. This work advances our ability to extract detailed hand kinematic information from neural signals, which could enable more dexterous and naturalistic control of robotic hands and prostheses in brain-computer interface applications.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">intracortical neural signals</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor cortex</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">brain-computer interface</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1109/TNSRE.2024.3366506" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1109/TNSRE.2024.3366506)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">Decoding hand kinetics and kinematics using somatosensory cortex activity in non-human primates</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Abbasi, Adeel, Chao, Zenas C., Ghanbari, Ladan, Torab, Kian, Yazdan-Shahmorad, Azadeh
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This study demonstrates that hand kinematics and kinetics can be accurately decoded from neural activity in area 2 of the primary somatosensory cortex (S1) in non-human primates during both active and passive hand movements. The researchers found that kinematics were decoded with higher accuracy than kinetics, and active movements were decoded more accurately than passive ones. These findings suggest that area 2 of S1 could potentially be used as a source of proprioceptive feedback signals in brain-computer interfaces for restoring or augmenting hand function.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">somatosensory cortex</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">brain-computer interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">non-human primates</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1038/s41598-023-40664-x" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1038/s41598-023-40664-x)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">State-based decoding of hand and finger kinematics using neuronal ensemble and local field potential activity</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Ajiboye, A. Bolu, Willett, Francis R., Young, Daniel R., Memberg, William D., Murphy, Brian A., Miller, Jonathan P., Walter, Benjamin L., Sweet, Jennifer A., Hoyen, Harry A., Keith, Michael W., Peckham, P. Hunter, Simeral, John D., Donoghue, John P., Hochberg, Leigh R., Kirsch, Robert F.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper presents a novel state-based decoding approach for hand and finger kinematics using both neuronal ensemble and local field potential (LFP) activity recorded from multiple cortical areas during reach-and-grasp movements[1]. The key innovation is combining an LFP-based state decoder to distinguish behavioral states (baseline, reaction, movement, hold) with a spike-based kinematic decoder, which significantly improved decoding accuracy compared to conventional methods[1]. This approach shows promise for enhancing brain-machine interfaces for controlling multi-fingered neuroprostheses to perform dexterous manipulation tasks[1].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">intracortical neural signals</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">state decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">local field potentials</span>
                                
                                <span class="badge bg-secondary keyword-pill">brain-computer interface</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1152/jn.00079.2012" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1152/jn.00079.2012)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">Decoding repetitive finger movements with brain activity acquired via non-invasive electroencephalography</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Ofner, Patrick, MÃ¼ller-Putz, Gernot R.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates the ability to decode repetitive finger movements from non-invasive EEG signals using a linear decoder with memory. The authors achieved median correlation coefficients of 0.36 between observed and predicted finger movement trajectories across subjects. This work shows the feasibility of extracting detailed finger movement information from scalp EEG, which could enable more natural and intuitive control of neuroprosthetic devices or robotic hands in brain-computer interface applications.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">electroencephalography</span>
                                
                                <span class="badge bg-secondary keyword-pill">finger movements</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">brain-computer interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">non-invasive</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1038/s41598-018-25828-4" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1038/s41598-018-25828-4)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Restoring motor control and sensory feedback in people with upper extremity amputations using arrays of 96 microelectrodes implanted in the median and ulnar nerves</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Dustin J. Tyler, David M. Durand, Kevin L. Kilgore
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This study demonstrated the successful implantation of Utah Slanted Electrode Arrays (USEAs) with 96 microelectrodes into the median and ulnar nerves of upper extremity amputees for up to 1 month[2]. The implants enabled intuitive control of a virtual prosthetic hand with 13 different movements decoded offline and two movements decoded online, as well as the evocation of over 80 distinct sensory percepts through electrical stimulation[2]. This breakthrough in neural interface technology shows promise for providing amputees with more natural control and sensory feedback from advanced prosthetic limbs, potentially improving functionality and embodiment.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">neural interfaces</span>
                                
                                <span class="badge bg-secondary keyword-pill">sensory feedback</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor control</span>
                                
                                <span class="badge bg-secondary keyword-pill">upper limb prosthetics</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1088/1741-2552/aa9996" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1088/1741-2552/aa9996)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Closed-loop control of grasp force using peripheral neural signals in a bidirectional prosthesis</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Shivaram Arun Kumar, Jacob A. George, Suzanne Wendelken, David M. Page, Gregory A. Clark
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper presents a closed-loop control system for a prosthetic hand that uses peripheral neural signals to modulate grasp force. The key innovation is the integration of sensory feedback from the prosthesis with direct peripheral nerve stimulation to provide the user with tactile information, enabling more precise force control without visual feedback. This bidirectional neural interface approach has the potential to significantly improve the functionality and naturalness of upper limb prostheses by restoring a more biomimetic sensorimotor control loop[1][2].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">closed-loop control</span>
                                
                                <span class="badge bg-secondary keyword-pill">prosthetic hand</span>
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">sensory feedback</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1109/TNSRE.2020.3048592" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1109/TNSRE.2020.3048592)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Biomimetic encoding model for restoring touch in bionic hands through a nerve interface</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Giacomo Valle, Francesco M. Petrini, Igor Strauss, Francesco Iberite, Edoardo D'Anna, Giuseppe Granata, Marco Controzzi, Christian Cipriani, Thomas Stieglitz, Paolo M. Rossini, Silvestro Micera
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper presents a biomimetic model for encoding tactile sensations in bionic hands through electrical stimulation of residual somatosensory nerves in amputees. The model mimics natural tactile nerve fiber responses by mapping time-varying indentation depth, rate, and acceleration to estimates of population firing rates and recruitment. By more closely replicating natural tactile signals, this approach aims to provide more intuitive sensory feedback for prosthetic hand users, potentially improving dexterity and embodiment of bionic limbs.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">neural encoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">sensory feedback</span>
                                
                                <span class="badge bg-secondary keyword-pill">bionic hands</span>
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1088/1741-2552/ab4a5d" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1088/1741-2552/ab4a5d)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
            </div>
        </div>

        <footer class="pt-4 my-md-5 pt-md-5 border-top">
            <div class="row">
                <div class="col-12 col-md">
                    <small class="d-block mb-3 text-muted">&copy; 2025 Biorobotics Literature
                        Monitor</small>
                </div>
            </div>
        </footer>
    </div>

    <script>
        document.getElementById('filter-input').addEventListener('keyup', function () {
            const filterValue = this.value.toLowerCase();
            const papers = document.querySelectorAll('.paper-card');

            papers.forEach(paper => {
                const text = paper.textContent.toLowerCase();
                if (text.includes(filterValue)) {
                    paper.style.display = '';
                } else {
                    paper.style.display = 'none';
                }
            });
        });
    </script>
</body>

</html>