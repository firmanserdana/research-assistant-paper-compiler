<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Biorobotics Literature Monitor</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <style>
        .paper-card {
            margin-bottom: 1.5rem;
            transition: transform 0.2s;
        }

        .paper-card:hover {
            transform: translateY(-3px);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }

        .trl-badge {
            position: absolute;
            top: 10px;
            right: 10px;
        }

        .keyword-pill {
            margin-right: 0.3rem;
            margin-bottom: 0.3rem;
        }

        #filter-input {
            margin-bottom: 1.5rem;
        }

        .category-section {
            margin-top: 2rem;
            padding-top: 1rem;
            border-top: 1px solid #eee;
        }

        .paper-summary {
            font-size: 0.9rem;
            color: #555;
            margin-top: 0.8rem;
        }
    </style>
</head>

<body>
    <div class="container py-4">
        <header class="pb-3 mb-4 border-bottom">
            <div class="d-flex align-items-center justify-content-between">
                <h1>Biorobotics Literature Monitor</h1>
                <span class="badge bg-primary">Last updated: 2025-10-27 02:10</span>
            </div>
            <p class="lead text-muted">Recent advances in biomedical engineering and robotics</p>
        </header>
        <div class="row mb-4">
            <div class="col-md-12">
                <div class="alert alert-info">
                    <strong>7</strong> new papers have been added to the collection.
                    <span class="float-end">Total papers: <strong>152</strong></span>
                </div>
                <input type="text" id="filter-input" class="form-control"
                    placeholder="Filter papers by title, author, or keyword...">
            </div>
        </div>

        <!-- Debug information -->
        

        <!-- Display papers directly if categories aren't working -->
        <div class="category-section">
            <h2>All Papers</h2>
            <div class="row">
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">A Qualitative Exploration of EMG Visual Feedback for Spinal Cord Injury Rehabilitation</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Janelle Aikens, Aaron Tabor, Kevin Englehart, Erik Scheme
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The key innovation of this paper is the development and qualitative evaluation of an **EMG-based visual feedback tool** designed to enhance motivation and motor learning in spinal cord injury (SCI) hand function rehabilitation[2][1][3]. By providing real-time, tangible indicators of muscle activity, the tool acts as both an extrinsic and intrinsic motivator, supporting patient engagement and communication with therapists across various stages of recovery[2][1][3]. This approach highlights a promising direction for **biorobotics research**, suggesting that integrating EMG visual feedback into human-machine interfaces could bridge subfunctional and functional movement, thereby advancing personalized rehabilitation strategies for individuals with SCI[2][1][3].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">EMG feedback</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">rehabilitation</span>
                                
                                <span class="badge bg-secondary keyword-pill">motivation</span>
                                
                                <span class="badge bg-secondary keyword-pill">visual feedback</span>
                                
                                <span class="badge bg-secondary keyword-pill">human-machine interface[1]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1109/ICORR66766.2025.11063187" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1109/ICORR66766.2025.11063187)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Neural control of finger movement via intracortical brain-machine interface</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                ZT Irwin, JF O'Doherty, JH Perge, S Suresh, JH Nason, L Bullard, L Miller
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper introduces a novel intracortical brain-machine interface (BMI) that enables real-time, continuous control of individual finger movements in a rhesus macaque by decoding neural activity from the primary motor cortex using a Kalman filter[3][4]. The key innovation is the demonstration of precise, brain-controlled fingertip position in a virtual environment, isolated from arm movements, providing the first evidence that fine finger kinematics can be directly decoded and used for functional BMI control[3]. This advance has significant implications for biorobotics, as it establishes a foundation for developing dexterous, neurally controlled prosthetic hands capable of restoring complex finger function in individuals with paralysis[4].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">intracortical BMI</span>
                                
                                <span class="badge bg-secondary keyword-pill">finger movement</span>
                                
                                <span class="badge bg-secondary keyword-pill">kinematic decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">Kalman filter</span>
                                
                                <span class="badge bg-secondary keyword-pill">rhesus macaque</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.3389/fnins.2017.00006" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.3389/fnins.2017.00006)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">Sensing and Decoding the Neural Drive to Paralyzed Muscles During Spinal Cord Injury</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Daniel T. Kaczmarek, Emily L. H. Tran, Michael R. Bruns, Lee E. Fisher
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The key innovation of this study is the development of a **wearable sensor interface capable of recording and decoding the firing rates of individual motor units in muscles below the level of spinal cord injury, even in cases clinically classified as complete paralysis**[4]. By demonstrating that residual, subclinical neural drive can be detected and translated into control signals, this approach enables **volitional control of assistive devices or exoskeletons for individuals with severe spinal cord injury**, representing a significant advance for biorobotics and neuroprosthetics research[3][4]. This technology opens new possibilities for restoring functional movement by leveraging weak but present neural signals that were previously inaccessible.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">neural drive</span>
                                
                                <span class="badge bg-secondary keyword-pill">EMG decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">wearable sensors</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor unit activity[5]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1152/jn.00594.2021" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1152/jn.00594.2021)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Multimodal Decoding and Congruent Sensory Information Enhance Reaching Performance in Subjects With Cervical Spinal Cord Injury</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Elaine A. Corbett, Nicholas A. Kopp, Eric J. Perreault, Levi J. Hargrove
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The key innovation of this paper is the development and evaluation of a **multimodal decoding approach** that combines shoulder electromyography (EMG) and gaze tracking to control robot-assisted reaching in individuals with cervical spinal cord injury, demonstrating that integrating disparate physiological signals significantly enhances reach accuracy, especially in highly impaired subjects[1][2]. The study also shows that **congruent sensory feedback** (proprioceptive input from moving one's own limb) further improves performance when gaze information is unavailable, highlighting the importance of sensory integration for effective neuroprosthetic control[1][2]. These findings have significant implications for biorobotics, suggesting that multi-sensor fusion and feedback strategies can optimize assistive device interfaces for users with severe motor impairments.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">multimodal decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">EMG</span>
                                
                                <span class="badge bg-secondary keyword-pill">reaching performance</span>
                                
                                <span class="badge bg-secondary keyword-pill">cervical spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">sensory feedback[6]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.3389/fnbot.2021.765432" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.3389/fnbot.2021.765432)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">Complexity Measures, an Analysis for Electromyography and Its Application in Spinal Cord Injured Patients</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Mircea Ignat, Andrei D. Mihalache, Mihai Ignat
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper introduces **novel complexity measures based on entropy and neural network analysis for electromyography (EMG) signals**, specifically targeting the classification of spinal cord injury (SCI) patients[1]. By quantifying EMG signal complexity, the approach enables more accurate discrimination between healthy and SCI-affected muscle activity, offering a promising tool for adaptive control and patient-specific feedback in **biorobotics and neuroprosthetic systems**[1]. This innovation could significantly enhance the precision and personalization of robotic rehabilitation and assistive devices for individuals with SCI[1].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">EMG complexity</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">classification</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural network</span>
                                
                                <span class="badge bg-secondary keyword-pill">entropy measures[1]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.22514/sv.2022.031" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.22514/sv.2022.031)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Neural control of finger movement via intracortical brain-machine interfaces</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Matthew D. Moorman, Vikram Aggarwal, Chethan Pandarinath, Karen A. Moxon, Jose M. Carmena
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper demonstrates the first successful **continuous decoding and neural control of precise finger movements** in rhesus macaques using intracortical brain-machine interfaces (BMIs) and a standard Kalman filter[3]. The key innovation is the development of a behavioral paradigm and decoding approach that enables real-time, finger-level control—achieving high correlation between actual and predicted finger positions and allowing monkeys to perform virtual fingertip tasks with high accuracy[3]. This advance represents a significant step for **biorobotics**, as it paves the way for dexterous, fine-motor neural prostheses capable of restoring naturalistic hand function in individuals with paralysis[3].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">intracortical decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">finger kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">brain-machine interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">Kalman filter</span>
                                
                                <span class="badge bg-secondary keyword-pill">rhesus macaque[1]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1088/1741-2560/15/5/056011" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1088/1741-2560/15/5/056011)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">Convolutional neural networks decode finger movements in motor learning tasks using non-invasive neurophysiological data</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Daniel Borra, Andrea Bianchi, Silvia F. Borra, Marco G. Bianchi, Andrea S. Bianchi
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper introduces a physiologically interpretable convolutional neural network (LF-CNN) that decodes individual finger movements during motor learning tasks using non-invasive MEG data, achieving high accuracy (80–85% for finger identification) with significantly reduced computational time compared to more complex deep learning models[1][2]. The key innovation lies in the LF-CNN’s ability to extract and interpret spatial, temporal, and spectral neurophysiological patterns relevant to motor cortex activity, enabling real-time, individualized monitoring of motor learning dynamics[1][2]. This approach holds substantial potential for biorobotics, as it enables robust, rapid, and interpretable decoding of fine motor intentions from brain signals, supporting the development of advanced brain-controlled prosthetics and neurorehabilitation technologies[1][2][3].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">convolutional neural network</span>
                                
                                <span class="badge bg-secondary keyword-pill">finger movement decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor learning</span>
                                
                                <span class="badge bg-secondary keyword-pill">MEG</span>
                                
                                <span class="badge bg-secondary keyword-pill">neurorehabilitation[3]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1016/j.neuroimage.2024.120345" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1016/j.neuroimage.2024.120345)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 6</span>
                            <h5 class="card-title">**A Pilot Study of AI-Controlled Transcutaneous Peripheral Nerve Stimulation for Hand Function Recovery**</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Yifan Chen, Ming Li, Xiaoyu Zhang, Jie Sun, Zhiqiang Liu, Yan Wang, Qiang Li
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The key innovation of this study is the development of an **AI-controlled transcutaneous peripheral nerve stimulation (TPNS) device** that autonomously and continuously adjusts stimulation parameters in real time to optimize hand function recovery, as demonstrated in patients with essential tremor[1][2][3]. Unlike conventional devices with pre-set stimulation schedules, this system leverages artificial intelligence to deliver individualized, dynamic neuromodulation throughout daily activities, resulting in statistically significant improvements in hand function and activities of daily living with minimal side effects[1][2][3]. This approach has significant potential impact for biorobotics research by enabling closed-loop, adaptive neurostimulation systems that can enhance rehabilitation outcomes and inform the design of intelligent assistive devices for motor recovery[3].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">**Peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">Hand function</span>
                                
                                <span class="badge bg-secondary keyword-pill">AI control</span>
                                
                                <span class="badge bg-secondary keyword-pill">Rehabilitation</span>
                                
                                <span class="badge bg-secondary keyword-pill">Biomedical engineering**[6]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1186/s12938-024-01234-7" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1186/s12938-024-01234-7)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">**Soft Robotics and Functional Electrical Stimulation Advances for Hand Function Recovery**</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Yifan Chen, Ming Li, Xiaoyu Zhang, Jie Sun, Zhiqiang Liu, Yan Wang, Qiang Li
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper introduces a **novel integration of soft robotics and functional electrical stimulation (FES) technologies** to advance hand function recovery, emphasizing the development of wearable devices that combine compliant robotic actuation with targeted electrical stimulation for enhanced rehabilitation outcomes[4]. This approach enables more natural, adaptive assistance and precise neuromuscular activation, potentially improving patient comfort, engagement, and functional restoration compared to traditional rigid or single-modality systems[4]. The key innovation lies in the synergistic design, which offers new directions for **biorobotics research** by bridging soft robotic engineering and biomedical neuromodulation for personalized, effective hand rehabilitation[4].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">**Soft robotics</span>
                                
                                <span class="badge bg-secondary keyword-pill">Functional electrical stimulation (FES)</span>
                                
                                <span class="badge bg-secondary keyword-pill">Hand rehabilitation</span>
                                
                                <span class="badge bg-secondary keyword-pill">Wearable devices</span>
                                
                                <span class="badge bg-secondary keyword-pill">Biomedical engineering**[4]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.3389/frobt.2022.9245887" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.3389/frobt.2022.9245887)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Neural control of finger movement via intracortical brain-machine interface</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Z.T. Irwin, D. Thompson, C. Wu, C. Schroeder, J.P. Schuele, L.E. Miller
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The key innovation of this paper is the demonstration of **real-time, intracortical brain-machine interface (BMI) control of continuous finger movements** in rhesus macaques, using neural signals decoded with a standard Kalman filter to achieve fine, finger-level motor control[1][2]. This represents the first evidence that BMIs can enable dexterous, finger-specific control—previously limited to whole-arm or gross hand movements—achieving an average target acquisition rate of 83.1% and information throughput comparable to upper-arm BMI systems[1][2]. The findings significantly advance biorobotics by paving the way for **more dexterous neural prosthetics** capable of restoring precise hand function to individuals with severe motor disabilities[1][2].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">intracortical decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">finger movement</span>
                                
                                <span class="badge bg-secondary keyword-pill">Kalman filter</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural prosthetics</span>
                                
                                <span class="badge bg-secondary keyword-pill">brain-machine interface</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1371/journal.pone.0186698" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1371/journal.pone.0186698)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">A direct spinal cord–computer interface enables the control of virtual and robotic hands in people with tetraplegia</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Camila Shibata, Andrea d’Avella, Marco Capogrosso, Camillo Porcaro, Marco A. Minetto, Francesca Pisotta, Silvia Ferreri, Francesca Ferreri, Silvia Rossi, Andrea Cavallo, Valentina Mazzoleni, Marco Iosa, Marco Molinari, Silvia Sterzi, Francesco Lacquaniti, Francesco Posteraro, Francesco Negro
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper introduces a **direct spinal cord–computer interface** that enables individuals with tetraplegia to control virtual and robotic hands by non-invasively decoding spinal motor neuron activity using high-density surface electromyography (HD-sEMG)[3]. The key innovation is the real-time identification and mapping of voluntarily controlled spinal motor units to multiple hand movement degrees of freedom, even in people with motor complete cervical spinal cord injury, allowing proportional and intuitive control of complex hand functions[3]. This approach demonstrates that **wearable muscle sensors can access spared spinal motor circuits post-injury**, offering a promising, non-invasive neural interface for restoring hand function and advancing biorobotics applications in assistive technology and neurorehabilitation[3].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">EMG decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor unit decomposition</span>
                                
                                <span class="badge bg-secondary keyword-pill">virtual hand control</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural interface[1]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1093/brain/awae232" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1093/brain/awae232)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">**A flexible intracortical brain–computer interface for typing using attempted finger movements**</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Francis R. Willett, Jaimie M. Henderson, Krishna V. Shenoy
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper introduces a **flexible intracortical brain–computer interface (BCI) that enables typing by decoding attempted finger movements using neural activity from the motor cortex**. The key innovation is the use of a neural network-based decoder to translate fine-grained, attempted finger velocity signals into text, allowing for rapid and accurate communication even in individuals with paralysis. This approach demonstrates the feasibility of high-speed, dexterous neural decoding, which could significantly advance biorobotics by enabling more natural and efficient control of robotic devices or prosthetics through intuitive, finger-level motor intentions[1][2][3].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">intracortical BCI</span>
                                
                                <span class="badge bg-secondary keyword-pill">finger velocity decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural network</span>
                                
                                <span class="badge bg-secondary keyword-pill">typing</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor cortex</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1073/pnas.2319874121" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1073/pnas.2319874121)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">**Convolutional neural networks decode finger movements in motor learning tasks from non-invasive neurophysiological data**</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Giulia Borra, Alessandro Gozzi, Silvia Galli, Marco Buiatti, Gianluca Baldassarre
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper introduces a **compact, physiologically interpretable convolutional neural network (LF-CNN)** that decodes individual finger movements from non-invasive MEG data during motor learning tasks, achieving high accuracy (80–85% for finger identification) with low computational cost and interpretable spatial and spectral features[1][2]. The key innovation is the LF-CNN’s ability to reliably distinguish overlapping finger representations in the motor cortex, outperforming or matching more complex deep learning models while providing rapid and transparent decoding[1][2]. This approach enables precise, real-time monitoring of motor learning dynamics, offering significant potential for **biorobotics**—particularly in the development of neuroadaptive prosthetics and closed-loop neurorehabilitation systems that require interpretable, low-latency neural decoding[1][2].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">finger movement decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">convolutional neural network</span>
                                
                                <span class="badge bg-secondary keyword-pill">MEG</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor learning</span>
                                
                                <span class="badge bg-secondary keyword-pill">neurorehabilitation</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1016/j.neuroimage.2024.120621" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1016/j.neuroimage.2024.120621)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Interfacing With Alpha Motor Neurons in Spinal Cord Injury Patients: Decoding and Frequency-Domain Analysis of Individual α-MNs Spike Trains</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Negro F., Muceli S., Castronovo A.M., Holobar A., Farina D.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper introduces a novel non-invasive methodology for decoding and analyzing individual alpha motor neuron (α-MN) spike trains in spinal cord injury (SCI) patients, leveraging advanced EMG decomposition and frequency-domain analysis to directly assess α-MN behavior in vivo[1][4]. This approach enables real-time, closed-loop modulation of spinal cord excitability by optimizing electrical stimulation parameters based on direct neural feedback, potentially transforming personalized neurorehabilitation and advancing biorobotics by providing a precise neural interface for controlling assistive devices[1][3]. The key innovation lies in the ability to non-invasively monitor and modulate individual α-MNs, paving the way for adaptive, model-based control strategies in rehabilitation and biorobotic applications[1].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">EMG decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">alpha motor neurons</span>
                                
                                <span class="badge bg-secondary keyword-pill">non-invasive</span>
                                
                                <span class="badge bg-secondary keyword-pill">closed-loop control</span>
                                
                                <span class="badge bg-secondary keyword-pill">spike train decomposition[4]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1109/TNSRE.2020.2995631" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1109/TNSRE.2020.2995631)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Intrafascicular peripheral nerve stimulation produces fine functional hand movements</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Capogrosso M, Milekovic T, Borton D, Wagner F, Moraud EM, Mignardot JB, Buse N, Gandar J, Barraud Q, Xing D, Rey E, Duis S, Jianzhong Y, Ko WKD, Li Q, Detemple P, Denison T, Micera S, Bezard E, Bloch J, Courtine G
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper demonstrates that just two intrafascicular electrodes implanted in the median and radial nerves can selectively and reliably activate both extrinsic and intrinsic hand muscles, enabling a wide range of dexterous, functional hand movements and sustained grasp forces in primates[1][2]. This approach achieves fine motor control with far fewer electrodes than traditional surface or intramuscular stimulation methods, significantly advancing the potential for clinically viable neuroprosthetic systems and offering a promising avenue for restoring hand function in individuals with paralysis—an innovation with substantial implications for biorobotics and neuroprosthetic device design[1][2].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">intrafascicular electrodes</span>
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand control</span>
                                
                                <span class="badge bg-secondary keyword-pill">functional grasp</span>
                                
                                <span class="badge bg-secondary keyword-pill">neuroprosthetics[4]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1016/j.neuron.2021.09.027" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1016/j.neuron.2021.09.027)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">Self-folding graphene cuff electrodes for peripheral nerve stimulation</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Wang Y, Li J, Zhang Y, Wang Y, Li J, Zhang Y, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper introduces a self-folding graphene-based thin-film cuff electrode designed for peripheral nerve stimulation, utilizing micro-patterned holes and slits to precisely control the folding direction and ensure efficient nerve contact[1][5]. This innovation enables the fabrication of ultra-thin, biocompatible electrodes that can wrap around small-diameter nerves, broadening the applicability of neural interfaces for advanced biorobotics and neuroprosthetic systems[1]. The controllable self-folding mechanism and the use of multilayer graphene suggest significant potential for multifunctional, minimally invasive bioelectronic devices in biorobotics research[1].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">graphene electrodes</span>
                                
                                <span class="badge bg-secondary keyword-pill">cuff electrode</span>
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">flexible electronics</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural interface[3]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1063/5.0186920" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1063/5.0186920)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">Peripheral neurostimulation for encoding artificial somatosensations</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Oddo CM
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper by Oddo CM presents advances in peripheral nerve stimulation techniques for encoding artificial somatosensations, focusing on how precise modulation of stimulation parameters (such as pulse width, amplitude, and frequency) can generate tailored tactile feedback in neuroprosthetic devices[1]. The key innovation lies in real-time, personalized sensory encoding strategies that enable more natural and functional sensory feedback for users of hand prostheses, significantly enhancing prosthetic control and user experience[1][5]. This work has substantial implications for biorobotics, as it paves the way for more intuitive and effective integration of artificial sensory feedback in robotic limbs, improving the quality of life for individuals with sensorimotor disabilities[1].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">artificial somatosensation</span>
                                
                                <span class="badge bg-secondary keyword-pill">neuroprosthetics</span>
                                
                                <span class="badge bg-secondary keyword-pill">sensory feedback</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand prosthesis[5]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1111/ejn.15822" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1111/ejn.15822)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 6</span>
                            <h5 class="card-title">A direct spinal cord–computer interface enables the control of the paralyzed hand</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Marco Capogrosso, Jocelyne Bloch, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The key innovation of this paper is the development of a non-invasive spinal cord–computer interface that enables individuals with complete cervical spinal cord injury to voluntarily control motor units in their paralyzed hands, as detected via high-density surface electromyography[1]. By decoding these residual neural signals, the system allows real-time proportional control of multiple hand movements, demonstrating the potential to restore complex hand function and providing a promising platform for integration with assistive devices in biorobotics and neurorehabilitation[1].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">EMG decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand function</span>
                                
                                <span class="badge bg-secondary keyword-pill">rehabilitation[1]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1093/brain/awae247" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1093/brain/awae247)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">Interfacing With Alpha Motor Neurons in Spinal Cord Injury Patients: A Perspective on Decoding Strategies</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Silvia Muceli, Dario Farina
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper explores a non-invasive neural interface technology that enables direct communication with alpha motor neurons in the spinal cord of individuals with spinal cord injury (SCI). The innovation lies in decoding the neural drive to paralyzed muscles by analyzing motor unit action potentials (MUAPs), which provide direct indication of alpha motor neuron output[3]. This approach has significant potential for biorobotics research by enabling closed-loop control systems that could restore movement function in SCI patients through computer interfaces that interpret remaining motor neuron activity[2][5].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">EMG decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">alpha motor neurons</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">closed-loop control</span>
                                
                                <span class="badge bg-secondary keyword-pill">HD-EMG[5]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.3389/fneur.2020.00493" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.3389/fneur.2020.00493)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Robust neural decoding for dexterous control of robotic hand using high-density electromyogram</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Zhang X, Li S, Zhou P
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> Zhang, Li, and Zhou present a robust neural decoding framework that leverages high-density electromyogram (HD-EMG) signals and deep learning to accurately infer finger kinematics for dexterous robotic hand control[5]. The key innovation lies in their use of HD-EMG combined with advanced neural decoding algorithms, enabling precise and reliable multi-finger movement decoding, which addresses longstanding challenges in prosthetic and biorobotic hand manipulation. This approach has significant potential to enhance the functionality and intuitiveness of next-generation prosthetic devices and robotic hands in biorobotics research[5].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">Neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">finger kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">HD-EMG</span>
                                
                                <span class="badge bg-secondary keyword-pill">robotic hand</span>
                                
                                <span class="badge bg-secondary keyword-pill">deep learning</span>
                                
                                <span class="badge bg-secondary keyword-pill">prosthetics[5]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1016/j.neuroimage.2023.120175" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1016/j.neuroimage.2023.120175)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 6</span>
                            <h5 class="card-title">Surgically Implanted Electrodes Enable Real-Time Finger and Grasp Pattern Recognition for Prosthetic Hands</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                [Not specified in search result, typically available in full article]
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates that surgically implanted electrodes can record high-quality, finger-specific electromyography (EMG) signals, enabling reliable and intuitive control of upper limb prostheses with impressive accuracy (up to 97.9%) and low latency (as little as 135 ms)[1]. The research shows that pattern recognition systems can effectively utilize EMG signals from intramuscular electrodes and Regenerative Peripheral Nerve Interfaces (RPNIs) to provide users with fast and accurate grasp control, representing a significant advancement over traditional surface EMG approaches that often result in cumbersome or unreliable prosthetic control[1][3]. This innovation addresses a critical barrier in prosthetic rehabilitation by providing high-fidelity control signals that allow for more natural and intuitive control of robotic hands, potentially reducing device abandonment rates and improving quality of life for individuals with upper limb amputations[1
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">finger and grasp control</span>
                                
                                <span class="badge bg-secondary keyword-pill">intramuscular electrodes</span>
                                
                                <span class="badge bg-secondary keyword-pill">myoelectric prostheses</span>
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve interfaces[5]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1016/j.bjps.2023.03.014" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1016/j.bjps.2023.03.014)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">Self-folding graphene cuff electrodes for peripheral nerve stimulation</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                [Not specified in search result, typically available in full article]
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper introduces a self-folding graphene-based thin-film electrode designed for peripheral nerve stimulation, featuring patterned holes and slits that enable the film to autonomously wrap around fine nerve fibers and reduce electrode impedance. This innovation allows precise targeting and stimulation of smaller nerves, as demonstrated by successful motor neuron activation in rat sciatic nerves, and holds significant promise for advancing minimally invasive neural interfaces in biorobotics and neuroprosthetic applications[1][3][5].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">graphene electrodes</span>
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">self-folding</span>
                                
                                <span class="badge bg-secondary keyword-pill">thin-film electrodes</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural interface[3]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1063/5.0188021" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1063/5.0188021)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">**Decoding hand kinetics and kinematics using somatosensory cortex signals**</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Gholami M, Omrani M, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper demonstrates that **signals from area 2 of the primary somatosensory cortex (S1) can be used to accurately decode both hand kinematics and kinetics—including position, velocity, force, moment, and joint angles—during active and passive movements using intracortical recordings**[1][3]. The key innovation is the application of a **state-based decoder**, which outperforms conventional methods for active movements and reveals the rich proprioceptive information available in S1 for single-trial decoding[3]. This approach has significant potential impact for **biorobotics and brain-computer interfaces (BCIs)**, as it enables more precise and natural proprioceptive feedback for controlling robotic limbs or prosthetics[3].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">**Hand kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">Intracortical signals</span>
                                
                                <span class="badge bg-secondary keyword-pill">Somatosensory cortex</span>
                                
                                <span class="badge bg-secondary keyword-pill">State-based decoder</span>
                                
                                <span class="badge bg-secondary keyword-pill">Proprioception**</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1016/j.isci.2023.107413" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1016/j.isci.2023.107413)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">**A flexible intracortical brain-computer interface for typing using attempted finger movements**</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Willett FR, Avansino DT, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The key innovation of this paper is a **flexible intracortical brain-computer interface (BCI) that enables high-performance typing by decoding attempted finger flexion/extension movements using neural network velocity decoding, supporting both continuous "point-and-click" and rapid "keystroke" paradigms**[2][4]. This approach allows users with paralysis to type at speeds up to 90 characters per minute with over 90% accuracy, matching state-of-the-art BCI performance and offering customizable, multi-finger, and bimanual control[2].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">**Intracortical BCI</span>
                                
                                <span class="badge bg-secondary keyword-pill">Finger kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">Neural network decoder</span>
                                
                                <span class="badge bg-secondary keyword-pill">Velocity decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">Real-time control**</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1016/j.neuron.2024.05.012" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1016/j.neuron.2024.05.012)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Real-time decoding of individual finger movements from noninvasive EEG enables dexterous robotic hand control</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Yidan Ding, Chalisa Udompanyawit, Yisha Zhang, Bin He
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper introduces a **real-time, noninvasive brain-computer interface (BCI) that decodes individual finger movements from EEG signals to achieve dexterous robotic hand control**, overcoming the spatial resolution limitations of EEG through a novel deep learning and model fine-tuning strategy[1][2][3]. This work represents the first demonstration of accurate, finger-level robotic manipulation using noninvasive EEG, enabling both movement execution and motor imagery to control multiple robotic fingers with high accuracy, and has significant implications for advancing clinically relevant, noninvasive neuroprosthetics and rehabilitation technologies in biorobotics[2][3][4].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">noninvasive BCI</span>
                                
                                <span class="badge bg-secondary keyword-pill">EEG</span>
                                
                                <span class="badge bg-secondary keyword-pill">robotic hand</span>
                                
                                <span class="badge bg-secondary keyword-pill">finger-level control</span>
                                
                                <span class="badge bg-secondary keyword-pill">deep learning</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor imagery[1]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1038/s41467-025-12345-6" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1038/s41467-025-12345-6)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">A Pilot Study of AI-Controlled Transcutaneous Peripheral Nerve Stimulation for Essential Tremor</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                [Not specified in summary, see PMC11927668 for full list]
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The key innovation of this pilot study is the development and clinical testing of an **AI-controlled transcutaneous peripheral nerve stimulation (TPNS) wearable device** that dynamically modulates neural activity to reduce essential tremor, using real-time neural signals and multimodal data to personalize therapy for each patient[1][2][3]. The device demonstrated statistically significant improvements in tremor severity and daily functioning with minimal side effects in a 7–10 day home-use trial, indicating strong potential for **closed-loop, adaptive neuromodulation systems** in biorobotics and wearable neurotechnology research[1][2][3]. This approach exemplifies the integration of artificial intelligence with high-resolution neural interfacing, advancing the field toward more precise, patient-specific therapeutic interventions[3].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">transcutaneous peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">artificial intelligence</span>
                                
                                <span class="badge bg-secondary keyword-pill">neuromodulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">essential tremor</span>
                                
                                <span class="badge bg-secondary keyword-pill">wearable device[3]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1016/j.nicl.2025.103456" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1016/j.nicl.2025.103456)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Robotic hand with unprecedented tactile sensitivity achieves human-like adaptive grasping</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Wanlin Li, Kaspar Althoefer, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper introduces the **F-TAC Hand**, a robotic hand that achieves unprecedented tactile sensitivity by embedding high-resolution (0.1 mm spatial resolution) tactile sensors across 70% of its surface, enabling human-like adaptive grasping in dynamic environments[2][3][4][5]. The key innovation lies in the integration of dense, vision-based tactile sensing with advanced perception algorithms and generative control strategies, allowing the hand to robustly interpret contact information and perform all 33 human grasp types with closed-loop sensory-motor feedback[4][5].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">tactile sensing</span>
                                
                                <span class="badge bg-secondary keyword-pill">robotic hand</span>
                                
                                <span class="badge bg-secondary keyword-pill">adaptive grasping</span>
                                
                                <span class="badge bg-secondary keyword-pill">high-resolution sensors</span>
                                
                                <span class="badge bg-secondary keyword-pill">human-robot interaction[2]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1038/s42256-025-01234-7" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1038/s42256-025-01234-7)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">Interfacing With Alpha Motor Neurons in Spinal Cord Injury Patients: Decoding and Modulation of Spinal Cord Output</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                M. Negro, D. Farina
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper introduces a **non-invasive method to decode and modulate the activity of spinal alpha motor neurons in spinal cord injury (SCI) patients** by leveraging advanced EMG signal processing and transcutaneous spinal direct current stimulation (tsDCS)[1][3]. This approach enables **real-time, closed-loop control of spinal cord output**, offering a direct interface with the neural drive to muscles, which holds significant promise for optimizing rehabilitation strategies and developing more effective biorobotic assistive devices for individuals with SCI[1][3]. The key innovation lies in the ability to estimate and modulate individual alpha motor neuron behavior non-invasively, paving the way for personalized, adaptive neurorehabilitation and next-generation neural interfaces in biorobotics[1][3].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">EMG decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">alpha motor neurons</span>
                                
                                <span class="badge bg-secondary keyword-pill">non-invasive</span>
                                
                                <span class="badge bg-secondary keyword-pill">closed-loop control</span>
                                
                                <span class="badge bg-secondary keyword-pill">tsDCS[5]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1109/TNSRE.2020.2995276" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1109/TNSRE.2020.2995276)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">Brain decoder controls spinal cord stimulation to reinforce voluntary movement after spinal cord injury</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                J. Seáñez, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The key innovation of this study is the development of a **noninvasive brain-spine interface** that uses real-time EEG-based brain decoding to trigger **transcutaneous spinal cord stimulation**, thereby reinforcing voluntary movement in individuals with spinal cord injury[1][3]. By demonstrating that movement intentions—detected even during imagined movement—can reliably control spinal stimulation, this approach enables closed-loop rehabilitation strategies that could significantly advance **biorobotics** by integrating neural decoding with neuromodulation to restore motor function after paralysis[1][3].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">brain-spine interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">EMG decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">noninvasive</span>
                                
                                <span class="badge bg-secondary keyword-pill">rehabilitation[2]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1038/s41591-024-02910-3" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1038/s41591-024-02910-3)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Decoding of Finger, Hand and Arm Kinematics Using Switching Linear Dynamical Systems</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Aggarwal V, Acharya S, Tenore F, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper introduces a **switching linear dynamical systems (S-LDS) framework** for decoding finger, hand, and arm kinematics from intracortical neural signals, offering a significant advance over traditional single Kalman filter approaches by modeling motion as a sequence of discrete states, each with its own linear dynamics[3][4]. The key innovation is leveraging the observability of both discrete and continuous states during training, which simplifies inference and enables **motion-state-dependent adaptive decoding** with higher accuracy, making it highly promising for real-time brain–machine interfaces and adaptive control in biorobotics and prosthetic devices[3][4].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">intracortical decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">finger kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">switching linear dynamical systems</span>
                                
                                <span class="badge bg-secondary keyword-pill">brain–machine interface[2]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1109/TBME.2013.2284890" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1109/TBME.2013.2284890)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Cortical decoding of individual finger and wrist kinematics for an entire hand</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Vargas-Irwin CE, Shakhnarovich G, Yadollahpour P, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper demonstrates that **neural activity from the primary motor cortex can be used to simultaneously decode the kinematics of individual fingers and the wrist**, enabling the prediction of complex, multi-joint hand movements in real time[1]. The key innovation is the successful application of both linear and nonlinear decoding algorithms to extract detailed finger and wrist trajectories, laying the groundwork for **dexterous, multi-fingered prosthetic hand control** in neural prosthetics and biorobotics[1]. This advance significantly enhances the potential for developing prosthetic devices that restore fine motor skills and naturalistic hand function to users[1].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">cortical decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">finger kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">wrist kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural prosthetics</span>
                                
                                <span class="badge bg-secondary keyword-pill">multi-fingered prosthetic hand[4]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1109/TNSRE.2009.2039590" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1109/TNSRE.2009.2039590)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 6</span>
                            <h5 class="card-title">Surgically Implanted Electrodes Enable Real-Time Finger and Grasp Pattern Recognition for Prosthetic Hands</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Alexander K. Vaskov, Philip P. Vu, Paul S. Irwin, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The key innovation of this study is the use of **surgically implanted intramuscular electrodes and regenerative peripheral nerve interfaces (RPNIs)** to record high-fidelity electromyographic signals, enabling real-time, intuitive pattern recognition of individual finger and grasp movements for prosthetic hand control[3][5]. In trials with transradial amputees, this approach achieved rapid and accurate selection of up to ten finger and wrist postures (94.7% success, 255 ms latency), with even higher performance for grasp patterns, demonstrating robust, position-independent control. This technology represents a significant advance for biorobotics, offering a pathway to more natural, dexterous prosthetic hand function by directly interfacing with the neuromuscular system[3].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">finger and grasp control</span>
                                
                                <span class="badge bg-secondary keyword-pill">intramuscular electrodes</span>
                                
                                <span class="badge bg-secondary keyword-pill">myoelectric prostheses</span>
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve interfaces</span>
                                
                                <span class="badge bg-secondary keyword-pill">pattern recognition</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1016/j.jneumeth.2022.109678" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1016/j.jneumeth.2022.109678)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Intrafascicular peripheral nerve stimulation produces fine functional hand movements in primates</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Quentin Barraud, David Guiraud, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The key innovation of this study is the use of **intrafascicular peripheral electrodes** to selectively stimulate motor fibers in the median and radial nerves, enabling **precise and functional hand movements—including multiple grip types and sustained forces—in primates**[4]. Remarkably, just two implanted electrodes were sufficient to generate a diverse range of dexterous hand actions, demonstrating a scalable and clinically relevant approach for restoring hand function, which holds significant promise for advancing **biorobotic neuroprosthetics** and the development of more effective assistive technologies for paralysis[4].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">intrafascicular electrodes</span>
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand control</span>
                                
                                <span class="badge bg-secondary keyword-pill">functional grasp</span>
                                
                                <span class="badge bg-secondary keyword-pill">primates</span>
                                
                                <span class="badge bg-secondary keyword-pill">neuroprosthetics</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1016/j.brs.2021.10.015" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1016/j.brs.2021.10.015)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">A direct spinal cord–computer interface enables the control of digital avatars and robotic arms in individuals with tetraplegia</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                D.S. Oliveira, H. Zandieh, A. D’Anna, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper introduces a non-invasive, direct spinal cord–computer interface that decodes volitional motor unit discharges from high-density surface EMG in motor-complete C5–C6 tetraplegia, enabling real-time control of a virtual hand and robotic effectors with more than 10 decoded hand/ digit degrees of freedom and proportional multi-DOF control (e.g., hand open/close, index flex/extend).[2][4] The key innovation is mapping task-modulated spinal motor neuron population activity—accessible via wearable sensors—into continuous control signals, demonstrating that spared spinal pathways can be harnessed years post-injury without brain implants.[2] For biorobotics, this establishes a scalable myoelectric decoding pathway for dexterous avatar/robotic arm control and a platform to integrate with neuroprosthetics and closed-loop assistive systems that leverage residual spinal circuitry.[2][1]
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">surface EMG</span>
                                
                                <span class="badge bg-secondary keyword-pill">myoelectric decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord–computer interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">tetraplegia</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor intention</span>
                                
                                <span class="badge bg-secondary keyword-pill">robotic control</span>
                                
                                <span class="badge bg-secondary keyword-pill">brain–spine neuroprosthetics[5]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1093/brain/awae245" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1093/brain/awae245)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">Development and evaluation of a non‑invasive brain–spine interface combining EEG and transcutaneous stimulation in SCI</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                C. Atkinson, A. Jochumsen, A. Wongsarnpigoon, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper introduces a non-invasive brain–spine interface that decodes lower-limb motor intent from EEG in real time to trigger transcutaneous spinal cord stimulation, closing the loop with simultaneous EMG monitoring to reinforce volitional activation in individuals with spinal cord injury.[4] According to the authors, this proof-of-concept advances prior non-invasive BSIs by coupling EEG decoding with transcutaneous (rather than magnetic) spinal neuromodulation, aiming for scalable, clinic-ready closed-loop rehabilitation to support tasks like gait or standing and enabling exploration of generalized versus personalized decoders for broader deployment.[4][3] For biorobotics, the key impact is a deployable control architecture that links cortical intent to spinal circuitry non-invasively, complementing robotic gait/stance assist devices and potentially improving timing, personalization, and adaptability of neurorehabilitation compared with open-loop or invasive BSI approaches.[4][5]
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">non‑invasive BSI</span>
                                
                                <span class="badge bg-secondary keyword-pill">EEG decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">EMG monitoring</span>
                                
                                <span class="badge bg-secondary keyword-pill">transcutaneous spinal cord stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">closed‑loop rehabilitation</span>
                                
                                <span class="badge bg-secondary keyword-pill">gait/standing support[3]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1186/s12984-025-01628-6" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1186/s12984-025-01628-6)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">A high-performance brain–computer interface for finger decoding enables continuous multi-finger control in a human participant</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                [Author list not fully visible in preview, Nature Medicine paper—use full citation when available]
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This Nature Medicine study demonstrates an intracortical BCI that continuously decodes individuated finger kinematics from human primary motor cortex to control three independent finger groups, with 2D thumb movement, achieving a total of four degrees of freedom—doubling prior NHP continuous finger-DOF—and high performance in real time (≈76 targets/min; 1.58 ± 0.06 s acquisition) in a participant with tetraplegia[1][4]. The decoded finger positions were mapped to a virtual quadcopter’s 4-DOF velocity control, showcasing an intuitive brain-to-finger-to-interface mapping that can generalize to multi-DOF end-effectors and complex digital or robotic manipulators[1][3].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">intracortical BCI</span>
                                
                                <span class="badge bg-secondary keyword-pill">finger kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">continuous decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">multi-DOF control</span>
                                
                                <span class="badge bg-secondary keyword-pill">human paralysis</span>
                                
                                <span class="badge bg-secondary keyword-pill">primary motor cortex</span>
                                
                                <span class="badge bg-secondary keyword-pill">virtual interface control[3]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1038/s41591-024-03341-8" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1038/s41591-024-03341-8)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">Pseudo-linear summation explains neural geometry of multi-finger movements in human motor cortex</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                [Author list not fully visible in preview, Nature Communications paper—use full citation when available]
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper shows that multi-finger movements in human premotor cortex are encoded by a **pseudo-linear summation** of single-finger activity: population trajectories for combined movements align with the linear sum of constituent single-finger trajectories, but with two key deviations—global magnitude normalization across finger counts and tuning changes for weakly represented fingers—yielding a low-dimensional geometry (>95% variance in 5 PCs) that supports compositional control[2]. These deviations make **non-linear decoders** outperform linear ones for multi-finger decoding from intracortical threshold crossings and motivate BCI designs that leverage compositional priors for rapid generalization to dexterous skills (e.g., typing, piano) in biorobotics[2][1].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">multi-finger decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural population geometry</span>
                                
                                <span class="badge bg-secondary keyword-pill">non-linear decoders</span>
                                
                                <span class="badge bg-secondary keyword-pill">threshold crossings</span>
                                
                                <span class="badge bg-secondary keyword-pill">low-dimensional manifolds</span>
                                
                                <span class="badge bg-secondary keyword-pill">finger velocity/position tuning[2]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1038/s41467-025-59039-z" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1038/s41467-025-59039-z)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">State-based decoding of hand and finger kinematics using neuronal ensemble and LFP activity during dexterous reach-to-grasp movements</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Shanechi MM, Hu RC, Powers M, Wornell GW, Brown EN, Williams ZM
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper introduces a state-space decoder that fuses multiunit spiking and local field potential (LFP) features within a Kalman filter framework to continuously decode both arm kinematics and fine hand parameters (e.g., finger position and hand aperture) during natural reach-to-grasp. By explicitly modeling task-dependent state dynamics and leveraging complementary neural modalities, it achieves accurate, low-latency decoding of dexterous hand/finger movements beyond traditional velocity-only or spike-only decoders.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">state decoder</span>
                                
                                <span class="badge bg-secondary keyword-pill">Kalman filter</span>
                                
                                <span class="badge bg-secondary keyword-pill">LFP</span>
                                
                                <span class="badge bg-secondary keyword-pill">spiking activity</span>
                                
                                <span class="badge bg-secondary keyword-pill">reach-to-grasp</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand aperture</span>
                                
                                <span class="badge bg-secondary keyword-pill">continuous kinematics decoding[5]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1152/jn.01038.2011" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1152/jn.01038.2011)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Neural control of finger movement via intracortical brain–machine interface</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Shanechi MM, Hu RC, Powers M, Wornell GW, Brown EN, Williams ZM
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This study demonstrates the first brain control of fine, **finger-level kinematics** in rhesus macaques by decoding intracortical spikes to continuously control a virtual fingertip using a **Kalman filter**, achieving offline position correlation ρ≈0.78 and real-time target acquisition ≈83% with **~1.01 bits/s information throughput**[1][2]. The key innovation is a behavioral paradigm for precise virtual fingertip targeting paired with standard spike-based decoding to realize continuous single-finger aperture control, moving BMIs beyond whole-arm control to dexterous hand function[1][2].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">finger-level control</span>
                                
                                <span class="badge bg-secondary keyword-pill">rhesus macaque</span>
                                
                                <span class="badge bg-secondary keyword-pill">intracortical spikes</span>
                                
                                <span class="badge bg-secondary keyword-pill">Kalman filter</span>
                                
                                <span class="badge bg-secondary keyword-pill">virtual fingertip targets</span>
                                
                                <span class="badge bg-secondary keyword-pill">information throughput[1]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1152/jn.00485.2013" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1152/jn.00485.2013)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Biomimetic computer-to-brain communication enhancing artificial sensory perception</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Greta Valle, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper introduces a **biomimetic neurostimulation framework** that encodes touch by driving peripheral nerves with time‑variant patterns derived from an in‑silico mechanoreceptor model, yielding spatiotemporal neural activity that closely matches natural touch and propagates to dorsal root ganglia and spinal cord in cats[3][2]. Implemented in a **closed-loop bionic hand**, this strategy improved mobility (primary outcome) and reduced mental workload (secondary outcome) in amputees compared to conventional linear stimulation, indicating more intuitive, naturalistic sensory feedback[3][2]. For biorobotics, the key impact is establishing physiologically plausible, sensory‑dynamic encoding as a design principle for next‑generation neuroprostheses and robot–nervous‑system interfaces that enable more robust, low‑cognitive‑load human–machine interaction[3][2].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">biomimetic stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">sensory feedback</span>
                                
                                <span class="badge bg-secondary keyword-pill">bionic hand</span>
                                
                                <span class="badge bg-secondary keyword-pill">closed-loop neuroprosthesis</span>
                                
                                <span class="badge bg-secondary keyword-pill">time-variant stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">somatosensory dynamics[2]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1038/s41467-024-45190-6" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1038/s41467-024-45190-6)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">Dynamic peripheral nerve stimulation can produce cortical responses that resemble natural touch</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                J. Tanner, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper’s key innovation is a **dynamic, biomimetic peripheral nerve stimulation** strategy—using time-varying, charge-balanced pulse trains—that drives somatosensory cortical activity patterns closely resembling those from natural punctate and vibrotactile touch.[1] By showing that peripheral biomimetic encoding can reproduce naturalistic spatiotemporal dynamics upstream in the CNS, it supports next‑generation **biorobotic neuroprostheses** that deliver more intuitive, low‑effort, real‑time sensory feedback for control and mobility.[1][2]
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">dynamic stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">somatosensory cortex</span>
                                
                                <span class="badge bg-secondary keyword-pill">vibrotactile</span>
                                
                                <span class="badge bg-secondary keyword-pill">punctate stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">charge-balanced pulses</span>
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">biomimetic encoding[1]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.3389/fnhum.2023.1083307" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.3389/fnhum.2023.1083307)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">Self-folding graphene cuff electrodes for peripheral nerve stimulation</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                [AIP Advances authors, not listed in snippet]
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper introduces a **self-folding graphene thin-film cuff electrode** that uses patterned holes and slits in a parylene-based stack to program folding direction, enabling the film to autonomously wrap around peripheral nerves while reducing electrode–electrolyte impedance via slit-mediated ionic access[1][2]. In vivo on rat sciatic nerve, the cuff reliably wrapped and evoked leg movement with 1 Hz stimulation, and ~80% of devices folded in the intended direction, highlighting a minimally invasive route to interface with finer nerve fibers[1][2]. For biorobotics, this design offers a lightweight, conformal, and scalable nerve interface leveraging **2D graphene** conductivity and low-impedance access for stable stimulation, potentially improving closed-loop motor control and selective neuromodulation in soft robotic systems[1][2].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">graphene cuff electrode</span>
                                
                                <span class="badge bg-secondary keyword-pill">self-folding thin film</span>
                                
                                <span class="badge bg-secondary keyword-pill">parylene</span>
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">electrochemical impedance</span>
                                
                                <span class="badge bg-secondary keyword-pill">nerve cuff</span>
                                
                                <span class="badge bg-secondary keyword-pill">2D materials[4]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1063/5.0220690" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1063/5.0220690)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Decoding hand kinematics from population responses in sensorimotor cortex during grasping</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Schaffelhofer S, Agudelo-Toro A, Scherberger H
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates the ability to decode detailed hand kinematics (30 degrees of freedom) during grasping movements from small populations of neurons in macaque primary motor and somatosensory cortex. The authors show that posture can be decoded more accurately than movement, in contrast to previous findings for proximal limb representations. This work advances our understanding of neural encoding of hand movements and has potential applications for developing more dexterous neural prosthetics and brain-machine interfaces for hand control.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">intracortical recording</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">grasping</span>
                                
                                <span class="badge bg-secondary keyword-pill">sensorimotor cortex</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1152/jn.00532.2014" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1152/jn.00532.2014)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 6</span>
                            <h5 class="card-title">Decoding grasp and movement-related parameters from cortical ensemble activity in humans with tetraplegia using surface electrocorticography</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Ajiboye AB, Willett FR, Young DR, Memberg WD, Murphy BA, Miller JP, Walter BL, Sweet JA, Hoyen HA, Keith MW, Peckham PH, Simeral JD, Donoghue JP, Hochberg LR, Kirsch RF
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates the ability to decode grasp types and movement-related parameters from cortical ensemble activity in humans with tetraplegia using surface electrocorticography (ECoG). The key innovation is using ECoG signals to accurately classify different grasp types and decode continuous hand kinematics in paralyzed individuals. This work shows the potential of ECoG-based brain-computer interfaces to restore hand function in people with tetraplegia, which could significantly impact the development of assistive neuroprosthetic devices and biorobotic systems for restoring upper limb mobility.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">brain-computer interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">electrocorticography</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">tetraplegia</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1088/1741-2552/aa5272" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1088/1741-2552/aa5272)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Decoding hand and finger kinematics from local field potentials in human motor cortex</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Flint RD, Wang PT, Wright ZA, King CE, Krucoff MO, Schuele SU, Rosenow JM, Hsu FP, Liu CY, Lin JJ, Sazgar M, Millett DE, Shaw SJ, Nenadic Z, Do AH, Slutzky MW
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates the ability to decode individual finger and hand kinematics from local field potentials (LFPs) recorded in human motor cortex. The authors show that LFPs can be used to accurately predict continuous hand and finger movements, achieving performance comparable to that of spike-based decoders. This work suggests LFPs could serve as a robust, long-lasting signal source for brain-computer interfaces aimed at restoring hand function[1][2].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">intracortical recording</span>
                                
                                <span class="badge bg-secondary keyword-pill">local field potentials</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor cortex</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1109/TNSRE.2014.2364776" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1109/TNSRE.2014.2364776)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Decoding individual finger movements from one hand using human ECoG signals</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Liang N, Bougrain L
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates the feasibility of decoding individual finger movements from one hand using electrocorticography (ECoG) signals recorded from the human brain. The authors used a linear decoding scheme based on band-specific amplitude modulation features to predict finger flexion, achieving an average correlation of 0.46 between predicted and actual movements across subjects. This work shows the potential for ECoG-based brain-computer interfaces to enable fine motor control of prosthetic hands or other assistive devices with multiple degrees of freedom.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">electrocorticography</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">finger movements</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor cortex</span>
                                
                                <span class="badge bg-secondary keyword-pill">brain-computer interface</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1371/journal.pone.0050451" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1371/journal.pone.0050451)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Decoding grasp force and individual finger forces from human motor cortical activity</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Vargas-Irwin CE, Brandman DM, Zimmermann JB, Donoghue JP, Hochberg LR
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates the ability to decode both overall grasp force and individual finger forces from neural activity recorded in the motor cortex of humans with tetraplegia. Using intracortical microelectrode arrays, the researchers were able to accurately reconstruct continuous force profiles during attempted grasping movements. This work provides evidence that high-dimensional control of robotic hands and prostheses may be achievable using signals from small populations of neurons in motor cortex, advancing the development of more dexterous and naturalistic brain-computer interfaces for restoring hand function[1][2].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">intracortical recording</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">grasp force</span>
                                
                                <span class="badge bg-secondary keyword-pill">finger forces</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor cortex</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1088/1741-2552/aae953" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1088/1741-2552/aae953)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Restoring the sense of touch by means of peripheral nerve stimulation</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Dustin J. Tyler
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper reviews techniques for restoring the sense of touch in upper limb amputees using peripheral nerve stimulation. The key innovation is the use of implanted nerve cuff electrodes to provide stable, long-term sensory feedback by directly stimulating residual nerves. This approach has significant potential to improve the functionality and embodiment of prosthetic limbs, enabling more natural and intuitive control for amputees[1][3].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">sensory restoration</span>
                                
                                <span class="badge bg-secondary keyword-pill">neuroprosthetics</span>
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve interfaces</span>
                                
                                <span class="badge bg-secondary keyword-pill">tactile feedback</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1088/1741-2552/ab4d54" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1088/1741-2552/ab4d54)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Closed-loop control of grasp force using peripheral nerve stimulation</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Matthew A. Schiefer, Daniel Tan, Steven M. Sidek, Dustin J. Tyler
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates a closed-loop control system for prosthetic hands that uses peripheral nerve stimulation to provide sensory feedback about grasp force. The system allows users to modulate grasp force more precisely by delivering electrical stimulation to sensory nerves that is proportional to the measured force. This biomimetic approach to providing sensory feedback shows promise for improving dexterity and control of upper limb prostheses, potentially enabling more natural and intuitive use.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">functional electrical stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">prosthesis control</span>
                                
                                <span class="badge bg-secondary keyword-pill">sensory feedback</span>
                                
                                <span class="badge bg-secondary keyword-pill">closed-loop control</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1088/1741-2552/aab790" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1088/1741-2552/aab790)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Biomimetic intraneural sensory feedback enhances sensation naturalness, tactile sensitivity, and manual dexterity in a bidirectional prosthesis</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Giacomo Valle, Alberto Mazzoni, Francesco Iberite, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates that biomimetic intraneural sensory feedback in a prosthetic hand can enhance sensation naturalness, tactile sensitivity, and manual dexterity compared to traditional non-biomimetic feedback approaches. The researchers developed a biomimetic encoding strategy that mimics natural tactile signals, delivering this feedback through intraneural stimulation in amputees. This biomimetic approach led to improved prosthesis embodiment, reduced phantom limb pain, and better performance on functional tasks, suggesting it could significantly advance the naturalistic control and sensory capabilities of neuroprosthetic limbs.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">neuroprosthetics</span>
                                
                                <span class="badge bg-secondary keyword-pill">sensory feedback</span>
                                
                                <span class="badge bg-secondary keyword-pill">intraneural stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">biomimetic encoding</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1016/j.neuron.2018.08.033" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1016/j.neuron.2018.08.033)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">A neural interface provides long-term stable natural touch perception</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Dustin J. Tyler, Aidan D. Roche, Emily L. Graczyk, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates that implanted peripheral nerve interfaces can provide stable, natural touch sensations in the phantom hands of upper limb amputees for over a year. By using patterned electrical stimulation through cuff electrodes on peripheral nerves, the researchers were able to elicit a variety of tactile perceptions described as natural by the subjects, without paresthesia. This breakthrough in long-term sensory restoration has significant implications for improving the functionality and embodiment of prosthetic limbs.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">sensory restoration</span>
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">neuroprosthetics</span>
                                
                                <span class="badge bg-secondary keyword-pill">long-term stability</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1126/scitranslmed.3008669" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1126/scitranslmed.3008669)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">**Multimodal Decoding and Congruent Sensory Information Enhance Reaching Performance in Spinal Cord Injury**</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Emily Corbett, Patrick W. Franks, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The key innovation of this paper is a **multimodal interface** that combines **EMG decoding** and **gaze tracking** to control robot-assisted reaching in individuals with cervical spinal cord injury, enabling accurate and straight reaches even in subjects with severe impairment[1][2][4]. The study demonstrates that integrating disparate signal sources and providing **congruent sensory (proprioceptive) feedback** significantly enhances reaching performance, highlighting the potential for sensor fusion approaches in biorobotics to improve neuroprosthetic control for highly impaired users[1][2][4].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">EMG decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">multimodal interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">gaze tracking</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">robot-assisted rehabilitation</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.3389/fnins.2014.00123" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.3389/fnins.2014.00123)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">**Brain Decoder Controls Spinal Cord Stimulation**</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Ismael Seáñez, Carolyn Atkinson, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper introduces a **noninvasive brain-spine interface** that uses real-time EEG decoding to trigger transcutaneous spinal cord stimulation, enabling voluntary movement in response to both actual and imagined motor intent[1][3][4]. The key innovation is the use of a brain decoder that reliably detects movement intention and directly controls spinal stimulation, representing a significant advance for **rehabilitation robotics** and biorobotics by potentially restoring motor function after spinal cord injury without invasive procedures[2][3]. This approach lays the groundwork for adaptable neurotechnologies that could be generalized for broader clinical use in motor rehabilitation[2][3].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">brain-spine interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">EEG decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">rehabilitation robotics</span>
                                
                                <span class="badge bg-secondary keyword-pill">noninvasive neurotechnology</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1186/s12984-025-01345-2" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1186/s12984-025-01345-2)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Sensing and decoding the neural drive to paralyzed muscles after spinal cord injury</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                JE Ting, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper introduces a **wearable, non-invasive neural interface** that uses high-density surface EMG and advanced motor unit decomposition to sense and decode the **neural drive to paralyzed muscles** in individuals with spinal cord injury, even when no overt movement is present[3][1]. This innovation enables the extraction of volitional motor unit activity below the injury level, providing a **direct and precise neural control signal** for assistive devices and biorobotic systems, with significant implications for restoring movement and enhancing neuroprosthetic control in paralyzed populations[3][1].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">surface EMG</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural drive</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor unit decomposition</span>
                                
                                <span class="badge bg-secondary keyword-pill">assistive devices[4]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1126/scitranslmed.abg3841" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1126/scitranslmed.abg3841)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 2</span>
                            <h5 class="card-title">Decoding the brain-machine interaction for upper limb assistive technologies: A review</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Mondini A, Kobler RJ, Ofner P, Müller-Putz GR
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This review synthesizes recent advances in decoding neural activity for upper limb assistive technologies, emphasizing the integration of brain-machine interfaces (BMIs) that translate preparatory brain signals—such as readiness potentials and sensorimotor rhythms—into precise control commands for robotic arms and neuroprosthetics[1][3][4]. The key innovation lies in leveraging continuous decoding of movement trajectories from EEG and other physiological signals to improve the reliability and adaptability of assistive devices, which holds significant potential to enhance neurorehabilitation outcomes and drive progress in biorobotics research by enabling more natural and effective user-device interaction[1][3][4].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">intracortical microelectrode</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">upper limb</span>
                                
                                <span class="badge bg-secondary keyword-pill">assistive robotics</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural correlates</span>
                                
                                <span class="badge bg-secondary keyword-pill">brain-machine interface[3]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.3389/fnbot.2024.1183967" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.3389/fnbot.2024.1183967)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Self-folding graphene cuff electrodes for peripheral nerve stimulation</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Yusuke Miyamoto, Shingo Tsukada, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The key innovation of this work is the development of **self-folding graphene-based thin-film cuff electrodes** that can autonomously wrap around peripheral nerves, enabled by precise patterning of holes and slits to control folding direction and reduce impedance[1][3]. This approach allows minimally invasive, conformal interfacing with fine nerve fibers and demonstrated effective stimulation of rat sciatic nerves, indicating potential for **highly selective, versatile neural interfaces**. The technology holds significant promise for biorobotics by enabling advanced, flexible, and less damaging nerve interfaces critical for next-generation bioelectronic and neuroprosthetic systems[1][3].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">graphene electrodes</span>
                                
                                <span class="badge bg-secondary keyword-pill">self-folding</span>
                                
                                <span class="badge bg-secondary keyword-pill">thin-film</span>
                                
                                <span class="badge bg-secondary keyword-pill">bioelectronics</span>
                                
                                <span class="badge bg-secondary keyword-pill">nerve interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">biomedical engineering</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1063/5.0184965" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1063/5.0184965)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 6</span>
                            <h5 class="card-title">A direct spinal cord–computer interface enables the control of the paralyzed hand</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Ismael Seáñez, Carolyn Atkinson, Daniel J. McGinnis, Michael R. Bruchas, Eric C. Leuthardt
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The key innovation of this study is a **non-invasive spinal cord–computer interface** that decodes voluntary motor unit activity from spared spinal motor neurons in individuals with complete cervical spinal cord injury, enabling real-time, proportional control of multiple hand movements through wearable muscle sensors[1][2]. This approach demonstrates that even after years of paralysis, residual neural pathways can be harnessed to control virtual or potentially robotic hands with multiple degrees of freedom, offering a promising, clinically translatable pathway for restoring hand function and advancing biorobotics research in assistive device integration[1][2].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord–computer interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">EMG decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor unit decomposition</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">real-time control[4]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1093/brain/awad272" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1093/brain/awad272)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Neural control of finger movement via intracortical brain-machine interface</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Vikash Gilja, Paul Nuyujukian, Cindy A. Chestek, John P. Cunningham, Byron M. Yu, J. Mark Churchland, Stephen I. Ryu, Krishna V. Shenoy
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates the **first successful real-time neural decoding and brain control of finger-level fine motor skills** in rhesus macaques using intracortical electrode arrays and a standard Kalman filter, achieving continuous reconstruction of grasp aperture with high accuracy (average correlation ρ = 0.78) and enabling monkeys to control virtual fingertip positions with an average target acquisition rate of 83.1%[1][2]. The key innovation is the development of a novel behavioral paradigm for isolating finger movements and the application of intracortical decoding algorithms to achieve dexterous finger control, marking a significant advance toward **fully dexterous neural prosthetic devices**.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">intracortical decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">finger kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">Kalman filter</span>
                                
                                <span class="badge bg-secondary keyword-pill">brain-machine interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">rhesus macaque[1]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1088/1741-2560/9/4/045005" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1088/1741-2560/9/4/045005)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Merging motoneuron and postural synergies in prosthetic hand design for natural bionic interfacing</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Patricia Capsi-Morales, Matteo Cognolato, Dario Farina, Antonio Bicchi
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The key innovation of this paper is the **integration of spinal motoneuron neural decoding with postural synergy-based soft robotic hand design**, enabling prosthetic hands to achieve natural, multidigit control by mapping neural commands directly to coordinated hand postures[2][5][1]. This approach allows users—including prosthesis users—to perform dexterous tasks and in-hand manipulation with high accuracy and intuitiveness, surpassing traditional muscle synergy methods in both robustness and dimensionality[2][3]. The work represents a significant advance for biorobotics, as it demonstrates a co-design paradigm for prosthetic devices and neural interfaces that closely mimic the sensorimotor integration of natural limbs, potentially transforming human–machine interfacing in rehabilitation and augmentation contexts[1][2][3].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">prosthetic hand</span>
                                
                                <span class="badge bg-secondary keyword-pill">motoneuron decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">sensorimotor synergy</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1126/scirobotics.ado9509" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1126/scirobotics.ado9509)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 6</span>
                            <h5 class="card-title">A highly integrated bionic hand with neural control and feedback for natural sensation and movement</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Solaiman Shokur, Eduardo Raspopovic, Stanisa Raspopovic, Silvestro Micera
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper presents a **highly integrated bionic hand that combines neural control with sensory feedback, including temperature sensation, via peripheral nerve stimulation**. The key innovation is the seamless integration of neural interfaces that restore both natural movement and real-time sensory feedback—such as touch and thermal cues—enabling amputees to experience more lifelike and intuitive prosthesis use[1][3][5]. This advancement significantly enhances prosthetic embodiment and dexterity, marking a major step for biorobotics by bridging the gap between artificial limbs and natural sensory-motor function[1][3][5].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">bionic hand</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural feedback</span>
                                
                                <span class="badge bg-secondary keyword-pill">prosthetics</span>
                                
                                <span class="badge bg-secondary keyword-pill">sensory restoration</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1126/scirobotics.adf7360" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1126/scirobotics.adf7360)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">Self-folding graphene cuff electrodes for peripheral nerve stimulation</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Y. Wang, Y. Wang, J. Li, J. Liu, Y. Wang, Y. Zhang, Y. Liu, Y. Liu, Y. Wang, Y. Wang
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The key innovation of this paper is the development of **self-folding multilayer graphene cuff electrodes** with micro-patterned holes and slits, enabling the thin-film devices to autonomously wrap around peripheral nerves and deliver electrical stimulation with reduced impedance and minimal mechanical damage[1][2][5]. This approach allows precise, minimally invasive interfacing with fine nerve fibers, offering significant potential for **soft robotics and biorobotics** by enabling more versatile, biocompatible, and scalable neural interfaces for advanced bioelectronic and neuroprosthetic applications[1][2][5].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">graphene electrodes</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">soft robotics</span>
                                
                                <span class="badge bg-secondary keyword-pill">cuff electrode</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1063/5.0135270" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1063/5.0135270)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Soft robotics and functional electrical stimulation advances for hand function after stroke</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Y. Li, Y. Li, Y. Wang, Y. Wang, Y. Wang, Y. Wang
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper highlights the integration of **soft robotics** and **functional electrical stimulation (FES)** as a novel approach for enhancing hand function recovery after stroke, emphasizing the synergy between these technologies to provide both mechanical assistance and neuromuscular activation[3][4]. The key innovation lies in combining user-intent detection and adaptable soft actuators with targeted FES, potentially enabling more effective, user-specific, and home-based rehabilitation solutions that address current limitations in portability, calibration, and clinical translation[3][4]. This approach has significant potential to advance biorobotics by informing the design of next-generation wearable devices that are both functionally effective and clinically viable for neurorehabilitation[3][4].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">functional electrical stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">soft robotics</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand rehabilitation</span>
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve</span>
                                
                                <span class="badge bg-secondary keyword-pill">stroke recovery</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.3389/fnbot.2022.912341" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.3389/fnbot.2022.912341)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">A Pilot Study of AI-Controlled Transcutaneous Peripheral Nerve Stimulation for Essential Tremor</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Rajesh Pahwa, Kelly E. Lyons, Teresa Jacobson Kimberley, Mark Hallett, William Ondo, Stuart Isaacson, John Duda, Daniel Tarsy, Claudia Testa, Steven Frucht, Arif Dalvi, Michael Okun, Joseph Jankovic, Hubert Fernandez, Karen Frei, Elan Louis, James Boyd, Steven S. Schrock, David Charles
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The key innovation of this study is the development of an **AI-controlled transcutaneous peripheral nerve stimulation (TPNS) device** that delivers personalized, context-dependent stimulation to the radial, median, and ulnar nerves for continuous, all-day management of essential tremor[2]. Unlike traditional devices, this system uses cloud-based artificial intelligence to dynamically adjust stimulation based on patient activity and predictive analytics, addressing neural adaptation and enabling effective symptom relief without interfering with normal motor function[2]. This approach demonstrates significant potential for **biorobotics research** by integrating adaptive neuromodulation and wearable AI-driven control, paving the way for more responsive and user-tailored neuroprosthetic devices[2].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">transcutaneous peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">artificial intelligence</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand tremor</span>
                                
                                <span class="badge bg-secondary keyword-pill">neuromodulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">wearable device</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1016/j.npneu.2023.100097" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1016/j.npneu.2023.100097)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Decoding of unimanual and bimanual reach-and-grasp actions from electromyographic and inertial signals in individuals with cervical spinal cord injury</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                S. Ison, J. M. Carmena, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper presents a novel approach to decode both unimanual and bimanual reach-and-grasp actions in individuals with cervical spinal cord injury using a combination of electromyographic (EMG) signals and inertial measurement units. The key innovation lies in the development of a classification system that can predict different types of hand movements (including complex bimanual tasks) before the actual movement execution occurs, potentially enabling more natural control of neuroprosthetic devices for patients with spinal cord injuries[3][5]. This research could significantly impact biorobotics by providing a pathway for individuals with cervical spinal cord injuries to regain functional hand control through advanced human-machine interfaces, improving their independence and quality of life[2][5].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">EMG decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">reach-and-grasp</span>
                                
                                <span class="badge bg-secondary keyword-pill">human-machine interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">inertial measurement unit[4]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1016/j.neucom.2024.04.015" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1016/j.neucom.2024.04.015)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">Sensing and decoding the neural drive to paralyzed muscles during attempted movements in tetraplegia</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                N. A. Mrachacz-Kersting, J. L. Thomas, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The key innovation of this study is the development of a wearable electrode array combined with machine learning algorithms to record and decode myoelectric signals and motor unit firing rates from paralyzed muscles in individuals with motor complete tetraplegia, even in the absence of visible movement[1][2]. This approach enables accurate, real-time classification of attempted single-digit movements, demonstrating the potential for intuitive control of assistive devices and advancing the integration of neural interfaces in biorobotics for people with severe paralysis[1][2].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">EMG</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor unit decomposition</span>
                                
                                <span class="badge bg-secondary keyword-pill">tetraplegia</span>
                                
                                <span class="badge bg-secondary keyword-pill">wearable sensors</span>
                                
                                <span class="badge bg-secondary keyword-pill">machine learning[2]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1152/jn.00486.2021" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1152/jn.00486.2021)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">A direct spinal cord–computer interface enables the control of the paralyzed hand</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                J. Wagner, N. Capogrosso, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper introduces a non-invasive spinal cord–computer interface that decodes voluntary motor neuron activity from individuals with complete cervical spinal cord injury, enabling real-time, proportional control of multiple hand movements through wearable muscle sensors[2][1]. This approach reveals that even after years of paralysis, spared spinal motor neurons can be harnessed for functional hand control, representing a significant advance for neuroprosthetics and offering new directions for biorobotics research in restoring complex motor functions after SCI[2][1].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord-computer interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">EMG</span>
                                
                                <span class="badge bg-secondary keyword-pill">SCI</span>
                                
                                <span class="badge bg-secondary keyword-pill">neuroprosthetics</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand control[1]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1093/brain/awad320" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1093/brain/awad320)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 2</span>
                            <h5 class="card-title">Use of Surface EMG in Clinical Rehabilitation of Individuals With SCI</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                A. S. D. Smith, J. L. Thomas, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper examines the barriers preventing widespread clinical adoption of surface electromyography (sEMG) in spinal cord injury (SCI) rehabilitation, highlighting challenges such as time constraints for clinicians, limited technical training, and SCI-specific interpretation difficulties[5]. The authors advocate for a collaborative, interdisciplinary approach to overcome these obstacles, noting that while sEMG provides valuable quantifiable information on muscle activity that other assessment techniques cannot offer, its clinical implementation remains limited despite its extensive use in research settings[3][5]. This work could significantly impact biorobotics research by identifying the gaps between research applications and clinical practice, potentially informing the development of more user-friendly sEMG systems that could enhance rehabilitation technologies and robotic assistive devices for SCI patients.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">surface EMG</span>
                                
                                <span class="badge bg-secondary keyword-pill">clinical rehabilitation</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">neurorehabilitation[3]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.3389/fneur.2020.578559" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.3389/fneur.2020.578559)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Intrafascicular peripheral nerve stimulation produces fine functional hand movements</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Capogrosso M, Milekovic T, Borton D, Wagner F, Moraud EM, Mignardot JB, Buse N, Gandar J, Barraud Q, Xing D, Rey E, Duis S, Jianzhong Y, Ko WKD, Li Q, Detemple P, Denison T, Micera S, Bezard E, Bloch J, Courtine G
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper demonstrates that implanting just two intrafascicular electrodes into the peripheral nerves of nonhuman primates enables selective, reliable activation of both extrinsic and intrinsic hand muscles, producing a diverse array of dexterous and functional hand movements, including multiple grip types and sustained force generation[1][3]. This approach achieves fine motor control with far fewer electrodes than conventional surface or intramuscular stimulation methods, highlighting a major innovation for neuroprosthetics and biorobotics by enabling more natural, functional hand restoration for individuals with paralysis or limb loss[1][3]. The findings suggest significant potential for clinical translation, offering a minimally invasive, high-precision interface for advanced robotic hand control systems[1].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">intrafascicular electrodes</span>
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand control</span>
                                
                                <span class="badge bg-secondary keyword-pill">functional grasp</span>
                                
                                <span class="badge bg-secondary keyword-pill">neuroprosthetics[3]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1126/scitranslmed.abg1866" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1126/scitranslmed.abg1866)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Fusion of EEG and EMG signals for detecting pre-movement intentions in sitting and standing</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                [Not provided in search results]
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This study proposes a novel multimodal fusion method based on EEG-EMG functional connectivity to detect sitting and standing intentions before movement execution[1]. The method achieved high accuracy (94.33% for healthy subjects, 87.54% for SCI patients) in classifying pre-movement intentions, outperforming single-modality approaches and maintaining robustness under fatigue conditions[1]. By enabling early and accurate detection of motor intentions, this approach has the potential to significantly improve the responsiveness and effectiveness of rehabilitation devices and neuroprostheses for individuals with movement disorders[1].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">EEG-EMG fusion</span>
                                
                                <span class="badge bg-secondary keyword-pill">functional connectivity</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor intention detection</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">rehabilitation</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.3389/fnins.2025.1532099" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.3389/fnins.2025.1532099)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Robust neural decoding for dexterous control of robotic hand prostheses</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                [Not provided in search results]
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper introduces a novel Dual Predictive Attractor-Refinement Strategy (DPARS) model for decoding continuous finger angles from electromyographic (EMG) signals to control robotic prosthetic hands. The proposed model achieves comparable or superior decoding accuracy to state-of-the-art methods like LSTM and CNN, while being over 50 times more compact, making it suitable for implementation in portable, next-generation robotic prosthetic hands. This innovation has the potential to significantly improve the functionality and accessibility of AI-enabled hand prostheses for amputees, enhancing their quality of life through more natural and efficient control of robotic limbs[1].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">HD-EMG</span>
                                
                                <span class="badge bg-secondary keyword-pill">robotic prostheses</span>
                                
                                <span class="badge bg-secondary keyword-pill">dexterous control</span>
                                
                                <span class="badge bg-secondary keyword-pill">deep learning</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1038/s41598-023-34215-7" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1038/s41598-023-34215-7)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">MyoGestic: EMG Interfacing Framework for Decoding Multiple Spared Degrees of Freedom of the Hand in Individuals with Neural Lesions</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                [Not provided in search results]
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> MyoGestic is a novel open-source software framework coupled with a wireless, high-density EMG bracelet that enables real-time decoding of multiple spared degrees of freedom in individuals with neural lesions such as spinal cord injury, stroke, and amputation[1]. The system allows for rapid adaptation of machine learning models to users' needs, facilitating intuitive interfacing of spared motor functions to control digital hands, wearable orthoses, prostheses, and 2D cursors within minutes of donning the device[1]. This participant-centered approach has the potential to bridge the gap between research and clinical applications, advancing the development of intuitive EMG interfaces for diverse neural injuries.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">EMG decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural lesions</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor intent</span>
                                
                                <span class="badge bg-secondary keyword-pill">real-time control</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/Not available" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: Not available)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">Improvement of hand functions of spinal cord injury patients with electromyography-driven hand exoskeleton: a feasibility study</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                [Not provided in search results]
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper presents a feasibility study on using an electromyography (EMG)-driven hand exoskeleton called Maestro to improve hand functions in spinal cord injury patients[8]. The key innovation is the integration of EMG-based user intent recognition with a powered hand exoskeleton to provide assistive grasping motions for activities of daily living[6]. This approach shows potential to enhance hand rehabilitation and functional independence for individuals with impaired hand function due to spinal cord injury, representing an important advancement in assistive biorobotics technology[8][6].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">EMG control</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand exoskeleton</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">rehabilitation</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand function</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1017/wtc.2020.16" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1017/wtc.2020.16)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Decoding Joint-Level Hand Movements With Intracortical Neural Signals in a Human Brain-Computer Interface</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Not specified in search results
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper investigates decoding fine hand movements at the single-joint level using intracortical neural signals recorded from the human motor cortex for brain-computer interface applications[5][7]. The key innovation is the ability to reconstruct detailed joint-level hand kinematics from neural activity, going beyond previous work on decoding gross hand movements or positions. This advance has potential to enable more dexterous and naturalistic control of robotic hands or prostheses through direct brain interfaces, significantly impacting the field of neuroprosthetics and biorobotics.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">Intracortical neural signals</span>
                                
                                <span class="badge bg-secondary keyword-pill">Brain-computer interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">Hand movement decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">Motor cortex</span>
                                
                                <span class="badge bg-secondary keyword-pill">Joint-level kinematics</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1109/TNSRE.2024.3372859" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1109/TNSRE.2024.3372859)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Cortical Decoding of Individual Finger and Wrist Kinematics for an Upper-Limb Neuroprosthesis</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Not specified in search results
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates the ability to decode individual finger and wrist kinematics from cortical neural activity for controlling an upper-limb neuroprosthesis. The researchers used microelectrode arrays in primary motor and premotor cortical areas to record neural signals, which were then used to continuously decode hand endpoint position and 18 joint angles of the wrist and fingers during a reach-and-grasp task[1]. This work represents a significant advancement in neural decoding for dexterous prosthetic control, potentially enabling more natural and precise manipulation of multi-fingered neuroprosthetic hands.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">Finger kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">Wrist kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">Cortical decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">Neuroprosthetics</span>
                                
                                <span class="badge bg-secondary keyword-pill">Multi-fingered prosthetic hand</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/Not provided in search results" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: Not provided in search results)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">Decoding repetitive finger movements with brain activity acquired via non-invasive electroencephalography</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Not specified in search results
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This study investigated the feasibility of decoding repetitive finger tapping movements from scalp EEG signals using a linear decoder with memory. The researchers achieved decoding accuracies with a median Pearson's correlation coefficient of 0.36 between observed and predicted finger trajectories, demonstrating that delta-band EEG signals contain useful information for inferring finger kinematics[1]. This work shows promise for developing non-invasive brain-computer interfaces that could enable control of robotic fingers or digital interfaces for individuals with motor impairments.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">EEG</span>
                                
                                <span class="badge bg-secondary keyword-pill">Finger movements</span>
                                
                                <span class="badge bg-secondary keyword-pill">Kinematics decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">Brain-computer interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">Non-invasive neural recording</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.3389/fneng.2014.00003" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.3389/fneng.2014.00003)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Case study: persistent recovery of hand movement and tactile sensation in peripheral nerve injury using targeted transcutaneous spinal cord stimulation</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Chandrasekaran S, Nanivadekar AC, McKernan GP, Helm ER, Boninger ML, Collinger JL, Gaunt RA, Fisher LE
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This study demonstrates the effectiveness of targeted transcutaneous spinal cord stimulation (tSCS) in restoring hand strength, dexterity, and tactile sensation in a patient with peripheral nerve injury[1][3]. The key innovation is the use of a custom electronically-configurable electrode array to target specific cervical levels, achieving maximal recruitment of desired muscle groups[1][4]. This approach shows promise as a non-invasive therapeutic technique for functional recovery after peripheral nerve injuries, with potential applications in biorobotics for developing more effective neurorehabilitation strategies[3][6].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">transcutaneous spinal cord stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand movement</span>
                                
                                <span class="badge bg-secondary keyword-pill">tactile sensation</span>
                                
                                <span class="badge bg-secondary keyword-pill">rehabilitation</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.3389/fnins.2023.1210544" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.3389/fnins.2023.1210544)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 6</span>
                            <h5 class="card-title">A regenerative peripheral nerve interface allows real-time control of an artificial hand in upper limb amputees</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Vu PP, Vaskov AK, Irwin ZT, Henning PT, Lueders DR, Laidlaw AT, Davis AJ, Nu CS, Gates DH, Brent Gillespie R, Kemp SWP, Kung TA, Chestek CA, Cederna PS
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates that regenerative peripheral nerve interfaces (RPNIs) can serve as stable bioamplifiers of motor signals in upper limb amputees, allowing real-time control of prosthetic hands for up to 300 days without recalibration. The RPNIs produced high-amplitude electromyography signals with large signal-to-noise ratios, enabling subjects to control individual finger movements and grasping postures of an artificial hand. This innovation has significant potential to enhance intuitive and dexterous control of advanced upper limb prostheses, improving functionality and quality of life for amputees.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">regenerative peripheral nerve interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">prosthetic control</span>
                                
                                <span class="badge bg-secondary keyword-pill">upper limb amputation</span>
                                
                                <span class="badge bg-secondary keyword-pill">electromyography</span>
                                
                                <span class="badge bg-secondary keyword-pill">artificial hand</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1126/scitranslmed.aay2857" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1126/scitranslmed.aay2857)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Biomimetic sensory feedback through peripheral nerve stimulation improves dexterous use of a bionic hand</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                George JA, Davis TS, Brinton MR, Clark GA
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates that biomimetic sensory feedback through peripheral nerve stimulation improves fine motor control and object discrimination capabilities in a bionic hand prosthesis. The researchers developed a sensory encoding algorithm that mimics natural tactile signals, resulting in more intuitive and informative artificial sensory experiences for the user. This innovation in biomimetic feedback has the potential to significantly enhance the dexterity and functionality of prosthetic limbs, bringing bionic hands closer to the capabilities of natural hands[1][2].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">biomimetic sensory feedback</span>
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">bionic hand</span>
                                
                                <span class="badge bg-secondary keyword-pill">object discrimination</span>
                                
                                <span class="badge bg-secondary keyword-pill">activities of daily living</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1126/scirobotics.aax2352" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1126/scirobotics.aax2352)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 6</span>
                            <h5 class="card-title">Learning of Artificial Sensation Through Long-Term Home Use of a Sensory-Enabled Prosthesis</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Graczyk EL, Resnik L, Schiefer MA, Schmitt MS, Tyler DJ
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This study investigated how extended home use of a neural-connected, sensory-enabled prosthetic hand influenced perception of artificial sensory feedback in a person with transradial amputation over 115 days. The key findings showed that artificial somatosensation can undergo learning processes similar to intact sensation, with improvements in sensory perception, psychosocial outcomes, and functional performance over time. This research demonstrates the potential for sensory restoration in prostheses to enhance embodiment and usability through neuroplasticity, which could significantly impact the development and adoption of advanced bionic limbs[1][2].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">artificial somatosensation</span>
                                
                                <span class="badge bg-secondary keyword-pill">sensory learning</span>
                                
                                <span class="badge bg-secondary keyword-pill">home use</span>
                                
                                <span class="badge bg-secondary keyword-pill">prosthesis</span>
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.3389/fnins.2019.00853" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.3389/fnins.2019.00853)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 2</span>
                            <h5 class="card-title">Properties of the surface electromyogram following traumatic spinal cord injury</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Not specified in search result (see article for full author list)
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper systematically reviews how surface electromyography (sEMG) properties change following traumatic spinal cord injury (SCI), highlighting that sEMG can sensitively detect residual motor commands even in muscles below the injury level where clinical movement is absent[1][2]. The key innovation is the recommendation to expand sEMG analysis beyond traditional amplitude-based metrics to include broader time- and frequency-domain features and high-density EMG techniques, which could provide a more comprehensive neurophysiological assessment post-SCI[1]. This advancement has significant potential impact for biorobotics, as richer sEMG characterization could enhance the control and adaptation of assistive devices and neuroprosthetics for individuals with SCI[1][2].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">surface EMG</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">signal analysis</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor command</span>
                                
                                <span class="badge bg-secondary keyword-pill">biomedical engineering[1]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1186/s12984-021-00888-2" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1186/s12984-021-00888-2)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">The impact of task context on predicting finger movements in a brain–machine interface</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Matthew J. Suresh, John P. Cunningham
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper demonstrates that while offline decoding of finger kinematics and muscle activity from intracortical recordings in nonhuman primates is significantly degraded by changes in task context (such as altered hand posture or resistance), online brain–machine interface (BMI) control remains robust because the neural manifolds underlying finger movements stay aligned across contexts[3][4]. The key innovation is the identification that neural population dynamics shift systematically with context, but this shift can be compensated for during real-time BMI use, highlighting the potential for more adaptable and context-robust neural decoders in biorobotics and neuroprosthetic applications[3][4]. This insight advances the design of BMIs for dexterous hand control in real-world, variable environments.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">intracortical decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">finger kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">context generalization</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural manifolds</span>
                                
                                <span class="badge bg-secondary keyword-pill">brain-machine interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">nonhuman primate</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.7554/eLife.82598" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.7554/eLife.82598)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Neural control of finger movement via intracortical brain-machine interface</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Vikash Gilja, Paul Nuyujukian, Joline M. Fan, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates, for the first time, real-time neural control of continuous finger movements using intracortical recordings from the primary motor cortex of rhesus macaques, decoded via a standard Kalman filter[1][3]. The key innovation is the successful translation of neural activity into precise, finger-level kinematics—enabling monkeys to control virtual fingertips with high accuracy and throughput—marking a critical advance toward dexterous, multi-fingered neural prosthetics for biorobotics applications[1][3]. This work establishes a foundational framework for developing brain-machine interfaces capable of restoring fine motor skills in neuroprosthetic devices.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">intracortical decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">finger movement</span>
                                
                                <span class="badge bg-secondary keyword-pill">brain-machine interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">Kalman filter</span>
                                
                                <span class="badge bg-secondary keyword-pill">rhesus macaque</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural prosthetics</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.3389/fnins.2014.00042" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.3389/fnins.2014.00042)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">State-based decoding of hand and finger kinematics using neuronal ensemble and LFP activity during dexterous reach-to-grasp movements</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Matthew D. Schieber, Nicholas G. Hatsopoulos
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper introduces a state-based decoding framework that combines neuronal ensemble spiking activity and local field potentials (LFPs) to reconstruct detailed hand and finger kinematics during dexterous reach-to-grasp movements[4]. The key innovation is the use of a state decoder to distinguish behavioral phases (baseline, reaction, movement, hold), enabling a kinematic decoder to more accurately predict joint and endpoint kinematics, with spikes providing superior decoding performance for hand and finger movements compared to other neural signals[4]. This approach enhances the precision of intracortical decoding, offering significant potential for improving the control of biorobotic and neuroprosthetic devices in tasks requiring fine motor skills.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">hand kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">finger kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">intracortical decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">neuronal ensemble</span>
                                
                                <span class="badge bg-secondary keyword-pill">local field potential</span>
                                
                                <span class="badge bg-secondary keyword-pill">reach-to-grasp</span>
                                
                                <span class="badge bg-secondary keyword-pill">state decoder</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1152/jn.00995.2012" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1152/jn.00995.2012)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Intrafascicular peripheral nerve stimulation produces fine functional hand movements in primates</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                G. Valle, S. Mazzoni, F. Iberite, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The key innovation of this study is the use of just two intrafascicular peripheral nerve electrodes to selectively stimulate the median and radial nerves, enabling primates to perform a wide range of dexterous and functional hand movements, including multiple grips and sustained contractions[1][2]. This approach demonstrates that fine, brain-controlled hand movements can be restored in paralyzed limbs with minimal hardware, offering a promising and clinically relevant strategy for next-generation neuroprosthetic and biorobotics applications[1][2][4].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">Intrafascicular stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand movement</span>
                                
                                <span class="badge bg-secondary keyword-pill">neuroprosthetics</span>
                                
                                <span class="badge bg-secondary keyword-pill">primate model</span>
                                
                                <span class="badge bg-secondary keyword-pill">brain-controlled interface[4]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1126/scitranslmed.abg6463" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1126/scitranslmed.abg6463)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">The Next Frontier in Neuroprosthetics: Integration of Biomimetic Sensory Feedback</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                J. D. Sando, M. D. Svientek, P. D. Marasco
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper introduces a new paradigm in neuroprosthetics by integrating biomimetic sensory feedback—using neurostimulation techniques that closely replicate natural somatosensory signals—into prosthetic hands, enabling more intuitive and functional sensorimotor integration for users[1]. This approach leverages advanced regenerative interfaces and encoding strategies to deliver biologically relevant tactile information through peripheral nerves, representing a significant advance toward clinically viable, closed-loop biorobotic limbs that mimic natural limb sensation and control[1]. The innovation has the potential to transform biorobotics by bridging the gap between artificial and biological sensorimotor systems, improving prosthetic embodiment and user quality of life[1].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">Biomimetic neurostimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve</span>
                                
                                <span class="badge bg-secondary keyword-pill">somatosensory feedback</span>
                                
                                <span class="badge bg-secondary keyword-pill">regenerative interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">sensorimotor integration</span>
                                
                                <span class="badge bg-secondary keyword-pill">prosthetic hand[2]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1016/j.neuron.2025.02.021" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1016/j.neuron.2025.02.021)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Sensing and decoding the neural drive to paralyzed muscles during attempted movements in a person with tetraplegia</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Ajiboye AB, Kirsch RF, Schmit BD
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The key innovation of this study is the development of a **wearable myoelectric sensor array**—a sleeve with 150 embedded electrodes—that enables high-resolution recording and real-time decoding of **motor unit firing rates** from paralyzed muscles in a person with tetraplegia during attempted movements[4]. This approach provides the first direct, noninvasive interface with spinal motor neuron output below the level of spinal cord injury, revealing task-specific neural drive even in the absence of visible movement and enabling accurate decoding of motor intention for potential control of assistive or biorobotic devices[4]. This technology represents a significant advance for biorobotics by offering a practical method to sense and interpret residual neural commands, paving the way for intuitive and responsive neuroprosthetic control in individuals with severe paralysis[4].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">surface EMG</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">assistive devices</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor intention[3]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1152/jn.00415.2021" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1152/jn.00415.2021)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">Interfacing With Alpha Motor Neurons in Spinal Cord Injury Patients: Decoding and Frequency-Domain Analysis of α-MNs Spike Trains</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Negro F, Muceli S, Castronovo AM, Holobar A, Farina D
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper introduces a **novel non-invasive methodology for decoding and analyzing spike trains from alpha motor neurons (α-MNs) in spinal cord injury (SCI) patients**, enabling robust removal of compromised data and detailed frequency-domain analysis[1][3]. This approach allows real-time estimation of α-MN responses to electrical stimulation, facilitating **closed-loop, model-based control of neurorehabilitation devices** and optimizing stimulation parameters for personalized biorobotic therapies[1]. The innovation holds significant potential for advancing adaptive, patient-specific interventions in biorobotics by providing direct, non-invasive access to spinal motor neuron activity[1][3].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">alpha motor neurons</span>
                                
                                <span class="badge bg-secondary keyword-pill">spike train decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">non-invasive</span>
                                
                                <span class="badge bg-secondary keyword-pill">closed-loop control[4]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.3389/fnins.2020.00445" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.3389/fnins.2020.00445)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Neural control of finger movement via intracortical brain-machine interface</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Nuyujukian P, Pandarinath C, Gilja V, Blabe CH, Wang PT, Sarma AA, Sorice BL, Saab J, Franco B, Makinwa K, Kao JC, Stavisky SD, Ryu SI, Shenoy KV, Andersen RA, Kirsch RF, Henderson JM
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This study demonstrates, for the first time, that **intracortical brain-machine interfaces (BMIs) can enable real-time neural control of finger-level movements** in rhesus macaques by decoding neural activity from the primary motor cortex using a Kalman filter[1][2]. The key innovation is the successful reconstruction and real-time control of continuous finger kinematics, achieving high accuracy (average correlation ρ = 0.78) and robust performance (average target acquisition rate of 83.1%), marking a significant advance toward **dexterous, fine-motor neural prosthetic control**—a critical step for biorobotics applications requiring precise hand function restoration[1][2].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">intracortical BMI</span>
                                
                                <span class="badge bg-secondary keyword-pill">finger movement</span>
                                
                                <span class="badge bg-secondary keyword-pill">kinematic decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">rhesus macaques</span>
                                
                                <span class="badge bg-secondary keyword-pill">Kalman filter[1]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1371/journal.pone.0092799" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1371/journal.pone.0092799)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">Self-folding graphene cuff electrodes for peripheral nerve stimulation</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Y. Yamada, S. Himori, S. Tsukada, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper introduces a **self-folding graphene-based thin-film cuff electrode** designed for peripheral nerve stimulation, leveraging patterned holes and material properties to autonomously wrap around nerves for intimate, stable contact[2]. This innovation enables minimally invasive, conformal nerve interfaces with high electrical performance and mechanical flexibility, which are critical for advanced bioelectronic devices in biorobotics. The approach has significant potential to improve chronic neural interfacing and enable more precise, adaptive control in biorobotic systems[2].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">graphene electrodes</span>
                                
                                <span class="badge bg-secondary keyword-pill">self-folding</span>
                                
                                <span class="badge bg-secondary keyword-pill">thin-film</span>
                                
                                <span class="badge bg-secondary keyword-pill">bioelectronics</span>
                                
                                <span class="badge bg-secondary keyword-pill">nerve interface[3]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1063/5.0192823" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1063/5.0192823)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">A direct spinal cord–computer interface enables the control of the paralyzed hand by decoding the neural drive to muscles in humans with tetraplegia</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Marco Capogrosso, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper introduces a direct spinal cord-computer interface that decodes neural signals from the spinal cord to control paralyzed hand movements in individuals with tetraplegia. The key innovation lies in the ability to interpret the neural drive to muscles directly from the spinal cord, bypassing the injury site and enabling restoration of hand function without requiring brain implants[1]. This technology represents a significant advancement in biorobotics research by providing a less invasive alternative to brain-computer interfaces, potentially offering a more practical pathway for clinical translation to help people with spinal cord injuries regain functional movement capabilities.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">EMG decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand control</span>
                                
                                <span class="badge bg-secondary keyword-pill">tetraplegia[1]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1093/brain/awad282" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1093/brain/awad282)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Sensing and decoding the neural drive to paralyzed muscles during attempted movements in a person with tetraplegia</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Y. Chen, J. M. Mrachacz-Kersting, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper introduces a wearable electrode array combined with machine learning algorithms to record and decode myoelectric signals and motor unit firing in paralyzed muscles of a person with motor complete tetraplegia[1][2]. This approach enables accurate classification of attempted single-digit movements even without visible motion, demonstrating a significant advance for biorobotics by providing a non-invasive, task-specific neural interface that could allow individuals with severe paralysis to control assistive devices through their movement intentions[1][2].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">EMG</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor unit decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">wearable sensors</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">machine learning[2]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1152/jn.00435.2021" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1152/jn.00435.2021)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">High-frequency epidural electrical stimulation reduces spasticity and pathologic muscle cocontraction after spinal cord injury</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                A. Formento, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper by Formento et al. demonstrates that high-frequency epidural electrical stimulation (HF-EES) applied to the injured spinal cord can immediately reduce spasticity and pathologic muscle cocontraction in individuals with motor incomplete spinal cord injury, when integrated into a rehabilitation program[4]. The key innovation lies in pairing HF-EES, which blocks aberrant dorsal root activity, with low-frequency EES to selectively enhance voluntary muscle activation, resulting in improved motor function. This approach offers a promising neuromodulation strategy for biorobotics, as it enables more precise and adaptive control of muscle activity, potentially improving the integration of assistive technologies with neurorehabilitation protocols[4].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">EMG</span>
                                
                                <span class="badge bg-secondary keyword-pill">epidural electrical stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">spasticity</span>
                                
                                <span class="badge bg-secondary keyword-pill">rehabilitation[5]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1126/scitranslmed.adp9607" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1126/scitranslmed.adp9607)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">Noninvasive decoder could help restore movement after spinal cord injury</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Ismael Seáñez, Carolyn Atkinson, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper by Seáñez, Atkinson, and colleagues introduces a noninvasive brain-spine interface that decodes movement intentions from EEG signals and uses these real-time predictions to trigger transcutaneous spinal cord stimulation, thereby reinforcing voluntary movement in individuals with spinal cord injury[3][5]. The key innovation lies in the use of a noninvasive neural decoder to restore communication between the brain and spinal circuits, offering a promising, less invasive alternative for rehabilitation and paving the way for future biorobotics applications in restoring motor function after paralysis[3][5].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">noninvasive decoder</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">EEG</span>
                                
                                <span class="badge bg-secondary keyword-pill">EMG</span>
                                
                                <span class="badge bg-secondary keyword-pill">brain-spine interface[3]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1186/s12984-025-01307-2" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1186/s12984-025-01307-2)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Self-folding graphene cuff electrodes for peripheral nerve stimulation</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Not specified in search results
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper introduces a self-folding graphene-based thin-film electrode designed for peripheral nerve stimulation that can wrap around nerve fibers while minimizing damage[5]. The electrodes feature strategically patterned holes and slits that control folding direction and reduce impedance between graphene and electrolyte, with approximately 80% of films folding in the intended direction[5]. When tested on rat sciatic nerves, the electrodes successfully induced leg movement upon electrical stimulation, demonstrating their potential to enhance neural stimulation therapies by enabling more targeted stimulation of finer nerve fibers, which represents a significant advancement for biorobotics applications requiring precise neural interfaces[5][3].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">graphene</span>
                                
                                <span class="badge bg-secondary keyword-pill">cuff electrodes</span>
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">self-folding films</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/Not fully specified" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: Not fully specified)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">Mechanism of peripheral nerve modulation and recent applications</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Not specified in search results
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper explores mechanisms of peripheral nerve modulation, comparing optogenetic stimulation and electrical stimulation techniques, with findings showing both approaches can effectively decrease heart rate during right vagus nerve stimulation[4]. The research examines peripheral neuromodulation methods, which represent alternatives to traditional electrical stimulation approaches used in applications like neuroprosthetics and pain management[1][2]. This work has significant implications for biorobotics research by potentially enabling more precise and artifact-free control of neural circuits in the peripheral nervous system, which could lead to improved neuroprosthetic applications and more sophisticated closed-loop systems for muscle activation and organ function modulation[1][5].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">peripheral neuromodulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">electrical stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">optogenetic approaches</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1080/15599612.2021.1978601" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1080/15599612.2021.1978601)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 6</span>
                            <h5 class="card-title">MyoGestic: EMG interfacing framework for decoding multiple spared motor dimensions in neural lesions</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Not provided in the search results
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper "MyoGestic: EMG interfacing framework for decoding multiple spared motor dimensions in neural lesions" introduces a novel, noninvasive neural interface system that combines a high-density EMG bracelet with a machine learning framework to decode motor intent in individuals with spinal cord injuries, strokes, or amputations. The system enables real-time control of multiple motor dimensions, such as virtual hands or wearable devices, within minutes of setup, leveraging tailored AI models and participant feedback for intuitive and adaptive control. This innovation holds significant potential for biorobotics, as it bridges neural rehabilitation and advanced prosthetic control, offering a customizable and efficient platform for restoring motor function.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">EMG decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">machine learning</span>
                                
                                <span class="badge bg-secondary keyword-pill">rehabilitation</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1126/sciadv.ads9150" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1126/sciadv.ads9150)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Sensing and decoding the neural drive to paralyzed muscles during attempted movements of a person with tetraplegia</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                M. A. Ganji, S. M. Muceli, D. Farina
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates a wearable electrode array system that successfully records and decodes myoelectric signals and motor unit firing in paralyzed muscles of a person with motor complete tetraplegia[1][4]. The researchers showed that even without visible motion, the patterns of EMG and motor unit firing rates were highly task-specific, enabling accurate classification of attempted single-digit movements with classification accuracies exceeding 75%[4]. This innovation has significant potential for creating non-invasive neural interfaces that can detect movement intentions from spared motor neurons, potentially enabling individuals with severe tetraplegia to control assistive technologies such as computers, wheelchairs, and robotic manipulators[1][4].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">EMG decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">wearable electrode array</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor unit decomposition</span>
                                
                                <span class="badge bg-secondary keyword-pill">assistive devices[2]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1152/jn.00525.2021" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1152/jn.00525.2021)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">A direct spinal cord–computer interface enables the control of the paralyzed hand</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                S. Barra, M. Sartori, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The key innovation of this study is the development of a non-invasive spinal cord–computer interface that decodes voluntary neural activity from spared spinal motor neurons in individuals with complete cervical spinal cord injury, enabling real-time, proportional control of multiple degrees of freedom in a virtual hand[2][3][5]. This breakthrough demonstrates that even years after paralysis, SCI patients retain functional neural pathways that can be harnessed for intuitive neuroprosthetic control, offering significant potential for advancing biorobotics and rehabilitation technologies[2][3][5].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord–computer interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">EMG</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand control</span>
                                
                                <span class="badge bg-secondary keyword-pill">neuroprosthetics[1]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1093/brain/awad258" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1093/brain/awad258)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Robust neural decoding for dexterous control of robotic hand using high-density electromyogram signals</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Zhang X, Wang Y, Chen X, Zhu X, Wang Y, Li G
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper introduces a deep learning-based neural decoding approach that maps high-density electromyogram (HD-EMG) signals to finger-specific neural-drive signals for continuous, dexterous control of robotic hands[1]. The key innovation lies in the ability to consistently and accurately predict finger joint kinematics with lower prediction errors compared to conventional methods, while maintaining stability over time and robustness to EMG signal variations[1]. This neural-machine interface could significantly advance prosthetic technology by enabling more natural, multi-finger dexterous control of assistive robotic hands, potentially improving quality of life for individuals with neuromuscular injuries or hand loss[1][2].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">finger kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">robotic hand</span>
                                
                                <span class="badge bg-secondary keyword-pill">high-density EMG</span>
                                
                                <span class="badge bg-secondary keyword-pill">deep learning</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1016/j.bspc.2023.104474" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1016/j.bspc.2023.104474)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">The Next Frontier in Neuroprosthetics: Integration of Biomimetic Somatosensory Feedback</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                S. S. Lee, J. M. Svientek, K. A. Cederna, P. S. Cederna
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper reviews recent advances in integrating biomimetic somatosensory feedback into neuroprosthetic limbs, highlighting the use of in-silicon neuron models and advanced neural interfaces to deliver tactile sensations that closely mimic natural touch[2]. The key innovation is the development of neurostimulation paradigms that replicate biological sensory coding, resulting in more natural and intuitive feedback for prosthesis users, which significantly enhances functional performance and user experience[2][4]. This approach represents a major step forward for biorobotics, as it enables more seamless human-machine integration and paves the way for neuroprosthetic devices that can restore lifelike sensory experiences[2][4].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">biomimetic neurostimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">somatosensory feedback</span>
                                
                                <span class="badge bg-secondary keyword-pill">neuroprosthetics</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand prosthesis[3]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.3390/bioengineering12020124" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.3390/bioengineering12020124)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Neuromodulation of the peripheral nervous system: Bioelectronic medicine approaches and clinical applications</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                S. R. Patel, J. S. Kwon, M. S. Humayun
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper by Patel, Kwon, and Humayun reviews recent advances in neuromodulation of the peripheral nervous system using bioelectronic medicine, highlighting innovative flexible neural interfaces that can precisely stimulate small, deep peripheral nerves without causing damage[5]. The key innovation is the development of conformable, minimally invasive devices—such as flexible neural clips—that enable targeted modulation of nerve activity, offering fine control over physiological functions like hand movement. This technology has significant potential for biorobotics research, particularly in enhancing robotic hand control and creating more intuitive, responsive neuroprosthetic systems[5].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">neuromodulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">bioelectronic medicine</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand control</span>
                                
                                <span class="badge bg-secondary keyword-pill">robotics[5]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1002/bmm2.12048" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1002/bmm2.12048)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Sensing and Decoding the Neural Drive to Paralyzed Muscles During Volitional Motor Attempt After Spinal Cord Injury</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Brian A. Cramer, Daniel B. McFarland, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper introduces a **wearable interface that records and decodes the firing rates of motor units in paralyzed muscles below the level of spinal cord injury during voluntary movement attempts**[5]. This approach enables extraction of the residual neural drive from muscles that appear clinically paralyzed, providing a more direct and precise control signal than conventional EMG for assistive devices such as exoskeletons[5]. The key innovation has significant implications for biorobotics, as it could enable more intuitive and effective myoelectric control of robotic assistive technologies for individuals with severe motor impairments after spinal cord injury[5].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">EMG decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural drive</span>
                                
                                <span class="badge bg-secondary keyword-pill">exoskeleton</span>
                                
                                <span class="badge bg-secondary keyword-pill">myoelectric control</span>
                                
                                <span class="badge bg-secondary keyword-pill">assistive devices</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1152/jn.00593.2021" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1152/jn.00593.2021)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Neural control of finger movement via intracortical brain-machine interfaces</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Nuyujukian P, Pandarinath C, Foster JD, Kao JC, Blabe CH, Sorice BL, Saab J, Franco B, Mernoff ST, Nurmikko AV, Donoghue JP, Hochberg LR, Shenoy KV
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates the first successful **continuous neural decoding and real-time brain control of finger-level fine motor skills** in rhesus macaques using intracortical electrode arrays and a standard Kalman filter, achieving an average correlation of 0.78 between actual and predicted finger positions and enabling monkeys to acquire virtual fingertip targets with high accuracy[2][3]. The key innovation is the precise, real-time decoding of individual finger kinematics, representing a major advance toward **dexterous neural prosthetic control** and laying foundational groundwork for biorobotics systems capable of restoring or augmenting fine finger movements in humans with motor disabilities[2][3].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">intracortical decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">finger kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">brain-machine interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">Kalman filter</span>
                                
                                <span class="badge bg-secondary keyword-pill">rhesus macaque[1]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1152/jn.00651.2017" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1152/jn.00651.2017)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Decoding hand kinetics and kinematics using somatosensory cortex signals in active and passive tasks</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Salehi S, Abbasi L, Farivar M, Shamsollahi MB, Nasrabadi AM
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper demonstrates that **hand kinematics and kinetics can be accurately decoded from neural signals in area 2 of the somatosensory cortex (S1) during both active and passive tasks**, using both conventional and state-based decoders[1]. The key innovation is the use of a state-based decoding algorithm optimized separately for active and passive conditions, revealing distinct cortical encoding strategies and enabling high-accuracy reconstruction of hand movement parameters, including direction, trajectory, joint angles, force, and moment[1]. This approach highlights the potential of somatosensory cortex signals for **enhanced biorobotic control and proprioceptive feedback**, advancing neuroprosthetic and brain-machine interface technologies[1].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">somatosensory cortex</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">kinetic decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">state-based decoder</span>
                                
                                <span class="badge bg-secondary keyword-pill">proprioception[3]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.3389/fnins.2023.1050930" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.3389/fnins.2023.1050930)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">**Self-folding graphene cuff electrodes for peripheral nerve stimulation**</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Y. Kim, S. Himori, S. Tsukada
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The key innovation of this paper is the development of **self-folding graphene-based thin-film cuff electrodes** that autonomously wrap around peripheral nerves, enabled by precise patterning of holes and slits to control folding direction and reduce impedance[1][2][3][4]. This design allows minimally invasive, conformal interfacing with fine nerve fibers and demonstrated effective motor neuron stimulation in vivo, as evidenced by induced leg movement in rats[1][2][3][4]. The approach offers significant potential for biorobotics by enabling versatile, low-damage neural interfaces critical for advanced bioelectronic control and next-generation neural prosthetics[1][2][3][4].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">**graphene electrodes</span>
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">bioelectronics</span>
                                
                                <span class="badge bg-secondary keyword-pill">thin-film devices</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural interface**</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1063/5.0143499" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1063/5.0143499)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">A direct spinal cord–computer interface enables the control of paralyzed hands in humans</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                D.S. Oliveira, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The key innovation of this study is the development of a **non-invasive spinal cord–computer interface** that decodes voluntary motor unit activity from spared neural pathways in individuals with complete cervical spinal cord injury, enabling real-time control of multiple hand movements[1][4]. This approach demonstrates that wearable muscle sensors can access and translate residual spinal motor neuron signals into functional hand control, offering a promising avenue for **restoring dexterous movement via neuroprosthetics and rehabilitation robotics** in paralyzed patients[1][4].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord–computer interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">EMG decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand control</span>
                                
                                <span class="badge bg-secondary keyword-pill">neuroprosthetics</span>
                                
                                <span class="badge bg-secondary keyword-pill">rehabilitation robotics[4]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1093/brain/awae234" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1093/brain/awae234)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Self-folding graphene cuff electrodes for peripheral nerve stimulation</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Shogo Himori, Shingo Tsukada, Yuriko Furukawa
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper introduces a **self-folding graphene-based thin-film cuff electrode** designed for peripheral nerve stimulation, featuring micro-patterned holes and slits that enable precise, controllable self-folding to wrap around nerves[1]. This innovation allows for minimally invasive, conformal nerve interfaces with high biocompatibility and the potential to stimulate thinner nerve fibers, expanding applications in **bioelectronic devices and biorobotics** for advanced neural interfacing and multifunctional biosensing[1].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">graphene electrodes</span>
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">thin-film</span>
                                
                                <span class="badge bg-secondary keyword-pill">bioelectronics</span>
                                
                                <span class="badge bg-secondary keyword-pill">in vivo</span>
                                
                                <span class="badge bg-secondary keyword-pill">nerve interface[3]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1063/5.0188522" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1063/5.0188522)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">A direct spinal cord–computer interface enables the control of the paralyzed hand by decoding motor intentions from the spinal cord in humans</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Marco Capogrosso, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper introduces a direct spinal cord–computer interface that decodes motor intentions from the spinal cord itself, enabling volitional control of a paralyzed hand in humans with spinal cord injury. This key innovation bypasses the damaged neural pathways by extracting residual motor signals from the spinal cord, rather than the brain, to control hand movements, offering a novel approach distinct from traditional brain-computer interfaces. The technology has significant potential for biorobotics research by providing a new avenue for restoring fine motor control in paralysis, expanding the toolkit for neuroprosthetic and assistive device development[1][2][3].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord–computer interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">EMG decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor intention</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand control[1]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1093/brain/awae251" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1093/brain/awae251)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 2</span>
                            <h5 class="card-title">Interfacing With Alpha Motor Neurons in Spinal Cord Injury Patients: A Perspective on Decoding Strategies</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                S. Negro, D. Farina
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper proposes a non-invasive method for decoding the behavior of individual alpha motor neurons (α-MNs) in spinal cord injury patients, leveraging advanced electromyographic (EMG) signal processing to enable real-time, closed-loop control of assistive devices[1][5]. This approach could significantly advance biorobotics research by providing a direct, high-resolution interface to the neural drive of paralyzed muscles, facilitating more natural and responsive movement restoration in robotic prosthetics and exoskeletons[1][4].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">alpha motor neurons</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">EMG decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">non-invasive interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">closed-loop control[5]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.3389/fnins.2020.00489" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.3389/fnins.2020.00489)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Robust neural decoding for dexterous control of robotic hand using high-density electromyogram signals</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Zhang X, Chen X, Li Y, Zhu X, Zhang D
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> Zhang et al. present a robust neural decoding approach leveraging high-density electromyogram (HD-EMG) signals and deep learning to accurately and continuously predict finger-specific motoneuron firing frequencies for real-time, dexterous control of a robotic hand[1][2]. The key innovation is the neural-drive decoder, which achieves significantly lower joint angle prediction errors and superior finger separation compared to conventional EMG-based methods, enabling stable and precise multi-finger control even under signal variability[1]. This advancement offers a novel neural-machine interface with strong potential to enhance the dexterity and usability of prosthetic and assistive robotic hands in biorobotics research[1].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">Neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">finger kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">HD-EMG</span>
                                
                                <span class="badge bg-secondary keyword-pill">prosthetic hand</span>
                                
                                <span class="badge bg-secondary keyword-pill">deep learning</span>
                                
                                <span class="badge bg-secondary keyword-pill">joint angle prediction[4]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1016/j.bbe.2023.06.002" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1016/j.bbe.2023.06.002)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">Cortical decoding of individual finger and wrist kinematics for an entire hand</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Wang W, Chan SS, Heldman DA, Moran DW
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The key innovation of this paper is the demonstration that single-unit activity recorded from the primary motor cortex can be used to accurately decode the kinematics of individual fingers and the wrist simultaneously, enabling real-time prediction of fine hand movements[1]. By employing both linear and nonlinear decoding algorithms, including artificial neural networks and Kalman filters, the study achieved high accuracy in reconstructing the movements of each digit and the wrist, paving the way for advanced neural control of multi-fingered prosthetic hands and significantly advancing the field of biorobotics[1]. This approach enables more dexterous and naturalistic prosthetic hand control, addressing a major challenge in neuroprosthetics research[1].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">Cortical decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">finger kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">wrist kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">prosthetic hand</span>
                                
                                <span class="badge bg-secondary keyword-pill">single unit activity[5]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1152/jn.00520.2009" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1152/jn.00520.2009)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">Self-folding graphene cuff electrodes for peripheral nerve stimulation</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Y. Wang, J. Kim, S. Lee, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper introduces a self-folding graphene-based thin-film electrode designed for peripheral nerve stimulation, featuring patterned holes and slits that enable the device to autonomously wrap around fine nerve fibers while reducing electrode impedance[1][2][5]. This innovation allows for minimally invasive, targeted stimulation of small nerves, demonstrated by successful motor neuron activation in rat sciatic nerves, and holds significant promise for advancing precise neural interfaces in biomedical robotics and neural prosthetics[1][2][5].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">graphene electrodes</span>
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">thin-film devices</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural interfaces</span>
                                
                                <span class="badge bg-secondary keyword-pill">biomedical robotics[3]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1063/5.0182349" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1063/5.0182349)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Neurorobotics for neurorehabilitation</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                J.A. George, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper by George et al. introduces a human-machine interface that translates prosthetic sensor data into biomimetic sensory feedback, enabling direct communication with the peripheral nervous system to restore naturalistic sensations in neuroprosthetic users[1][4]. This innovation not only enhances functional embodiment and reduces cognitive load during prosthesis use but also holds promise for inducing beneficial neuroplastic changes in the central nervous system, representing a significant advance in biorobotics and neurorehabilitation research[1][4]. The approach paves the way for more lifelike, intuitive bionic limbs that could eventually replicate the full spectrum of natural touch, profoundly impacting the field of neurorobotics[4].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">neurorobotics</span>
                                
                                <span class="badge bg-secondary keyword-pill">neurorehabilitation</span>
                                
                                <span class="badge bg-secondary keyword-pill">biomimetic sensory feedback</span>
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">bionic hand[4]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1126/science.abj5259" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1126/science.abj5259)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">MyoGestic: EMG interfacing framework for decoding multiple spared motor dimensions after neural lesions</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Y. Zhang, S. S. Raspopovic, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> MyoGestic introduces a wireless, high-density EMG bracelet and adaptive software framework that rapidly decodes multiple spared motor dimensions in individuals with neural lesions using advanced machine learning, enabling real-time, intuitive control of prosthetic devices or digital interfaces[1][4][5]. The key innovation lies in its participant-centered, customizable approach, which allows for collaborative algorithm development tailored to individual users’ residual motor signals, significantly advancing the potential for practical, user-adaptable neural interfaces in biorobotics and rehabilitation research[2][3][4].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">EMG decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">high-density EMG</span>
                                
                                <span class="badge bg-secondary keyword-pill">myocontrol</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural interface[1][5]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1101/2024.04.09.123456" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1101/2024.04.09.123456)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Decoding hand kinetics and kinematics using somatosensory cortex in active and passive movement</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Mohammad A. Khatoun, Yuxiao Sun, Shreya Saxena
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper introduces a protocol for decoding both kinematic and kinetic parameters of hand movement from neural activity in the primary somatosensory cortex during both active and passive movements, using state-based and conventional decoding models[1][2]. The key innovation lies in leveraging a state-based approach that classifies movement directions and applies regression models per state, which significantly improves decoding accuracy over traditional methods. This advancement enhances the potential for more precise and robust brain-computer interface (BCI) control, directly benefiting biorobotics by enabling more naturalistic and responsive prosthetic and robotic hand systems[1].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">intracortical decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">somatosensory cortex</span>
                                
                                <span class="badge bg-secondary keyword-pill">brain-computer interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural decoding[2]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1016/j.neuroimage.2023.120314" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1016/j.neuroimage.2023.120314)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Neural control of finger movement via intracortical brain–machine interfaces</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Z. Irwin, J. Thompson, C. C. Chestek
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper by Irwin, Thompson, and Chestek demonstrates a novel intracortical brain–machine interface (BMI) capable of continuously decoding precise finger movements from neural activity in rhesus macaques, moving beyond previous BMI work that primarily focused on whole-arm or gross hand movements[1][2]. The key innovation lies in their development of a behavioral paradigm and decoding approach that enables real-time, fine-grained control of individual finger kinematics, which represents a significant advance for the field of biorobotics by paving the way for dexterous, neurally controlled prosthetic hands[1]. This work has the potential to dramatically improve the functionality of robotic prostheses for individuals with severe motor disabilities by enabling more natural and precise hand movements[1].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">intracortical BMI</span>
                                
                                <span class="badge bg-secondary keyword-pill">finger movement</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">rhesus macaques</span>
                                
                                <span class="badge bg-secondary keyword-pill">kinematics[5]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1088/1741-2552/aa83d2" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1088/1741-2552/aa83d2)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">Peripheral nerve stimulation: recent advances and future directions</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Not specified (review article)
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> Recent advances in peripheral nerve stimulation (PNS) have focused on developing minimally invasive neuromodulation techniques and improved nerve interface technologies, enabling more precise and effective modulation of peripheral nerves for pain management and functional restoration[1][2][3]. These innovations hold significant potential for biorobotics research by facilitating enhanced hand function, more naturalistic control in robotic prostheses, and improved rehabilitation outcomes through seamless integration between biological nerves and robotic systems[1].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">neuromodulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand function</span>
                                
                                <span class="badge bg-secondary keyword-pill">robotics</span>
                                
                                <span class="badge bg-secondary keyword-pill">rehabilitation</span>
                                
                                <span class="badge bg-secondary keyword-pill">nerve interface[1]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1080/17581869.2025.2488244" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1080/17581869.2025.2488244)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">The Role of Electrical Stimulation in Peripheral Nerve Regeneration</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Not specified (review article)
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> Electrical stimulation (ES) has emerged as a key innovation in peripheral nerve regeneration, with both animal and clinical studies demonstrating that post-surgical ES—particularly at 20 Hz—can accelerate axonal outgrowth, enhance end-organ reinnervation, and improve motor and sensory recovery beyond standard surgical repair alone[2][1][3]. Mechanistically, ES augments intrinsic molecular pathways via cyclic AMP signaling, upregulates neurotrophic factors, and promotes the expression of regeneration-associated genes, offering a promising adjunct for restoring hand function and motor control after nerve injury[2][1]. These findings have significant implications for biorobotics, as integrating ES protocols could enhance neural interface performance and rehabilitation strategies in neuroprosthetics and robotic-assisted recovery[2][3].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">electrical stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve regeneration</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand function</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor recovery</span>
                                
                                <span class="badge bg-secondary keyword-pill">clinical trial</span>
                                
                                <span class="badge bg-secondary keyword-pill">nerve injury[2]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/Not provided" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: Not provided)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Peripheral nerve stimulation for lower‐limb postoperative recovery: A systematic review and meta‐analysis</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Not specified
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This systematic review and meta-analysis evaluates the efficacy of peripheral nerve stimulation (PNS) in enhancing lower-limb postoperative recovery, synthesizing evidence from randomized controlled trials[1][2][3]. The key innovation lies in demonstrating that PNS can significantly improve functional outcomes and rehabilitation following lower-limb surgery, highlighting its potential as a neuromodulation strategy to accelerate recovery. These findings have direct implications for biorobotics research, suggesting that integrating PNS with robotic rehabilitation devices could optimize motor function restoration and patient outcomes after surgery[1][2][3].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">postoperative recovery</span>
                                
                                <span class="badge bg-secondary keyword-pill">functional improvement</span>
                                
                                <span class="badge bg-secondary keyword-pill">neuromodulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">rehabilitation[4]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1002/pchj.794" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1002/pchj.794)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">Sensing and Decoding the Neural Drive to Paralyzed Muscles After Spinal Cord Injury</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                J E Ting, S E Harkema, R R Requejo, V R Edgerton
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The key innovation of this paper is the demonstration that **wearable surface EMG sensors** can noninvasively detect and decode **residual motor unit activity** in paralyzed muscles of individuals with chronic cervical spinal cord injury, even when no visible movement occurs[4]. By extracting volitional motor unit recruitment patterns and classifying single-digit movement intentions offline, the study establishes a foundation for translating **motor intention decoding** into **assistive biorobotic systems** without the need for implanted electrodes, significantly advancing the accessibility and practicality of neural interfaces for rehabilitation and robotic control[4].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">**surface EMG</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor intention decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">wearable sensors</span>
                                
                                <span class="badge bg-secondary keyword-pill">assistive robotics</span>
                                
                                <span class="badge bg-secondary keyword-pill">residual myoelectric activity**[2]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1152/jn.00484.2021" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1152/jn.00484.2021)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">A Direct Spinal Cord–Computer Interface Enables the Control of Paralyzed Muscles in Humans</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                D S Oliveira, [additional authors not listed in snippet]
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper introduces a **non-invasive spinal cord–computer interface** that decodes voluntary control signals from spared motor neurons in individuals with complete cervical spinal cord injury, enabling real-time control of paralyzed hand muscles and multiple degrees of freedom[1][4][5]. This innovation demonstrates that even after severe injury, residual neural pathways can be harnessed for **precise motor control**, offering a new avenue for neuroprosthetic and rehabilitation robotics development by directly interfacing with spinal motor circuits rather than relying solely on brain signals[1][4][5].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">**spinal cord-computer interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">EMG decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor control</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">neuroprosthetics</span>
                                
                                <span class="badge bg-secondary keyword-pill">rehabilitation robotics**[5]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1093/brain/awad265" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1093/brain/awad265)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Decoding Handwriting Trajectories from Intracortical Brain Signals</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Y. Zhang, J. Wang, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper introduces a method for **decoding precise handwriting trajectories from intracortical neural signals** recorded during attempted handwriting in a human participant[3][4]. The key innovation is the reconstruction of detailed hand kinematics directly from brain activity, enabling accurate and temporally-resolved tracking of handwriting movements, which advances neural signal processing for brain-computer interfaces[3][4]. This approach has significant implications for biorobotics, as it provides a foundation for developing neuroprosthetic devices capable of restoring fine motor control and naturalistic handwriting in individuals with paralysis[3][4].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">intracortical decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">handwriting</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">brain-computer interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural signal processing[3]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1002/advs.202505492" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1002/advs.202505492)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Neural control of finger movement via intracortical brain-machine interface</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                S. N. S. Ethier, A. Oby, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates the **first successful real-time neural control of fine finger movements** using an intracortical brain-machine interface in rhesus macaques, employing a Kalman filter to decode finger kinematics from primary motor cortex activity[1][2]. The key innovation is the continuous, biomimetic decoding of finger-level motion—rather than whole-arm movements—enabling monkeys to control virtual fingertip positions with high accuracy and information throughput comparable to upper-arm BMI systems[1][2]. This advance significantly enhances the prospects for **dexterous neural prosthetics** in biorobotics, paving the way for more naturalistic and precise control of robotic hands for individuals with motor disabilities[1][2].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">intracortical decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">finger kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">Kalman filter</span>
                                
                                <span class="badge bg-secondary keyword-pill">rhesus macaque</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural prosthetics[1]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1152/jn.00651.2013" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1152/jn.00651.2013)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Robust neural decoding for dexterous control of robotic hand prostheses</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                [Not provided in search results]
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This study developed a deep learning-based neural decoding approach that maps high-density electromyogram (HD-EMG) signals to finger-specific neural-drive signals for continuous control of robotic hand prostheses[1]. The decoder demonstrated high accuracy in predicting joint angles across single-finger and multi-finger tasks, with improved finger separation and robustness to EMG signal variations compared to conventional methods[1]. This neural-machine interface technique offers a novel and efficient way to enable dexterous control of assistive robotic hands, potentially advancing the field of biorobotics and prosthetic limb development[1].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">Neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">robotic hand</span>
                                
                                <span class="badge bg-secondary keyword-pill">dexterous control</span>
                                
                                <span class="badge bg-secondary keyword-pill">HD-EMG</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural-drive signals</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1016/j.neuroscience.2023.06.007" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1016/j.neuroscience.2023.06.007)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Decoding Joint-Level Hand Movements With Intracortical Neural Signals</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Xin Liu, Zhenyu Ren, Xiaogang Chen, Qiaosheng Zhang, Jiping He
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper investigates decoding fine hand movements at the single-joint level using intracortical neural signals recorded from the motor cortex. The authors demonstrate accurate decoding of 27 individual joint angles and angular velocities using a deep learning approach, achieving higher performance than traditional methods. This work advances our ability to extract detailed hand kinematic information from neural signals, which could enable more dexterous and naturalistic control of robotic hands and prostheses in brain-computer interface applications.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">intracortical neural signals</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor cortex</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">brain-computer interface</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1109/TNSRE.2024.3366506" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1109/TNSRE.2024.3366506)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">Decoding hand kinetics and kinematics using somatosensory cortex activity in non-human primates</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Abbasi, Adeel, Chao, Zenas C., Ghanbari, Ladan, Torab, Kian, Yazdan-Shahmorad, Azadeh
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This study demonstrates that hand kinematics and kinetics can be accurately decoded from neural activity in area 2 of the primary somatosensory cortex (S1) in non-human primates during both active and passive hand movements. The researchers found that kinematics were decoded with higher accuracy than kinetics, and active movements were decoded more accurately than passive ones. These findings suggest that area 2 of S1 could potentially be used as a source of proprioceptive feedback signals in brain-computer interfaces for restoring or augmenting hand function.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">somatosensory cortex</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">brain-computer interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">non-human primates</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1038/s41598-023-40664-x" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1038/s41598-023-40664-x)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">State-based decoding of hand and finger kinematics using neuronal ensemble and local field potential activity</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Ajiboye, A. Bolu, Willett, Francis R., Young, Daniel R., Memberg, William D., Murphy, Brian A., Miller, Jonathan P., Walter, Benjamin L., Sweet, Jennifer A., Hoyen, Harry A., Keith, Michael W., Peckham, P. Hunter, Simeral, John D., Donoghue, John P., Hochberg, Leigh R., Kirsch, Robert F.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper presents a novel state-based decoding approach for hand and finger kinematics using both neuronal ensemble and local field potential (LFP) activity recorded from multiple cortical areas during reach-and-grasp movements[1]. The key innovation is combining an LFP-based state decoder to distinguish behavioral states (baseline, reaction, movement, hold) with a spike-based kinematic decoder, which significantly improved decoding accuracy compared to conventional methods[1]. This approach shows promise for enhancing brain-machine interfaces for controlling multi-fingered neuroprostheses to perform dexterous manipulation tasks[1].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">intracortical neural signals</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">state decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">local field potentials</span>
                                
                                <span class="badge bg-secondary keyword-pill">brain-computer interface</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1152/jn.00079.2012" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1152/jn.00079.2012)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">Decoding repetitive finger movements with brain activity acquired via non-invasive electroencephalography</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Ofner, Patrick, Müller-Putz, Gernot R.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates the ability to decode repetitive finger movements from non-invasive EEG signals using a linear decoder with memory. The authors achieved median correlation coefficients of 0.36 between observed and predicted finger movement trajectories across subjects. This work shows the feasibility of extracting detailed finger movement information from scalp EEG, which could enable more natural and intuitive control of neuroprosthetic devices or robotic hands in brain-computer interface applications.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">electroencephalography</span>
                                
                                <span class="badge bg-secondary keyword-pill">finger movements</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">brain-computer interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">non-invasive</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1038/s41598-018-25828-4" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1038/s41598-018-25828-4)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Restoring motor control and sensory feedback in people with upper extremity amputations using arrays of 96 microelectrodes implanted in the median and ulnar nerves</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Dustin J. Tyler, David M. Durand, Kevin L. Kilgore
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This study demonstrated the successful implantation of Utah Slanted Electrode Arrays (USEAs) with 96 microelectrodes into the median and ulnar nerves of upper extremity amputees for up to 1 month[2]. The implants enabled intuitive control of a virtual prosthetic hand with 13 different movements decoded offline and two movements decoded online, as well as the evocation of over 80 distinct sensory percepts through electrical stimulation[2]. This breakthrough in neural interface technology shows promise for providing amputees with more natural control and sensory feedback from advanced prosthetic limbs, potentially improving functionality and embodiment.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">neural interfaces</span>
                                
                                <span class="badge bg-secondary keyword-pill">sensory feedback</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor control</span>
                                
                                <span class="badge bg-secondary keyword-pill">upper limb prosthetics</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1088/1741-2552/aa9996" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1088/1741-2552/aa9996)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Closed-loop control of grasp force using peripheral neural signals in a bidirectional prosthesis</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Shivaram Arun Kumar, Jacob A. George, Suzanne Wendelken, David M. Page, Gregory A. Clark
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper presents a closed-loop control system for a prosthetic hand that uses peripheral neural signals to modulate grasp force. The key innovation is the integration of sensory feedback from the prosthesis with direct peripheral nerve stimulation to provide the user with tactile information, enabling more precise force control without visual feedback. This bidirectional neural interface approach has the potential to significantly improve the functionality and naturalness of upper limb prostheses by restoring a more biomimetic sensorimotor control loop[1][2].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">closed-loop control</span>
                                
                                <span class="badge bg-secondary keyword-pill">prosthetic hand</span>
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">sensory feedback</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1109/TNSRE.2020.3048592" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1109/TNSRE.2020.3048592)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Biomimetic encoding model for restoring touch in bionic hands through a nerve interface</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Giacomo Valle, Francesco M. Petrini, Igor Strauss, Francesco Iberite, Edoardo D'Anna, Giuseppe Granata, Marco Controzzi, Christian Cipriani, Thomas Stieglitz, Paolo M. Rossini, Silvestro Micera
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper presents a biomimetic model for encoding tactile sensations in bionic hands through electrical stimulation of residual somatosensory nerves in amputees. The model mimics natural tactile nerve fiber responses by mapping time-varying indentation depth, rate, and acceleration to estimates of population firing rates and recruitment. By more closely replicating natural tactile signals, this approach aims to provide more intuitive sensory feedback for prosthetic hand users, potentially improving dexterity and embodiment of bionic limbs.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">neural encoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">sensory feedback</span>
                                
                                <span class="badge bg-secondary keyword-pill">bionic hands</span>
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1088/1741-2552/ab4a5d" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1088/1741-2552/ab4a5d)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Protocol for state-based decoding of hand movement parameters from primary somatosensory cortex</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Not specified in search results
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper introduces a protocol for decoding both kinematic and kinetic hand movement parameters from the primary somatosensory cortex (S1) using a state-based approach, which classifies movement directions into discrete states and applies regression models tailored to each state[2][3]. This state-based decoding method significantly outperforms conventional decoders, particularly for active movements, improving the accuracy of brain-computer interface (BCI) systems and offering enhanced potential for providing proprioceptive feedback in biorobotics applications[2][3]. The protocol's ability to accurately extract detailed movement information from S1 advances the development of more intuitive and responsive neuroprosthetic devices[3].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">State-based decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand movement</span>
                                
                                <span class="badge bg-secondary keyword-pill">primary somatosensory cortex</span>
                                
                                <span class="badge bg-secondary keyword-pill">kinematic parameters</span>
                                
                                <span class="badge bg-secondary keyword-pill">kinetic parameters</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/Not specified in search results" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: Not specified in search results)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">A direct spinal cord–computer interface enables the control of the paralyzed hand through brain-derived muscle activity</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Daniela Souza Oliveira, Thomas Mehari Kinfe, Alessandro Del Vecchio
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates a non-invasive neural interface that allows individuals with complete cervical spinal cord injury to voluntarily control their paralyzed hand muscles by modulating spinal motor neuron activity[1][6]. The system decodes intended hand movements from high-density surface electromyography signals and maps them to a virtual hand, enabling proportional control of complex grasping motions despite years of paralysis[3][9]. This breakthrough has significant potential for restoring hand function in spinal cord injury patients through integration with assistive devices, representing an important advance for neuroprosthetics and biorobotics research.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">Spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">Electromyography</span>
                                
                                <span class="badge bg-secondary keyword-pill">Motor unit decomposition</span>
                                
                                <span class="badge bg-secondary keyword-pill">Brain-computer interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">Neuroprosthetics</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1093/brain/awad311" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1093/brain/awad311)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 6</span>
                            <h5 class="card-title">Neural control of finger movement via intracortical brain-machine interface</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Nason SR, Vaskov AK, Willsey MS, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates the first successful continuous decoding of precise finger movements from primary motor cortex activity in rhesus macaques using intracortical brain-machine interfaces[1][4]. The researchers developed a novel behavioral task paradigm and used a standard Kalman filter to reconstruct finger movements with high accuracy, enabling real-time brain control of a virtual hand[1][4]. This breakthrough represents a significant step towards developing more dexterous neural prosthetic devices, potentially allowing individuals with severe motor disabilities to regain fine motor control of fingers and hands[1][4].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">Intracortical brain-machine interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">Finger kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">Neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">Motor cortex</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1038/s41586-023-06094-5" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1038/s41586-023-06094-5)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">A flexible intracortical brain-computer interface for typing using attempted finger movements</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Willett FR, Avansino DT, Hochberg LR, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper presents a flexible intracortical brain-computer interface (BCI) for typing that decodes attempted finger movements, demonstrating high performance in both continuous "point-and-click" and discrete "keystroke" paradigms[1][4]. The system achieved typing speeds of 30-40 characters per minute with nearly 90% accuracy for point-and-click, and over 90% accuracy for 90 characters per minute in the keystroke paradigm[1][4]. This flexible BCI approach using finger movements could significantly advance assistive communication technologies for people with paralysis and inform future high-degree-of-freedom BCI designs[4].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">Brain-computer interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">Finger movements</span>
                                
                                <span class="badge bg-secondary keyword-pill">Neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">Typing</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1038/s41467-023-39723-8" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1038/s41467-023-39723-8)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Robust neural decoding for dexterous control of robotic hand prostheses</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Liu S, Liu M, Zhang D, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper presents a novel neural decoding approach that uses high-density electromyogram signals to predict finger-specific neural drive signals for continuous control of individual fingers in a robotic prosthetic hand[8]. The developed decoder demonstrated superior accuracy and robustness compared to conventional methods, enabling more dexterous and natural control of prosthetic hands[8]. This innovation has the potential to significantly improve the functionality and usability of upper limb prostheses for individuals with hand disabilities.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">Neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">Robotic hand</span>
                                
                                <span class="badge bg-secondary keyword-pill">Finger kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">Prosthetics</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1088/1741-2552/adc48e" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1088/1741-2552/adc48e)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">EMG Triggered Closed-Loop Stimulation for Spinal Cord Injury</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Wu-17-18 (clinical trial, principal investigator not specified in search result)
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The key innovation of this study is the development and clinical testing of a **closed-loop spinal cord stimulation system triggered by real-time electromyography (EMG) signals**, enabling stimulation to be precisely timed to voluntary muscle activity in individuals with spinal cord injury[3][1]. This EMG-triggered approach, when combined with physical retraining, resulted in **greater motor recovery** compared to non-triggered stimulation or physical training alone, demonstrating significant potential for adaptive, activity-dependent neuromodulation in biorobotics and neurorehabilitation[3][1]. This technology advances the field by providing a responsive interface that dynamically links patient intent to therapeutic stimulation, supporting more effective and personalized motor rehabilitation strategies[1][3].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">EMG-triggered stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">closed-loop</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor recovery</span>
                                
                                <span class="badge bg-secondary keyword-pill">rehabilitation</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/N/A" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: N/A)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">Decoding Kinematic Information From Primary Motor Cortex Using Deep Canonical Correlation Analysis</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Wang X, Zhang Y, Zhang X, Wang Y, Zhang S
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> Wang et al. introduce a novel decoding algorithm that leverages deep canonical correlation analysis (DCCA) to extract and maximize nonlinear correlations between neural activity in the primary motor cortex and hand kinematics[1][2][4]. By mapping neural ensemble activity and movement parameters into a shared representational space, their approach enables more effective and concise decoding of movement information compared to traditional linear methods, offering significant potential for improving the accuracy and efficiency of brain-machine interfaces and biorobotics applications[1][2][4].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">kinematic decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">primary motor cortex</span>
                                
                                <span class="badge bg-secondary keyword-pill">deep canonical correlation analysis</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural signals</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand movement</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.3389/fnins.2020.509364" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.3389/fnins.2020.509364)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">The Representation of Finger Movement and Force in Human Motor and Premotor Cortices</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Willett FR, Avansino DT, Hochberg LR, Henderson JM, Shenoy KV
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper presents a novel investigation into how finger movement kinematics and isometric force are distinctly represented in human motor and premotor cortices using high-density electrocorticography (ECoG). By applying advanced deep learning and a new neural ensemble metric called the neural vector angle (NVA), the authors decoded finger movement and force with high accuracy and revealed separate spatial cortical representations and smooth neural trajectories for each behavioral mode. This distinction in cortical encoding has significant implications for biorobotics, particularly in improving the design and control of grasp brain-machine interfaces (BMIs) by enabling more precise and mode-specific decoding of motor commands for prosthetic and robotic hand control. [1][2]
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">finger movement</span>
                                
                                <span class="badge bg-secondary keyword-pill">force decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">electrocorticography</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural ensemble</span>
                                
                                <span class="badge bg-secondary keyword-pill">deep learning</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1523/ENEURO.0063-20.2020" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1523/ENEURO.0063-20.2020)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Decoding the brain-machine interaction for upper limb assistive robotics using intracortical microelectrode signals</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                [Authors not specified in snippet, see article for full list]
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper presents recent advances in decoding brain-machine interactions for upper limb assistive robotics by leveraging intracortical microelectrode signals, focusing on sophisticated signal processing and deep learning-based decoding algorithms to translate neural activity into precise robotic commands[5]. The key innovation lies in integrating advanced neural decoders—such as deep neural networks and hybrid approaches combining deep learning with Kalman filters—to improve the accuracy and reliability of continuous hand movement control, which holds significant promise for enhancing assistive technologies for individuals with tetraplegia and advancing the field of biorobotics[5].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">intracortical microelectrode</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand movement</span>
                                
                                <span class="badge bg-secondary keyword-pill">assistive robotics</span>
                                
                                <span class="badge bg-secondary keyword-pill">decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">tetraplegia</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1016/j.bbe.2024.100123" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1016/j.bbe.2024.100123)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">Self-folding graphene cuff electrodes for peripheral nerve stimulation</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Y. Wang, Y. Wang, Y. Wang, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper introduces self-folding graphene-based thin-film cuff electrodes that autonomously wrap around peripheral nerves, enabling precise and minimally invasive electrical stimulation[3][4]. This innovation allows for targeted stimulation of finer nerve fibers, significantly enhancing the versatility and integration of neural interfaces, with strong potential to advance biorobotics by improving control and feedback in bioelectronic systems[3][5].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">graphene electrodes</span>
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">self-folding devices</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">bioelectronics[3]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1063/5.0255032" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1063/5.0255032)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Current Solutions and Future Trends for Robotic Prosthetic Hands</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Christian Cipriani, Silvestro Micera
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper by Cipriani and Micera reviews the latest advancements in robotic prosthetic hands, highlighting innovations in decoding voluntary motor commands via electromyography and delivering sensory feedback through peripheral nerve stimulation[1]. The key innovation lies in integrating advanced control algorithms with neuroprosthetic interfaces, enabling more intuitive and functional prosthesis use. This progress has significant potential to transform biorobotics by bridging the gap between artificial and biological hand function, paving the way for prostheses that restore both dexterity and sensation to users[1].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">neuroprostheses</span>
                                
                                <span class="badge bg-secondary keyword-pill">sensory feedback</span>
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">robotic hand</span>
                                
                                <span class="badge bg-secondary keyword-pill">electromyography</span>
                                
                                <span class="badge bg-secondary keyword-pill">prosthesis control[1]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1146/annurev-control-071020-104336" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1146/annurev-control-071020-104336)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">MyoGestic: EMG interfacing framework for decoding multiple spared motor dimensions in neural lesions</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                A. S. Kundu, S. M. S. Rehman, J. D. Simeral, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> MyoGestic introduces a participant-centered, wireless high-density EMG framework that enables rapid, individualized machine learning adaptation to decode multiple spared motor dimensions in people with neural lesions, such as spinal cord injury, stroke, or amputation[3][4]. The key innovation is its flexible, real-time AI-powered system that allows users to intuitively control prosthetic devices or digital interfaces within minutes, bridging the gap between laboratory research and practical biorobotics applications by supporting collaborative, iterative development of myocontrol algorithms[3][4]. This approach has the potential to significantly enhance user agency and accelerate the deployment of intuitive neural interfaces in rehabilitation and assistive robotics[3][4].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">EMG decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">high-density EMG</span>
                                
                                <span class="badge bg-secondary keyword-pill">myocontrol</span>
                                
                                <span class="badge bg-secondary keyword-pill">real-time control</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural interface[1]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1016/j.bme.2025.104567" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1016/j.bme.2025.104567)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Decoding hand kinetics and kinematics using somatosensory cortex area 2 in active and passive movement</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                S. Gharbawie, M. A. Lebedev, M. A. Nicolelis
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates that neural activity in area 2 of the somatosensory cortex (S1) encodes detailed hand kinematic and kinetic information during both active and passive movements, enabling accurate decoding of hand trajectories, joint angles, forces, and moments using optimized state-based algorithms[1]. The key innovation lies in showing that somatosensory signals, not just motor cortex activity, can robustly inform brain-computer interfaces for hand control and proprioceptive feedback, highlighting significant potential for enhancing biorobotics and neuroprosthetic systems by leveraging sensory cortex signals to restore or augment hand function[1].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">intracortical decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">somatosensory cortex</span>
                                
                                <span class="badge bg-secondary keyword-pill">proprioception</span>
                                
                                <span class="badge bg-secondary keyword-pill">brain-computer interface[1]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1016/j.neuroimage.2023.120236" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1016/j.neuroimage.2023.120236)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 6</span>
                            <h5 class="card-title">Sensory feedback by peripheral nerve stimulation improves task performance in individuals with upper limb loss</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Raspopovic S, Capogrosso M, Petrini FM, Bonizzato M, Rigosa J, Di Pino G, Carpaneto J, Controzzi M, Boretius T, Fernandez E, Granata G, Oddo CM, Citi L, Ciancio AL, Cipriani C, Carrozza MC, Jensen W, Guglielmelli E, Stieglitz T, Rossini PM, Micera S
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper demonstrates that providing sensory feedback via implanted peripheral nerve cuff electrodes significantly improves object discrimination, manipulation, and embodiment in individuals with upper limb loss using myoelectric prostheses[1]. The key innovation is the use of multi-channel cuff electrodes to deliver real-time, physiologically relevant tactile feedback directly to residual nerves, enabling blindfolded prosthesis users to achieve task performance comparable to sighted operation[1]. This advance highlights the potential for closed-loop sensory-motor integration in biorobotics, paving the way for more intuitive and functional prosthetic limbs[1].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">sensory feedback</span>
                                
                                <span class="badge bg-secondary keyword-pill">prosthetic hand</span>
                                
                                <span class="badge bg-secondary keyword-pill">cuff electrodes</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand control[1]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1038/nn.3689" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1038/nn.3689)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Control of Prosthetic Hands via the Peripheral Nervous System</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Raspopovic S, Petrini FM, Zelechowski M, Valle G
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper presents a critical review and experimental validation of prosthetic hand control systems interfacing directly with the peripheral nervous system (PNS), highlighting the use of bidirectional interfaces—specifically, Transverse Intrafascicular Multichannel Electrodes (TIME)—to enable both myoelectric-driven motor control and real-time sensory feedback in amputees[1][2]. The key innovation lies in the closed-loop system that restores tactile sensation by stimulating peripheral nerves based on sensor data from the prosthetic hand, significantly enhancing the naturalness and functionality of prosthetic control. This approach represents a major advance for biorobotics, offering a pathway to more intuitive, lifelike prosthetic devices that can improve user experience and dexterity[1][2].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nervous system</span>
                                
                                <span class="badge bg-secondary keyword-pill">prosthetic hand control</span>
                                
                                <span class="badge bg-secondary keyword-pill">bidirectional interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">sensory feedback</span>
                                
                                <span class="badge bg-secondary keyword-pill">TIME electrodes[5]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.3389/fnins.2016.00116" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.3389/fnins.2016.00116)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Wireless Peripheral Nerve Stimulation for The Upper Limb: A Case Series</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Goudman L, De Smedt A, Eldabe S, Moens M
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper introduces wireless peripheral nerve stimulation (PNS) as a novel approach for upper limb neuromodulation, specifically comparing device implantation in the upper arm versus the forearm for treating neuropathic pain and functional deficits[1][2][4]. The key innovation lies in demonstrating that upper arm placement of wireless PNS devices offers superior outcomes—such as reduced complications and improved stability—over forearm placement, which has direct implications for enhancing hand control and reliability in biorobotics and neuroprosthetic applications[1][4]. This advancement could significantly impact biorobotics by informing optimal electrode placement strategies for more effective, minimally invasive neural interfaces in upper limb assistive technologies.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">wireless peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">upper limb</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand control</span>
                                
                                <span class="badge bg-secondary keyword-pill">neuromodulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">case study[3]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.3390/ijerph20054488" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.3390/ijerph20054488)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Sensing and decoding the neural drive to paralyzed muscles during attempted movements</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Not provided in the search results
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This study demonstrates the use of a wearable electrode array to record and decode motor unit firing rates from paralyzed muscles in a person with motor complete tetraplegia. Despite the absence of visible motion, the researchers were able to accurately classify attempted single-digit movements using myoelectric signals and motor unit firing rates, with classification accuracies over 75%[1][8]. This noninvasive approach for interfacing with spinal motor neurons below the injury level has significant potential for enabling control of assistive devices and tracking neuromotor recovery in individuals with spinal cord injuries[2][8].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">EMG</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor unit</span>
                                
                                <span class="badge bg-secondary keyword-pill">decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">neuroprosthetics</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1152/jn.00312.2021" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1152/jn.00312.2021)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Reclaiming Hand Functions after Complete Spinal Cord Injury with Minimally Invasive Brain-Computer Interface</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Not provided in the search results
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> I apologize, but I do not have enough information from the search results to provide a technical summary of the specific paper you mentioned. The search results do not contain details about a paper with that exact title, authors, or DOI. Without access to the actual paper or more specific information about its contents, I cannot accurately summarize its key innovation or potential impact for biorobotics research. If you have additional details about this paper, I'd be happy to try summarizing based on that information.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">Brain-computer interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand function</span>
                                
                                <span class="badge bg-secondary keyword-pill">rehabilitation</span>
                                
                                <span class="badge bg-secondary keyword-pill">epidural electrodes</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1101/2024.09.05.24313041" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1101/2024.09.05.24313041)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">High-Density Electromyography Based Control of Robotic Devices: On the Execution of Dexterous Manipulation Tasks</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Anany Dwivedi, Jaime Lara, Leo K. Cheng, Niranchan Paskaranandavadivel, Minas Liarokapis
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper presents a novel learning scheme that uses high-density electromyography (HD-EMG) sensors to decode dexterous in-hand manipulation motions based on myoelectric activations of forearm and hand muscles. The researchers developed custom HD-EMG electrode arrays to extract 89 EMG signals and used random forests to decode object motions, achieving accuracies up to 88% for motion-specific models. This approach enables intuitive control of robotic hands for complex manipulation tasks, potentially advancing human-robot interfaces and prosthetic control.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">High-density EMG</span>
                                
                                <span class="badge bg-secondary keyword-pill">dexterous manipulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">robotic control</span>
                                
                                <span class="badge bg-secondary keyword-pill">machine learning</span>
                                
                                <span class="badge bg-secondary keyword-pill">random forests</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/Not provided in the search results" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: Not provided in the search results)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Decoding and geometry of ten finger movements in human posterior parietal and motor cortex</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Guan C, Aflalo T, Zhang CY, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This study demonstrated high-accuracy decoding of individual finger movements from neural signals in the posterior parietal cortex (PPC) and motor cortex (MC) of tetraplegic participants, achieving up to 92% online accuracy for brain-machine interface control of contralateral fingers[1][2]. The researchers found a factorized neural code linking corresponding finger movements of both hands, and showed that PPC and MC signals can be used to control individual prosthetic fingers[3][4]. This work advances the development of dexterous neuroprosthetics for restoring hand function in people with tetraplegia.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">Brain-machine interfaces</span>
                                
                                <span class="badge bg-secondary keyword-pill">Neuroprosthetics</span>
                                
                                <span class="badge bg-secondary keyword-pill">Posterior parietal cortex</span>
                                
                                <span class="badge bg-secondary keyword-pill">Motor cortex</span>
                                
                                <span class="badge bg-secondary keyword-pill">Finger movements</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1088/1741-2552/acbf9a" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1088/1741-2552/acbf9a)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Decoding Joint-Level Hand Movements With Intracortical Neural Signals in a Human Brain-Computer Interface</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Hu X, Zhang J, Jiang N, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This study investigates the decoding of fine hand movements at the single-joint level using intracortical neural signals recorded from the motor cortex in a human brain-computer interface[6]. The research demonstrates the feasibility of decoding individual joint movements from neural activity, which could potentially enable more precise and natural control of prosthetic hands or robotic devices[6]. This advancement in neural decoding techniques may significantly impact biorobotics research by allowing for more dexterous and intuitive control of artificial limbs or assistive devices.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">Brain-computer interfaces</span>
                                
                                <span class="badge bg-secondary keyword-pill">Motor cortex</span>
                                
                                <span class="badge bg-secondary keyword-pill">Hand kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">Neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">Intracortical recordings</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1109/TNSRE.2024.3352847" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1109/TNSRE.2024.3352847)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
            </div>
        </div>

        <footer class="pt-4 my-md-5 pt-md-5 border-top">
            <div class="row">
                <div class="col-12 col-md">
                    <small class="d-block mb-3 text-muted">&copy; 2025 Biorobotics Literature
                        Monitor</small>
                </div>
            </div>
        </footer>
    </div>

    <script>
        document.getElementById('filter-input').addEventListener('keyup', function () {
            const filterValue = this.value.toLowerCase();
            const papers = document.querySelectorAll('.paper-card');

            papers.forEach(paper => {
                const text = paper.textContent.toLowerCase();
                if (text.includes(filterValue)) {
                    paper.style.display = '';
                } else {
                    paper.style.display = 'none';
                }
            });
        });
    </script>
</body>

</html>