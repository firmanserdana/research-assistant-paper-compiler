<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Biorobotics Literature Monitor</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <style>
        .paper-card {
            margin-bottom: 1.5rem;
            transition: transform 0.2s;
        }

        .paper-card:hover {
            transform: translateY(-3px);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }

        .trl-badge {
            position: absolute;
            top: 10px;
            right: 10px;
        }

        .keyword-pill {
            margin-right: 0.3rem;
            margin-bottom: 0.3rem;
        }

        #filter-input {
            margin-bottom: 1.5rem;
        }

        .category-section {
            margin-top: 2rem;
            padding-top: 1rem;
            border-top: 1px solid #eee;
        }

        .paper-summary {
            font-size: 0.9rem;
            color: #555;
            margin-top: 0.8rem;
        }
    </style>
</head>

<body>
    <div class="container py-4">
        <header class="pb-3 mb-4 border-bottom">
            <div class="d-flex align-items-center justify-content-between">
                <h1>Biorobotics Literature Monitor</h1>
                <span class="badge bg-primary">Last updated: 2026-02-02 11:05</span>
            </div>
            <p class="lead text-muted">Recent advances in biomedical engineering and robotics</p>
        </header>
        <div class="row mb-4">
            <div class="col-md-12">
                <div class="alert alert-info">
                    <strong>0</strong> new papers have been added to the collection.
                    <span class="float-end">Total papers: <strong>10</strong></span>
                </div>
                <input type="text" id="filter-input" class="form-control"
                    placeholder="Filter papers by title, author, or keyword...">
            </div>
        </div>

        <!-- Debug information -->
        

        <!-- Display papers directly if categories aren't working -->
        <div class="category-section">
            <h2>All Papers</h2>
            <div class="row">
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Decoding hand kinematics from population responses towards a dexterous brain-machine interface</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Matthew D. Golub, Byron M. Yu, Andrew M. Schwartz, Matthew C. Whitford, Jean P. Clavert, Lee E. Miller
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper introduces a key innovation in intracortical decoding by accurately estimating kinematics across **30 hand joints** (angles outperforming velocities) from small populations of neurons in sensorimotor cortex and superior colliculus (SC), enabling precise control of dexterous hand movements in brain-machine interfaces (BMIs).[1] Unlike prior proximal limb decoders, it leverages SC's postural representations, which could be exploited via intracortical stimulation to close the sensorimotor loop.[1] For biorobotics, this advances high-fidelity neural control of multi-jointed prosthetic hands, potentially transforming rehabilitation by restoring naturalistic manipulation beyond reach-and-grasp paradigms.[1] ---
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">intracortical decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">joint angles</span>
                                
                                <span class="badge bg-secondary keyword-pill">brain-machine interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">sensorimotor cortex[1]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.48550/arXiv.1904." target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.48550/arXiv.1904.)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">State-based decoding of hand and finger kinematics using neuronal ensemble and local field potential from motor cortex</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                V. Aggarwal, S. N. Katyal, M. V. gombolay, B. E. Gale, M. H. Schieber, M. A. L. Nicolelis, N. V. Thakor
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper introduces a **state-based decoding approach** that first classifies motor cortex neuronal ensemble spikes and local field potentials (LFPs) into discrete behavioral states (baseline, reaction, movement, hold) during reach-to-grasp tasks, then applies state-specific kinematic decoders to predict hand and finger positions, velocities, and orientations.[4] The key innovation lies in leveraging state segmentation to enhance decoding precision over continuous methods, capitalizing on the structured dynamics of motor cortex activity for more accurate trajectory reconstruction.[4][6] For biorobotics, this advances neuroprostheses by enabling finer-grained control of dexterous hand movements, potentially improving brain-machine interfaces for prosthetic limbs with real-time, state-aware responsiveness.[4] --- ## Stimulating Peripheral Nerve To Enable Hand And/or Finger Control (2 papers)
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">state decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">kinematic decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">local field potentials</span>
                                
                                <span class="badge bg-secondary keyword-pill">reach-to-grasp</span>
                                
                                <span class="badge bg-secondary keyword-pill">neuroprosthesis[3]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1101/" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1101/)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Evoking stable and precise tactile sensations via multi-electrode intracortical microstimulation in human somatosensory cortex</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Christopher L. Hughes, Matthew S. Fifer, David M. Rose, Tessy M. Thomas, Nathan E. Crone, Brock A. Wester, others[2]
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This study demonstrates that **multi-electrode intracortical microstimulation (ICMS)** in the primary somatosensory cortex (S1) of tetraplegic humans evokes stable, somatotopically matched perceptual fields (PFs) with controllable size, shape, and intensity via amplitude and frequency modulation, where overlapping PFs summate to produce more focal, localizable, and gradated sensations mimicking natural touch.[1] A key innovation is the precise mapping of bionic hand force sensors to corresponding S1 electrodes, enabling amplitude-modulated ICMS to convey object contact force and location with improved dynamic range and discriminability over single-electrode stimulation.[1] For **biorobotics research**, this advances brain-computer interfaces by restoring intuitive tactile feedback for prosthetic control, potentially enhancing grip precision and object manipulation in real-world tasks despite limitations in high-force dynamic range.[1] ---
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">**Intracortical microstimulation**</span>
                                
                                <span class="badge bg-secondary keyword-pill">Tactile feedback</span>
                                
                                <span class="badge bg-secondary keyword-pill">Robotic hand</span>
                                
                                <span class="badge bg-secondary keyword-pill">Brain–computer interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">Multi-electrode stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">Somatosensory cortex</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1038/s41551-024-01299-z" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1038/s41551-024-01299-z)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">Pseudo-linear summation explains neural geometry of multi-finger movements in human motor cortex</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                [Author list not fully visible in preview, Nature Communications paper—use full citation when available]
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper shows that multi-finger movements in human premotor cortex are encoded by a **pseudo-linear summation** of single-finger activity: population trajectories for combined movements align with the linear sum of constituent single-finger trajectories, but with two key deviations—global magnitude normalization across finger counts and tuning changes for weakly represented fingers—yielding a low-dimensional geometry (>95% variance in 5 PCs) that supports compositional control[2]. These deviations make **non-linear decoders** outperform linear ones for multi-finger decoding from intracortical threshold crossings and motivate BCI designs that leverage compositional priors for rapid generalization to dexterous skills (e.g., typing, piano) in biorobotics[2][1]. ---
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">multi-finger decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural population geometry</span>
                                
                                <span class="badge bg-secondary keyword-pill">non-linear decoders</span>
                                
                                <span class="badge bg-secondary keyword-pill">threshold crossings</span>
                                
                                <span class="badge bg-secondary keyword-pill">low-dimensional manifolds</span>
                                
                                <span class="badge bg-secondary keyword-pill">finger velocity/position tuning[2]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1038/s41467-025-59039-z" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1038/s41467-025-59039-z)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Real-time decoding of individual finger movements from noninvasive brain signals enables dexterous robotic hand control</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Yidan Ding, Chalisa Udompanyawit, Yisha Zhang, Bin He
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper introduces a **real-time EEG-based brain-computer interface (BCI) that decodes individual finger movements using deep learning, enabling dexterous, finger-level control of a robotic hand**[5][6]. The key innovation is the demonstration that noninvasive EEG signals can be reliably and rapidly translated into fine-grained, multi-finger robotic actions, overcoming previous limitations of noninvasive BCIs that could only achieve coarse or grouped finger control[5][6]. This advance holds significant potential for biorobotics, as it paves the way for more naturalistic, high-DOF prosthetic and assistive devices controlled directly by users’ brain activity, expanding the capabilities and accessibility of neurotechnology for rehabilitation and human-robot interaction[5][6]. ---
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">EEG-based BCI</span>
                                
                                <span class="badge bg-secondary keyword-pill">finger-level robotic control</span>
                                
                                <span class="badge bg-secondary keyword-pill">deep learning</span>
                                
                                <span class="badge bg-secondary keyword-pill">noninvasive neurotechnology[2]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1038/s41467-025-60818-x" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1038/s41467-025-60818-x)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">MyoGestic: EMG interfacing framework for decoding multiple spared motor dimensions after neural lesions</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Y. Zhang, S. S. Raspopovic, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> MyoGestic introduces a wireless, high-density EMG bracelet and adaptive software framework that rapidly decodes multiple spared motor dimensions in individuals with neural lesions using advanced machine learning, enabling real-time, intuitive control of prosthetic devices or digital interfaces[1][4][5]. The key innovation lies in its participant-centered, customizable approach, which allows for collaborative algorithm development tailored to individual users’ residual motor signals, significantly advancing the potential for practical, user-adaptable neural interfaces in biorobotics and rehabilitation research[2][3][4]. --- ## Intracortical Decoding On Hand And Finger Kinematics (3 papers)
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">EMG decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">high-density EMG</span>
                                
                                <span class="badge bg-secondary keyword-pill">myocontrol</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural interface[1][5]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1101/2024.04.09." target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1101/2024.04.09.)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">Decoding hand kinetics and kinematics using somatosensory cortex activity in non-human primates</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Abbasi, Adeel, Chao, Zenas C., Ghanbari, Ladan, Torab, Kian, Yazdan-Shahmorad, Azadeh
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This study demonstrates that hand kinematics and kinetics can be accurately decoded from neural activity in area 2 of the primary somatosensory cortex (S1) in non-human primates during both active and passive hand movements. The researchers found that kinematics were decoded with higher accuracy than kinetics, and active movements were decoded more accurately than passive ones. These findings suggest that area 2 of S1 could potentially be used as a source of proprioceptive feedback signals in brain-computer interfaces for restoring or augmenting hand function. ---
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">somatosensory cortex</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">brain-computer interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">non-human primates</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1038/s41598-023-40664-x" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1038/s41598-023-40664-x)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Robust neural decoding for dexterous control of robotic hand prostheses</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Liu S, Liu M, Zhang D, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper presents a novel neural decoding approach that uses high-density electromyogram signals to predict finger-specific neural drive signals for continuous control of individual fingers in a robotic prosthetic hand[8]. The developed decoder demonstrated superior accuracy and robustness compared to conventional methods, enabling more dexterous and natural control of prosthetic hands[8]. This innovation has the potential to significantly improve the functionality and usability of upper limb prostheses for individuals with hand disabilities. ---
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">Neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">Robotic hand</span>
                                
                                <span class="badge bg-secondary keyword-pill">Finger kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">Prosthetics</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1088/1741-2552/adc48e" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1088/1741-2552/adc48e)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Wireless Peripheral Nerve Stimulation for The Upper Limb: A Case Series</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Goudman L, De Smedt A, Eldabe S, Moens M
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper introduces wireless peripheral nerve stimulation (PNS) as a novel approach for upper limb neuromodulation, specifically comparing device implantation in the upper arm versus the forearm for treating neuropathic pain and functional deficits[1][2][4]. The key innovation lies in demonstrating that upper arm placement of wireless PNS devices offers superior outcomes—such as reduced complications and improved stability—over forearm placement, which has direct implications for enhancing hand control and reliability in biorobotics and neuroprosthetic applications[1][4]. This advancement could significantly impact biorobotics by informing optimal electrode placement strategies for more effective, minimally invasive neural interfaces in upper limb assistive technologies. ---
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">wireless peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">upper limb</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand control</span>
                                
                                <span class="badge bg-secondary keyword-pill">neuromodulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">case study[3]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.3390/ijerph" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.3390/ijerph)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Reclaiming Hand Functions after Complete Spinal Cord Injury with Minimally Invasive Brain-Computer Interface</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Not provided in the search results
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> I apologize, but I do not have enough information from the search results to provide a technical summary of the specific paper you mentioned. The search results do not contain details about a paper with that exact title, authors, or DOI. Without access to the actual paper or more specific information about its contents, I cannot accurately summarize its key innovation or potential impact for biorobotics research. If you have additional details about this paper, I'd be happy to try summarizing based on that information. ---
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">Brain-computer interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand function</span>
                                
                                <span class="badge bg-secondary keyword-pill">rehabilitation</span>
                                
                                <span class="badge bg-secondary keyword-pill">epidural electrodes</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1101/2024.09.05." target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1101/2024.09.05.)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
            </div>
        </div>

        <footer class="pt-4 my-md-5 pt-md-5 border-top">
            <div class="row">
                <div class="col-12 col-md">
                    <small class="d-block mb-3 text-muted">&copy; 2026 Biorobotics Literature
                        Monitor</small>
                </div>
            </div>
        </footer>
    </div>

    <script>
        document.getElementById('filter-input').addEventListener('keyup', function () {
            const filterValue = this.value.toLowerCase();
            const papers = document.querySelectorAll('.paper-card');

            papers.forEach(paper => {
                const text = paper.textContent.toLowerCase();
                if (text.includes(filterValue)) {
                    paper.style.display = '';
                } else {
                    paper.style.display = 'none';
                }
            });
        });
    </script>
</body>

</html>