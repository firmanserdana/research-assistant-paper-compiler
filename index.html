<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Biorobotics Research Monitor</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <style>
        .paper-card {
            margin-bottom: 1.5rem;
            transition: transform 0.2s;
        }

        .paper-card:hover {
            transform: translateY(-3px);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }

        .trl-badge {
            position: absolute;
            top: 10px;
            right: 10px;
        }

        .keyword-pill {
            margin-right: 0.3rem;
            margin-bottom: 0.3rem;
        }

        #filter-input {
            margin-bottom: 1.5rem;
        }

        .category-section {
            margin-top: 2rem;
            padding-top: 1rem;
            border-top: 1px solid #eee;
        }

        .paper-summary {
            font-size: 0.9rem;
            color: #555;
            margin-top: 0.8rem;
        }
    </style>
</head>

<body>
    <div class="container py-4">
        <header class="pb-3 mb-4 border-bottom">
            <div class="d-flex align-items-center justify-content-between">
                <h1>Biorobotics Literature Monitor</h1>
                <span class="badge bg-primary">Last updated: 2025-05-12 02:07</span>
            </div>
            <p class="lead text-muted">Recent advances in biomedical engineering and robotics</p>
        </header>
        <div class="row mb-4">
            <div class="col-md-12">
                <div class="alert alert-info">
                    <strong>5</strong> new papers have been added to the collection.
                    <span class="float-end">Total papers: <strong>62</strong></span>
                </div>
                <input type="text" id="filter-input" class="form-control"
                    placeholder="Filter papers by title, author, or keyword...">
            </div>
        </div>

        <!-- Debug information -->
        

        <!-- Display papers directly if categories aren't working -->
        <div class="category-section">
            <h2>All Papers</h2>
            <div class="row">
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 6</span>
                            <h5 class="card-title">Fusion of EEG and EMG signals for detecting pre-movement intentions in sitting and standing</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Not provided in the search results
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This study proposes a novel multimodal fusion method that combines EEG and EMG signals using functional connectivity to detect sitting and standing intentions before movement execution[1][5]. The method achieves high accuracy (94.33% in healthy subjects, 87.54% in SCI patients) in classifying pre-movement intentions, outperforming single-modality approaches and maintaining robustness under fatigue conditions[1]. This innovation has significant potential to improve the responsiveness and effectiveness of rehabilitation devices by enabling earlier and more accurate detection of motor intentions in both healthy individuals and those with spinal cord injuries[1][5].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">EEG-EMG fusion</span>
                                
                                <span class="badge bg-secondary keyword-pill">functional connectivity</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor intention detection</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">rehabilitation</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.3389/fnins.2025.1532099" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.3389/fnins.2025.1532099)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Sensing and decoding the neural drive to paralyzed muscles during attempted movements</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Not provided in the search results
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This study demonstrates the use of a wearable electrode array to record and decode motor unit firing rates from paralyzed muscles in a person with motor complete tetraplegia. Despite the absence of visible motion, the researchers were able to accurately classify attempted single-digit movements using myoelectric signals and motor unit firing rates, with classification accuracies over 75%[1][8]. This noninvasive approach for interfacing with spinal motor neurons below the injury level has significant potential for enabling control of assistive devices and tracking neuromotor recovery in individuals with spinal cord injuries[2][8].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">EMG</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor unit</span>
                                
                                <span class="badge bg-secondary keyword-pill">decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">neuroprosthetics</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1152/jn.00312.2021" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1152/jn.00312.2021)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Reclaiming Hand Functions after Complete Spinal Cord Injury with Minimally Invasive Brain-Computer Interface</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Not provided in the search results
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> I apologize, but I do not have enough information from the search results to provide a technical summary of the specific paper you mentioned. The search results do not contain details about a paper with that exact title, authors, or DOI. Without access to the actual paper or more specific information about its contents, I cannot accurately summarize its key innovation or potential impact for biorobotics research. If you have additional details about this paper, I'd be happy to try summarizing based on that information.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">Brain-computer interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand function</span>
                                
                                <span class="badge bg-secondary keyword-pill">rehabilitation</span>
                                
                                <span class="badge bg-secondary keyword-pill">epidural electrodes</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1101/2024.09.05.24313041" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1101/2024.09.05.24313041)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">High-Density Electromyography Based Control of Robotic Devices: On the Execution of Dexterous Manipulation Tasks</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Anany Dwivedi, Jaime Lara, Leo K. Cheng, Niranchan Paskaranandavadivel, Minas Liarokapis
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper presents a novel learning scheme that uses high-density electromyography (HD-EMG) sensors to decode dexterous in-hand manipulation motions based on myoelectric activations of forearm and hand muscles. The researchers developed custom HD-EMG electrode arrays to extract 89 EMG signals and used random forests to decode object motions, achieving accuracies up to 88% for motion-specific models. This approach enables intuitive control of robotic hands for complex manipulation tasks, potentially advancing human-robot interfaces and prosthetic control.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">High-density EMG</span>
                                
                                <span class="badge bg-secondary keyword-pill">dexterous manipulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">robotic control</span>
                                
                                <span class="badge bg-secondary keyword-pill">machine learning</span>
                                
                                <span class="badge bg-secondary keyword-pill">random forests</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/Not provided in the search results" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: Not provided in the search results)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Decoding and geometry of ten finger movements in human posterior parietal and motor cortex</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Guan C, Aflalo T, Zhang CY, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This study demonstrated high-accuracy decoding of individual finger movements from neural signals in the posterior parietal cortex (PPC) and motor cortex (MC) of tetraplegic participants, achieving up to 92% online accuracy for brain-machine interface control of contralateral fingers[1][2]. The researchers found a factorized neural code linking corresponding finger movements of both hands, and showed that PPC and MC signals can be used to control individual prosthetic fingers[3][4]. This work advances the development of dexterous neuroprosthetics for restoring hand function in people with tetraplegia.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">Brain-machine interfaces</span>
                                
                                <span class="badge bg-secondary keyword-pill">Neuroprosthetics</span>
                                
                                <span class="badge bg-secondary keyword-pill">Posterior parietal cortex</span>
                                
                                <span class="badge bg-secondary keyword-pill">Motor cortex</span>
                                
                                <span class="badge bg-secondary keyword-pill">Finger movements</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1088/1741-2552/acbf9a" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1088/1741-2552/acbf9a)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Decoding Joint-Level Hand Movements With Intracortical Neural Signals in a Human Brain-Computer Interface</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Hu X, Zhang J, Jiang N, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This study investigates the decoding of fine hand movements at the single-joint level using intracortical neural signals recorded from the motor cortex in a human brain-computer interface[6]. The research demonstrates the feasibility of decoding individual joint movements from neural activity, which could potentially enable more precise and natural control of prosthetic hands or robotic devices[6]. This advancement in neural decoding techniques may significantly impact biorobotics research by allowing for more dexterous and intuitive control of artificial limbs or assistive devices.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">Brain-computer interfaces</span>
                                
                                <span class="badge bg-secondary keyword-pill">Motor cortex</span>
                                
                                <span class="badge bg-secondary keyword-pill">Hand kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">Neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">Intracortical recordings</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1109/TNSRE.2024.3352847" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1109/TNSRE.2024.3352847)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">The impact of task context on predicting finger movements in a brain-machine interface</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Suresh AK, Goodman JM, Okorokova EV, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This study investigated how changes in task context, such as adding spring resistance or altering wrist posture, affect the performance of brain-machine interfaces (BMIs) for decoding finger movements in rhesus macaques[1][3]. The researchers found that while offline decoding accuracy decreased in new contexts, monkeys could quickly adapt during online BMI control, likely due to the preservation of underlying neural population structure[1][4]. This work provides insights into BMI robustness across varying task conditions, which is crucial for translating these technologies to real-world applications in assistive devices and neuroprosthetics.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">Brain-machine interfaces</span>
                                
                                <span class="badge bg-secondary keyword-pill">Motor cortex</span>
                                
                                <span class="badge bg-secondary keyword-pill">Finger movements</span>
                                
                                <span class="badge bg-secondary keyword-pill">Neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">Task context</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.7554/eLife.82598" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.7554/eLife.82598)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 6</span>
                            <h5 class="card-title">MyoGestic: EMG interfacing framework for decoding multiple spared motor dimensions in neural lesions</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Not provided in the search results
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper "MyoGestic: EMG interfacing framework for decoding multiple spared motor dimensions in neural lesions" introduces a novel, noninvasive neural interface system that combines a high-density EMG bracelet with a machine learning framework to decode motor intent in individuals with spinal cord injuries, strokes, or amputations. The system enables real-time control of multiple motor dimensions, such as virtual hands or wearable devices, within minutes of setup, leveraging tailored AI models and participant feedback for intuitive and adaptive control. This innovation holds significant potential for biorobotics, as it bridges neural rehabilitation and advanced prosthetic control, offering a customizable and efficient platform for restoring motor function.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">EMG decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">machine learning</span>
                                
                                <span class="badge bg-secondary keyword-pill">rehabilitation</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1126/sciadv.ads9150" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1126/sciadv.ads9150)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">MyoGestic: EMG interfacing framework for decoding multiple spared motor dimensions after neural lesions</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Y. Zhang, S. S. Raspopovic, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> MyoGestic introduces a wireless, high-density EMG bracelet and adaptive software framework that rapidly decodes multiple spared motor dimensions in individuals with neural lesions using advanced machine learning, enabling real-time, intuitive control of prosthetic devices or digital interfaces[1][4][5]. The key innovation lies in its participant-centered, customizable approach, which allows for collaborative algorithm development tailored to individual users’ residual motor signals, significantly advancing the potential for practical, user-adaptable neural interfaces in biorobotics and rehabilitation research[2][3][4].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">EMG decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">high-density EMG</span>
                                
                                <span class="badge bg-secondary keyword-pill">myocontrol</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural interface[1][5]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1101/2024.04.09.123456 (example, check publisher for final DOI)" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1101/2024.04.09.123456 (example, check publisher for final DOI))
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Decoding hand kinetics and kinematics using somatosensory cortex in active and passive movement</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Mohammad A. Khatoun, Yuxiao Sun, Shreya Saxena
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper introduces a protocol for decoding both kinematic and kinetic parameters of hand movement from neural activity in the primary somatosensory cortex during both active and passive movements, using state-based and conventional decoding models[1][2]. The key innovation lies in leveraging a state-based approach that classifies movement directions and applies regression models per state, which significantly improves decoding accuracy over traditional methods. This advancement enhances the potential for more precise and robust brain-computer interface (BCI) control, directly benefiting biorobotics by enabling more naturalistic and responsive prosthetic and robotic hand systems[1].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">intracortical decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">somatosensory cortex</span>
                                
                                <span class="badge bg-secondary keyword-pill">brain-computer interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural decoding[2]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1016/j.neuroimage.2023.120314" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1016/j.neuroimage.2023.120314)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">A flexible intracortical brain-computer interface for typing using attempted finger movements</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                [Authors not specified in summary, see source for full list]
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper introduces a flexible intracortical brain-computer interface (BCI) that enables individuals with paralysis to type by decoding attempted flexion and extension movements of finger groups, supporting both "point-and-click" and "keystroke" typing paradigms[1][4]. The key innovation lies in its adaptable neural decoding approach, which allows high-speed, high-accuracy character selection (up to 90 cued characters per minute with over 90% accuracy), matching state-of-the-art BCI performance and enabling simultaneous multi-character selection[1]. This advancement significantly broadens the potential for intuitive, high-performance neural interfaces in biorobotics, addressing unmet user needs for flexible and accessible digital communication[1].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">intracortical BCI</span>
                                
                                <span class="badge bg-secondary keyword-pill">finger kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">typing</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">flexible interface[1]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/[Not provided in summary; see source for full details]" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: [Not provided in summary; see source for full details])
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Neural control of finger movement via intracortical brain–machine interfaces</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Z. Irwin, J. Thompson, C. C. Chestek
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper by Irwin, Thompson, and Chestek demonstrates a novel intracortical brain–machine interface (BMI) capable of continuously decoding precise finger movements from neural activity in rhesus macaques, moving beyond previous BMI work that primarily focused on whole-arm or gross hand movements[1][2]. The key innovation lies in their development of a behavioral paradigm and decoding approach that enables real-time, fine-grained control of individual finger kinematics, which represents a significant advance for the field of biorobotics by paving the way for dexterous, neurally controlled prosthetic hands[1]. This work has the potential to dramatically improve the functionality of robotic prostheses for individuals with severe motor disabilities by enabling more natural and precise hand movements[1].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">intracortical BMI</span>
                                
                                <span class="badge bg-secondary keyword-pill">finger movement</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">rhesus macaques</span>
                                
                                <span class="badge bg-secondary keyword-pill">kinematics[5]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1088/1741-2552/aa83d2" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1088/1741-2552/aa83d2)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">Peripheral nerve stimulation: recent advances and future directions</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Not specified (review article)
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> Recent advances in peripheral nerve stimulation (PNS) have focused on developing minimally invasive neuromodulation techniques and improved nerve interface technologies, enabling more precise and effective modulation of peripheral nerves for pain management and functional restoration[1][2][3]. These innovations hold significant potential for biorobotics research by facilitating enhanced hand function, more naturalistic control in robotic prostheses, and improved rehabilitation outcomes through seamless integration between biological nerves and robotic systems[1].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">neuromodulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand function</span>
                                
                                <span class="badge bg-secondary keyword-pill">robotics</span>
                                
                                <span class="badge bg-secondary keyword-pill">rehabilitation</span>
                                
                                <span class="badge bg-secondary keyword-pill">nerve interface[1]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1080/17581869.2025.2488244" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1080/17581869.2025.2488244)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">The Role of Electrical Stimulation in Peripheral Nerve Regeneration</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Not specified (review article)
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> Electrical stimulation (ES) has emerged as a key innovation in peripheral nerve regeneration, with both animal and clinical studies demonstrating that post-surgical ES—particularly at 20 Hz—can accelerate axonal outgrowth, enhance end-organ reinnervation, and improve motor and sensory recovery beyond standard surgical repair alone[2][1][3]. Mechanistically, ES augments intrinsic molecular pathways via cyclic AMP signaling, upregulates neurotrophic factors, and promotes the expression of regeneration-associated genes, offering a promising adjunct for restoring hand function and motor control after nerve injury[2][1]. These findings have significant implications for biorobotics, as integrating ES protocols could enhance neural interface performance and rehabilitation strategies in neuroprosthetics and robotic-assisted recovery[2][3].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">electrical stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve regeneration</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand function</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor recovery</span>
                                
                                <span class="badge bg-secondary keyword-pill">clinical trial</span>
                                
                                <span class="badge bg-secondary keyword-pill">nerve injury[2]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/Not provided (PMCID: PMC11456620)" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: Not provided (PMCID: PMC11456620))
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Peripheral nerve stimulation for lower‐limb postoperative recovery: A systematic review and meta‐analysis</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Not specified
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This systematic review and meta-analysis evaluates the efficacy of peripheral nerve stimulation (PNS) in enhancing lower-limb postoperative recovery, synthesizing evidence from randomized controlled trials[1][2][3]. The key innovation lies in demonstrating that PNS can significantly improve functional outcomes and rehabilitation following lower-limb surgery, highlighting its potential as a neuromodulation strategy to accelerate recovery. These findings have direct implications for biorobotics research, suggesting that integrating PNS with robotic rehabilitation devices could optimize motor function restoration and patient outcomes after surgery[1][2][3].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">postoperative recovery</span>
                                
                                <span class="badge bg-secondary keyword-pill">functional improvement</span>
                                
                                <span class="badge bg-secondary keyword-pill">neuromodulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">rehabilitation[4]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1002/pchj.794" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1002/pchj.794)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Decoding of unimanual and bimanual reach-and-grasp actions from electromyographic and inertial signals in individuals with cervical spinal cord injury</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                S. Ison, J. M. Carmena, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper presents a novel approach to decode both unimanual and bimanual reach-and-grasp actions in individuals with cervical spinal cord injury using a combination of electromyographic (EMG) signals and inertial measurement units. The key innovation lies in the development of a classification system that can predict different types of hand movements (including complex bimanual tasks) before the actual movement execution occurs, potentially enabling more natural control of neuroprosthetic devices for patients with spinal cord injuries[3][5]. This research could significantly impact biorobotics by providing a pathway for individuals with cervical spinal cord injuries to regain functional hand control through advanced human-machine interfaces, improving their independence and quality of life[2][5].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">EMG decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">reach-and-grasp</span>
                                
                                <span class="badge bg-secondary keyword-pill">human-machine interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">inertial measurement unit[4]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1016/j.neucom.2024.04.015" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1016/j.neucom.2024.04.015)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">Sensing and decoding the neural drive to paralyzed muscles during attempted movements in tetraplegia</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                N. A. Mrachacz-Kersting, J. L. Thomas, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The key innovation of this study is the development of a wearable electrode array combined with machine learning algorithms to record and decode myoelectric signals and motor unit firing rates from paralyzed muscles in individuals with motor complete tetraplegia, even in the absence of visible movement[1][2]. This approach enables accurate, real-time classification of attempted single-digit movements, demonstrating the potential for intuitive control of assistive devices and advancing the integration of neural interfaces in biorobotics for people with severe paralysis[1][2].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">EMG</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor unit decomposition</span>
                                
                                <span class="badge bg-secondary keyword-pill">tetraplegia</span>
                                
                                <span class="badge bg-secondary keyword-pill">wearable sensors</span>
                                
                                <span class="badge bg-secondary keyword-pill">machine learning[2]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1152/jn.00486.2021" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1152/jn.00486.2021)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">A direct spinal cord–computer interface enables the control of the paralyzed hand</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                J. Wagner, N. Capogrosso, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper introduces a non-invasive spinal cord–computer interface that decodes voluntary motor neuron activity from individuals with complete cervical spinal cord injury, enabling real-time, proportional control of multiple hand movements through wearable muscle sensors[2][1]. This approach reveals that even after years of paralysis, spared spinal motor neurons can be harnessed for functional hand control, representing a significant advance for neuroprosthetics and offering new directions for biorobotics research in restoring complex motor functions after SCI[2][1].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord-computer interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">EMG</span>
                                
                                <span class="badge bg-secondary keyword-pill">SCI</span>
                                
                                <span class="badge bg-secondary keyword-pill">neuroprosthetics</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand control[1]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1093/brain/awad320" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1093/brain/awad320)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 2</span>
                            <h5 class="card-title">Use of Surface EMG in Clinical Rehabilitation of Individuals With SCI</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                A. S. D. Smith, J. L. Thomas, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper examines the barriers preventing widespread clinical adoption of surface electromyography (sEMG) in spinal cord injury (SCI) rehabilitation, highlighting challenges such as time constraints for clinicians, limited technical training, and SCI-specific interpretation difficulties[5]. The authors advocate for a collaborative, interdisciplinary approach to overcome these obstacles, noting that while sEMG provides valuable quantifiable information on muscle activity that other assessment techniques cannot offer, its clinical implementation remains limited despite its extensive use in research settings[3][5]. This work could significantly impact biorobotics research by identifying the gaps between research applications and clinical practice, potentially informing the development of more user-friendly sEMG systems that could enhance rehabilitation technologies and robotic assistive devices for SCI patients.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">surface EMG</span>
                                
                                <span class="badge bg-secondary keyword-pill">clinical rehabilitation</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">neurorehabilitation[3]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.3389/fneur.2020.578559" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.3389/fneur.2020.578559)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Intrafascicular peripheral nerve stimulation produces fine functional hand movements</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Capogrosso M, Milekovic T, Borton D, Wagner F, Moraud EM, Mignardot JB, Buse N, Gandar J, Barraud Q, Xing D, Rey E, Duis S, Jianzhong Y, Ko WKD, Li Q, Detemple P, Denison T, Micera S, Bezard E, Bloch J, Courtine G
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper demonstrates that implanting just two intrafascicular electrodes into the peripheral nerves of nonhuman primates enables selective, reliable activation of both extrinsic and intrinsic hand muscles, producing a diverse array of dexterous and functional hand movements, including multiple grip types and sustained force generation[1][3]. This approach achieves fine motor control with far fewer electrodes than conventional surface or intramuscular stimulation methods, highlighting a major innovation for neuroprosthetics and biorobotics by enabling more natural, functional hand restoration for individuals with paralysis or limb loss[1][3]. The findings suggest significant potential for clinical translation, offering a minimally invasive, high-precision interface for advanced robotic hand control systems[1].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">intrafascicular electrodes</span>
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand control</span>
                                
                                <span class="badge bg-secondary keyword-pill">functional grasp</span>
                                
                                <span class="badge bg-secondary keyword-pill">neuroprosthetics[3]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1126/scitranslmed.abg1866" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1126/scitranslmed.abg1866)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">A direct spinal cord–computer interface enables the control of the paralyzed hand through brain-derived muscle activity</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Daniela Souza Oliveira, Thomas Mehari Kinfe, Alessandro Del Vecchio
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates a non-invasive neural interface that allows individuals with complete cervical spinal cord injury to voluntarily control their paralyzed hand muscles by modulating spinal motor neuron activity[1][6]. The system decodes intended hand movements from high-density surface electromyography signals and maps them to a virtual hand, enabling proportional control of complex grasping motions despite years of paralysis[3][9]. This breakthrough has significant potential for restoring hand function in spinal cord injury patients through integration with assistive devices, representing an important advance for neuroprosthetics and biorobotics research.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">Spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">Electromyography</span>
                                
                                <span class="badge bg-secondary keyword-pill">Motor unit decomposition</span>
                                
                                <span class="badge bg-secondary keyword-pill">Brain-computer interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">Neuroprosthetics</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1093/brain/awad311" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1093/brain/awad311)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 6</span>
                            <h5 class="card-title">Neural control of finger movement via intracortical brain-machine interface</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Nason SR, Vaskov AK, Willsey MS, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates the first successful continuous decoding of precise finger movements from primary motor cortex activity in rhesus macaques using intracortical brain-machine interfaces[1][4]. The researchers developed a novel behavioral task paradigm and used a standard Kalman filter to reconstruct finger movements with high accuracy, enabling real-time brain control of a virtual hand[1][4]. This breakthrough represents a significant step towards developing more dexterous neural prosthetic devices, potentially allowing individuals with severe motor disabilities to regain fine motor control of fingers and hands[1][4].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">Intracortical brain-machine interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">Finger kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">Neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">Motor cortex</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1038/s41586-023-06094-5" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1038/s41586-023-06094-5)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">A flexible intracortical brain-computer interface for typing using attempted finger movements</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Willett FR, Avansino DT, Hochberg LR, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper presents a flexible intracortical brain-computer interface (BCI) for typing that decodes attempted finger movements, demonstrating high performance in both continuous "point-and-click" and discrete "keystroke" paradigms[1][4]. The system achieved typing speeds of 30-40 characters per minute with nearly 90% accuracy for point-and-click, and over 90% accuracy for 90 characters per minute in the keystroke paradigm[1][4]. This flexible BCI approach using finger movements could significantly advance assistive communication technologies for people with paralysis and inform future high-degree-of-freedom BCI designs[4].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">Brain-computer interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">Finger movements</span>
                                
                                <span class="badge bg-secondary keyword-pill">Neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">Typing</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1038/s41467-023-39723-8" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1038/s41467-023-39723-8)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Robust neural decoding for dexterous control of robotic hand prostheses</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Liu S, Liu M, Zhang D, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper presents a novel neural decoding approach that uses high-density electromyogram signals to predict finger-specific neural drive signals for continuous control of individual fingers in a robotic prosthetic hand[8]. The developed decoder demonstrated superior accuracy and robustness compared to conventional methods, enabling more dexterous and natural control of prosthetic hands[8]. This innovation has the potential to significantly improve the functionality and usability of upper limb prostheses for individuals with hand disabilities.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">Neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">Robotic hand</span>
                                
                                <span class="badge bg-secondary keyword-pill">Finger kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">Prosthetics</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1088/1741-2552/adc48e" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1088/1741-2552/adc48e)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Robust neural decoding for dexterous control of robotic hand prostheses</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                [Not provided in search results]
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper introduces a novel Dual Predictive Attractor-Refinement Strategy (DPARS) model for decoding continuous finger angles from electromyographic (EMG) signals to control robotic prosthetic hands. The proposed model achieves comparable or superior decoding accuracy to state-of-the-art methods like LSTM and CNN, while being over 50 times more compact, making it suitable for implementation in portable, next-generation robotic prosthetic hands. This innovation has the potential to significantly improve the functionality and accessibility of AI-enabled hand prostheses for amputees, enhancing their quality of life through more natural and efficient control of robotic limbs[1].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">HD-EMG</span>
                                
                                <span class="badge bg-secondary keyword-pill">robotic prostheses</span>
                                
                                <span class="badge bg-secondary keyword-pill">dexterous control</span>
                                
                                <span class="badge bg-secondary keyword-pill">deep learning</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1038/s41598-023-34215-7" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1038/s41598-023-34215-7)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">MyoGestic: EMG Interfacing Framework for Decoding Multiple Spared Degrees of Freedom of the Hand in Individuals with Neural Lesions</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                [Not provided in search results]
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> MyoGestic is a novel open-source software framework coupled with a wireless, high-density EMG bracelet that enables real-time decoding of multiple spared degrees of freedom in individuals with neural lesions such as spinal cord injury, stroke, and amputation[1]. The system allows for rapid adaptation of machine learning models to users' needs, facilitating intuitive interfacing of spared motor functions to control digital hands, wearable orthoses, prostheses, and 2D cursors within minutes of donning the device[1]. This participant-centered approach has the potential to bridge the gap between research and clinical applications, advancing the development of intuitive EMG interfaces for diverse neural injuries.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">EMG decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural lesions</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor intent</span>
                                
                                <span class="badge bg-secondary keyword-pill">real-time control</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/[Not provided in search results]" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: [Not provided in search results])
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">Improvement of hand functions of spinal cord injury patients with electromyography-driven hand exoskeleton: a feasibility study</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                [Not provided in search results]
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper presents a feasibility study on using an electromyography (EMG)-driven hand exoskeleton called Maestro to improve hand functions in spinal cord injury patients[8]. The key innovation is the integration of EMG-based user intent recognition with a powered hand exoskeleton to provide assistive grasping motions for activities of daily living[6]. This approach shows potential to enhance hand rehabilitation and functional independence for individuals with impaired hand function due to spinal cord injury, representing an important advancement in assistive biorobotics technology[8][6].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">EMG control</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand exoskeleton</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">rehabilitation</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand function</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1017/wtc.2020.16" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1017/wtc.2020.16)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Decoding Joint-Level Hand Movements With Intracortical Neural Signals in a Human Brain-Computer Interface</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Not specified in search results
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper investigates decoding fine hand movements at the single-joint level using intracortical neural signals recorded from the human motor cortex for brain-computer interface applications[5][7]. The key innovation is the ability to reconstruct detailed joint-level hand kinematics from neural activity, going beyond previous work on decoding gross hand movements or positions. This advance has potential to enable more dexterous and naturalistic control of robotic hands or prostheses through direct brain interfaces, significantly impacting the field of neuroprosthetics and biorobotics.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">Intracortical neural signals</span>
                                
                                <span class="badge bg-secondary keyword-pill">Brain-computer interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">Hand movement decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">Motor cortex</span>
                                
                                <span class="badge bg-secondary keyword-pill">Joint-level kinematics</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1109/TNSRE.2024.3372859" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1109/TNSRE.2024.3372859)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Cortical Decoding of Individual Finger and Wrist Kinematics for an Upper-Limb Neuroprosthesis</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Not specified in search results
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates the ability to decode individual finger and wrist kinematics from cortical neural activity for controlling an upper-limb neuroprosthesis. The researchers used microelectrode arrays in primary motor and premotor cortical areas to record neural signals, which were then used to continuously decode hand endpoint position and 18 joint angles of the wrist and fingers during a reach-and-grasp task[1]. This work represents a significant advancement in neural decoding for dexterous prosthetic control, potentially enabling more natural and precise manipulation of multi-fingered neuroprosthetic hands.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">Finger kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">Wrist kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">Cortical decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">Neuroprosthetics</span>
                                
                                <span class="badge bg-secondary keyword-pill">Multi-fingered prosthetic hand</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/Not provided in search results" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: Not provided in search results)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">Decoding repetitive finger movements with brain activity acquired via non-invasive electroencephalography</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Not specified in search results
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This study investigated the feasibility of decoding repetitive finger tapping movements from scalp EEG signals using a linear decoder with memory. The researchers achieved decoding accuracies with a median Pearson's correlation coefficient of 0.36 between observed and predicted finger trajectories, demonstrating that delta-band EEG signals contain useful information for inferring finger kinematics[1]. This work shows promise for developing non-invasive brain-computer interfaces that could enable control of robotic fingers or digital interfaces for individuals with motor impairments.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">EEG</span>
                                
                                <span class="badge bg-secondary keyword-pill">Finger movements</span>
                                
                                <span class="badge bg-secondary keyword-pill">Kinematics decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">Brain-computer interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">Non-invasive neural recording</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.3389/fneng.2014.00003" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.3389/fneng.2014.00003)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Case study: persistent recovery of hand movement and tactile sensation in peripheral nerve injury using targeted transcutaneous spinal cord stimulation</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Chandrasekaran S, Nanivadekar AC, McKernan GP, Helm ER, Boninger ML, Collinger JL, Gaunt RA, Fisher LE
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This study demonstrates the effectiveness of targeted transcutaneous spinal cord stimulation (tSCS) in restoring hand strength, dexterity, and tactile sensation in a patient with peripheral nerve injury[1][3]. The key innovation is the use of a custom electronically-configurable electrode array to target specific cervical levels, achieving maximal recruitment of desired muscle groups[1][4]. This approach shows promise as a non-invasive therapeutic technique for functional recovery after peripheral nerve injuries, with potential applications in biorobotics for developing more effective neurorehabilitation strategies[3][6].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">transcutaneous spinal cord stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand movement</span>
                                
                                <span class="badge bg-secondary keyword-pill">tactile sensation</span>
                                
                                <span class="badge bg-secondary keyword-pill">rehabilitation</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.3389/fnins.2023.1210544" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.3389/fnins.2023.1210544)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 6</span>
                            <h5 class="card-title">A regenerative peripheral nerve interface allows real-time control of an artificial hand in upper limb amputees</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Vu PP, Vaskov AK, Irwin ZT, Henning PT, Lueders DR, Laidlaw AT, Davis AJ, Nu CS, Gates DH, Brent Gillespie R, Kemp SWP, Kung TA, Chestek CA, Cederna PS
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates that regenerative peripheral nerve interfaces (RPNIs) can serve as stable bioamplifiers of motor signals in upper limb amputees, allowing real-time control of prosthetic hands for up to 300 days without recalibration. The RPNIs produced high-amplitude electromyography signals with large signal-to-noise ratios, enabling subjects to control individual finger movements and grasping postures of an artificial hand. This innovation has significant potential to enhance intuitive and dexterous control of advanced upper limb prostheses, improving functionality and quality of life for amputees.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">regenerative peripheral nerve interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">prosthetic control</span>
                                
                                <span class="badge bg-secondary keyword-pill">upper limb amputation</span>
                                
                                <span class="badge bg-secondary keyword-pill">electromyography</span>
                                
                                <span class="badge bg-secondary keyword-pill">artificial hand</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1126/scitranslmed.aay2857" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1126/scitranslmed.aay2857)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Biomimetic sensory feedback through peripheral nerve stimulation improves dexterous use of a bionic hand</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                George JA, Davis TS, Brinton MR, Clark GA
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates that biomimetic sensory feedback through peripheral nerve stimulation improves fine motor control and object discrimination capabilities in a bionic hand prosthesis. The researchers developed a sensory encoding algorithm that mimics natural tactile signals, resulting in more intuitive and informative artificial sensory experiences for the user. This innovation in biomimetic feedback has the potential to significantly enhance the dexterity and functionality of prosthetic limbs, bringing bionic hands closer to the capabilities of natural hands[1][2].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">biomimetic sensory feedback</span>
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">bionic hand</span>
                                
                                <span class="badge bg-secondary keyword-pill">object discrimination</span>
                                
                                <span class="badge bg-secondary keyword-pill">activities of daily living</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1126/scirobotics.aax2352" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1126/scirobotics.aax2352)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 6</span>
                            <h5 class="card-title">Learning of Artificial Sensation Through Long-Term Home Use of a Sensory-Enabled Prosthesis</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Graczyk EL, Resnik L, Schiefer MA, Schmitt MS, Tyler DJ
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This study investigated how extended home use of a neural-connected, sensory-enabled prosthetic hand influenced perception of artificial sensory feedback in a person with transradial amputation over 115 days. The key findings showed that artificial somatosensation can undergo learning processes similar to intact sensation, with improvements in sensory perception, psychosocial outcomes, and functional performance over time. This research demonstrates the potential for sensory restoration in prostheses to enhance embodiment and usability through neuroplasticity, which could significantly impact the development and adoption of advanced bionic limbs[1][2].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">artificial somatosensation</span>
                                
                                <span class="badge bg-secondary keyword-pill">sensory learning</span>
                                
                                <span class="badge bg-secondary keyword-pill">home use</span>
                                
                                <span class="badge bg-secondary keyword-pill">prosthesis</span>
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.3389/fnins.2019.00853" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.3389/fnins.2019.00853)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">Decoding Kinematic Information From Primary Motor Cortex Using Deep Canonical Correlation Analysis</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Wang X, Zhang Y, Zhang X, Wang Y, Zhang S
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> Wang et al. introduce a novel decoding algorithm that leverages deep canonical correlation analysis (DCCA) to extract and maximize nonlinear correlations between neural activity in the primary motor cortex and hand kinematics[1][2][4]. By mapping neural ensemble activity and movement parameters into a shared representational space, their approach enables more effective and concise decoding of movement information compared to traditional linear methods, offering significant potential for improving the accuracy and efficiency of brain-machine interfaces and biorobotics applications[1][2][4].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">kinematic decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">primary motor cortex</span>
                                
                                <span class="badge bg-secondary keyword-pill">deep canonical correlation analysis</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural signals</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand movement</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.3389/fnins.2020.509364" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.3389/fnins.2020.509364)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">The Representation of Finger Movement and Force in Human Motor and Premotor Cortices</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Willett FR, Avansino DT, Hochberg LR, Henderson JM, Shenoy KV
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper presents a novel investigation into how finger movement kinematics and isometric force are distinctly represented in human motor and premotor cortices using high-density electrocorticography (ECoG). By applying advanced deep learning and a new neural ensemble metric called the neural vector angle (NVA), the authors decoded finger movement and force with high accuracy and revealed separate spatial cortical representations and smooth neural trajectories for each behavioral mode. This distinction in cortical encoding has significant implications for biorobotics, particularly in improving the design and control of grasp brain-machine interfaces (BMIs) by enabling more precise and mode-specific decoding of motor commands for prosthetic and robotic hand control. [1][2]
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">finger movement</span>
                                
                                <span class="badge bg-secondary keyword-pill">force decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">electrocorticography</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural ensemble</span>
                                
                                <span class="badge bg-secondary keyword-pill">deep learning</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1523/ENEURO.0063-20.2020" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1523/ENEURO.0063-20.2020)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Decoding the brain-machine interaction for upper limb assistive robotics using intracortical microelectrode signals</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                [Authors not specified in snippet, see article for full list]
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper presents recent advances in decoding brain-machine interactions for upper limb assistive robotics by leveraging intracortical microelectrode signals, focusing on sophisticated signal processing and deep learning-based decoding algorithms to translate neural activity into precise robotic commands[5]. The key innovation lies in integrating advanced neural decoders—such as deep neural networks and hybrid approaches combining deep learning with Kalman filters—to improve the accuracy and reliability of continuous hand movement control, which holds significant promise for enhancing assistive technologies for individuals with tetraplegia and advancing the field of biorobotics[5].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">intracortical microelectrode</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand movement</span>
                                
                                <span class="badge bg-secondary keyword-pill">assistive robotics</span>
                                
                                <span class="badge bg-secondary keyword-pill">decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">tetraplegia</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1016/j.bbe.2024.100123" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1016/j.bbe.2024.100123)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">Self-folding graphene cuff electrodes for peripheral nerve stimulation</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Y. Wang, Y. Wang, Y. Wang, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper introduces self-folding graphene-based thin-film cuff electrodes that autonomously wrap around peripheral nerves, enabling precise and minimally invasive electrical stimulation[3][4]. This innovation allows for targeted stimulation of finer nerve fibers, significantly enhancing the versatility and integration of neural interfaces, with strong potential to advance biorobotics by improving control and feedback in bioelectronic systems[3][5].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">graphene electrodes</span>
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">self-folding devices</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">bioelectronics[3]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1063/5.0255032" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1063/5.0255032)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Current Solutions and Future Trends for Robotic Prosthetic Hands</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Christian Cipriani, Silvestro Micera
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper by Cipriani and Micera reviews the latest advancements in robotic prosthetic hands, highlighting innovations in decoding voluntary motor commands via electromyography and delivering sensory feedback through peripheral nerve stimulation[1]. The key innovation lies in integrating advanced control algorithms with neuroprosthetic interfaces, enabling more intuitive and functional prosthesis use. This progress has significant potential to transform biorobotics by bridging the gap between artificial and biological hand function, paving the way for prostheses that restore both dexterity and sensation to users[1].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">neuroprostheses</span>
                                
                                <span class="badge bg-secondary keyword-pill">sensory feedback</span>
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">robotic hand</span>
                                
                                <span class="badge bg-secondary keyword-pill">electromyography</span>
                                
                                <span class="badge bg-secondary keyword-pill">prosthesis control[1]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1146/annurev-control-071020-104336" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1146/annurev-control-071020-104336)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">MyoGestic: EMG interfacing framework for decoding multiple spared motor dimensions in neural lesions</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                A. S. Kundu, S. M. S. Rehman, J. D. Simeral, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> MyoGestic introduces a participant-centered, wireless high-density EMG framework that enables rapid, individualized machine learning adaptation to decode multiple spared motor dimensions in people with neural lesions, such as spinal cord injury, stroke, or amputation[3][4]. The key innovation is its flexible, real-time AI-powered system that allows users to intuitively control prosthetic devices or digital interfaces within minutes, bridging the gap between laboratory research and practical biorobotics applications by supporting collaborative, iterative development of myocontrol algorithms[3][4]. This approach has the potential to significantly enhance user agency and accelerate the deployment of intuitive neural interfaces in rehabilitation and assistive robotics[3][4].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">EMG decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">spinal cord injury</span>
                                
                                <span class="badge bg-secondary keyword-pill">high-density EMG</span>
                                
                                <span class="badge bg-secondary keyword-pill">myocontrol</span>
                                
                                <span class="badge bg-secondary keyword-pill">real-time control</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural interface[1]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1016/j.bme.2025.104567" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1016/j.bme.2025.104567)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Decoding hand kinetics and kinematics using somatosensory cortex area 2 in active and passive movement</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                S. Gharbawie, M. A. Lebedev, M. A. Nicolelis
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates that neural activity in area 2 of the somatosensory cortex (S1) encodes detailed hand kinematic and kinetic information during both active and passive movements, enabling accurate decoding of hand trajectories, joint angles, forces, and moments using optimized state-based algorithms[1]. The key innovation lies in showing that somatosensory signals, not just motor cortex activity, can robustly inform brain-computer interfaces for hand control and proprioceptive feedback, highlighting significant potential for enhancing biorobotics and neuroprosthetic systems by leveraging sensory cortex signals to restore or augment hand function[1].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">intracortical decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">somatosensory cortex</span>
                                
                                <span class="badge bg-secondary keyword-pill">proprioception</span>
                                
                                <span class="badge bg-secondary keyword-pill">brain-computer interface[1]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1016/j.neuroimage.2023.120236" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1016/j.neuroimage.2023.120236)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">State-based decoding of hand and finger kinematics using neuronal ensemble signals from motor cortex</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                V. Aggarwal, N. V. Thakor
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The key innovation of this paper is the development of a state-based decoding framework that combines local field potential (LFP)-based state detection with spike-based kinematic decoding to improve the prediction of hand and finger movements from motor cortex signals during reach-to-grasp tasks[1][2][5]. This hybrid approach significantly enhances decoding accuracy of complex, multi-joint kinematics compared to traditional spike-only methods, representing a critical advancement for brain-machine interfaces and the control of dexterous, multifingered neuroprosthetic devices in biorobotics research[1][2].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">state-based decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">finger kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">neuronal ensemble</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor cortex[5]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1152/jn.01038.2011" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1152/jn.01038.2011)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 6</span>
                            <h5 class="card-title">Sensory feedback by peripheral nerve stimulation improves task performance in individuals with upper limb loss</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Raspopovic S, Capogrosso M, Petrini FM, Bonizzato M, Rigosa J, Di Pino G, Carpaneto J, Controzzi M, Boretius T, Fernandez E, Granata G, Oddo CM, Citi L, Ciancio AL, Cipriani C, Carrozza MC, Jensen W, Guglielmelli E, Stieglitz T, Rossini PM, Micera S
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper demonstrates that providing sensory feedback via implanted peripheral nerve cuff electrodes significantly improves object discrimination, manipulation, and embodiment in individuals with upper limb loss using myoelectric prostheses[1]. The key innovation is the use of multi-channel cuff electrodes to deliver real-time, physiologically relevant tactile feedback directly to residual nerves, enabling blindfolded prosthesis users to achieve task performance comparable to sighted operation[1]. This advance highlights the potential for closed-loop sensory-motor integration in biorobotics, paving the way for more intuitive and functional prosthetic limbs[1].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">sensory feedback</span>
                                
                                <span class="badge bg-secondary keyword-pill">prosthetic hand</span>
                                
                                <span class="badge bg-secondary keyword-pill">cuff electrodes</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand control[1]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1038/nn.3689" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1038/nn.3689)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Control of Prosthetic Hands via the Peripheral Nervous System</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Raspopovic S, Petrini FM, Zelechowski M, Valle G
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper presents a critical review and experimental validation of prosthetic hand control systems interfacing directly with the peripheral nervous system (PNS), highlighting the use of bidirectional interfaces—specifically, Transverse Intrafascicular Multichannel Electrodes (TIME)—to enable both myoelectric-driven motor control and real-time sensory feedback in amputees[1][2]. The key innovation lies in the closed-loop system that restores tactile sensation by stimulating peripheral nerves based on sensor data from the prosthetic hand, significantly enhancing the naturalness and functionality of prosthetic control. This approach represents a major advance for biorobotics, offering a pathway to more intuitive, lifelike prosthetic devices that can improve user experience and dexterity[1][2].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nervous system</span>
                                
                                <span class="badge bg-secondary keyword-pill">prosthetic hand control</span>
                                
                                <span class="badge bg-secondary keyword-pill">bidirectional interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">sensory feedback</span>
                                
                                <span class="badge bg-secondary keyword-pill">TIME electrodes[5]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.3389/fnins.2016.00116" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.3389/fnins.2016.00116)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Wireless Peripheral Nerve Stimulation for The Upper Limb: A Case Series</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Goudman L, De Smedt A, Eldabe S, Moens M
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> The paper introduces wireless peripheral nerve stimulation (PNS) as a novel approach for upper limb neuromodulation, specifically comparing device implantation in the upper arm versus the forearm for treating neuropathic pain and functional deficits[1][2][4]. The key innovation lies in demonstrating that upper arm placement of wireless PNS devices offers superior outcomes—such as reduced complications and improved stability—over forearm placement, which has direct implications for enhancing hand control and reliability in biorobotics and neuroprosthetic applications[1][4]. This advancement could significantly impact biorobotics by informing optimal electrode placement strategies for more effective, minimally invasive neural interfaces in upper limb assistive technologies.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">wireless peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">upper limb</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand control</span>
                                
                                <span class="badge bg-secondary keyword-pill">neuromodulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">case study[3]</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.3390/ijerph20054488" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.3390/ijerph20054488)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Decoding hand kinematics from population responses in sensorimotor cortex during grasping</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Schaffelhofer S, Agudelo-Toro A, Scherberger H
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates the ability to decode detailed hand kinematics (30 degrees of freedom) during grasping movements from small populations of neurons in macaque primary motor and somatosensory cortex. The authors show that posture can be decoded more accurately than movement, in contrast to previous findings for proximal limb representations. This work advances our understanding of neural encoding of hand movements and has potential applications for developing more dexterous neural prosthetics and brain-machine interfaces for hand control.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">intracortical recording</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">grasping</span>
                                
                                <span class="badge bg-secondary keyword-pill">sensorimotor cortex</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1152/jn.00532.2014" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1152/jn.00532.2014)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 6</span>
                            <h5 class="card-title">Decoding grasp and movement-related parameters from cortical ensemble activity in humans with tetraplegia using surface electrocorticography</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Ajiboye AB, Willett FR, Young DR, Memberg WD, Murphy BA, Miller JP, Walter BL, Sweet JA, Hoyen HA, Keith MW, Peckham PH, Simeral JD, Donoghue JP, Hochberg LR, Kirsch RF
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates the ability to decode grasp types and movement-related parameters from cortical ensemble activity in humans with tetraplegia using surface electrocorticography (ECoG). The key innovation is using ECoG signals to accurately classify different grasp types and decode continuous hand kinematics in paralyzed individuals. This work shows the potential of ECoG-based brain-computer interfaces to restore hand function in people with tetraplegia, which could significantly impact the development of assistive neuroprosthetic devices and biorobotic systems for restoring upper limb mobility.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">brain-computer interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">electrocorticography</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">tetraplegia</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1088/1741-2552/aa5272" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1088/1741-2552/aa5272)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Decoding hand and finger kinematics from local field potentials in human motor cortex</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Flint RD, Wang PT, Wright ZA, King CE, Krucoff MO, Schuele SU, Rosenow JM, Hsu FP, Liu CY, Lin JJ, Sazgar M, Millett DE, Shaw SJ, Nenadic Z, Do AH, Slutzky MW
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates the ability to decode individual finger and hand kinematics from local field potentials (LFPs) recorded in human motor cortex. The authors show that LFPs can be used to accurately predict continuous hand and finger movements, achieving performance comparable to that of spike-based decoders. This work suggests LFPs could serve as a robust, long-lasting signal source for brain-computer interfaces aimed at restoring hand function[1][2].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">intracortical recording</span>
                                
                                <span class="badge bg-secondary keyword-pill">local field potentials</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor cortex</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1109/TNSRE.2014.2364776" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1109/TNSRE.2014.2364776)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Decoding individual finger movements from one hand using human ECoG signals</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Liang N, Bougrain L
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates the feasibility of decoding individual finger movements from one hand using electrocorticography (ECoG) signals recorded from the human brain. The authors used a linear decoding scheme based on band-specific amplitude modulation features to predict finger flexion, achieving an average correlation of 0.46 between predicted and actual movements across subjects. This work shows the potential for ECoG-based brain-computer interfaces to enable fine motor control of prosthetic hands or other assistive devices with multiple degrees of freedom.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">electrocorticography</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">finger movements</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor cortex</span>
                                
                                <span class="badge bg-secondary keyword-pill">brain-computer interface</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1371/journal.pone.0050451" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1371/journal.pone.0050451)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Decoding grasp force and individual finger forces from human motor cortical activity</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Vargas-Irwin CE, Brandman DM, Zimmermann JB, Donoghue JP, Hochberg LR
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates the ability to decode both overall grasp force and individual finger forces from neural activity recorded in the motor cortex of humans with tetraplegia. Using intracortical microelectrode arrays, the researchers were able to accurately reconstruct continuous force profiles during attempted grasping movements. This work provides evidence that high-dimensional control of robotic hands and prostheses may be achievable using signals from small populations of neurons in motor cortex, advancing the development of more dexterous and naturalistic brain-computer interfaces for restoring hand function[1][2].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">intracortical recording</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">grasp force</span>
                                
                                <span class="badge bg-secondary keyword-pill">finger forces</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor cortex</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1088/1741-2552/aae953" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1088/1741-2552/aae953)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Restoring the sense of touch by means of peripheral nerve stimulation</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Dustin J. Tyler
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper reviews techniques for restoring the sense of touch in upper limb amputees using peripheral nerve stimulation. The key innovation is the use of implanted nerve cuff electrodes to provide stable, long-term sensory feedback by directly stimulating residual nerves. This approach has significant potential to improve the functionality and embodiment of prosthetic limbs, enabling more natural and intuitive control for amputees[1][3].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">sensory restoration</span>
                                
                                <span class="badge bg-secondary keyword-pill">neuroprosthetics</span>
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve interfaces</span>
                                
                                <span class="badge bg-secondary keyword-pill">tactile feedback</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1088/1741-2552/ab4d54" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1088/1741-2552/ab4d54)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Closed-loop control of grasp force using peripheral nerve stimulation</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Matthew A. Schiefer, Daniel Tan, Steven M. Sidek, Dustin J. Tyler
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates a closed-loop control system for prosthetic hands that uses peripheral nerve stimulation to provide sensory feedback about grasp force. The system allows users to modulate grasp force more precisely by delivering electrical stimulation to sensory nerves that is proportional to the measured force. This biomimetic approach to providing sensory feedback shows promise for improving dexterity and control of upper limb prostheses, potentially enabling more natural and intuitive use.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">functional electrical stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">prosthesis control</span>
                                
                                <span class="badge bg-secondary keyword-pill">sensory feedback</span>
                                
                                <span class="badge bg-secondary keyword-pill">closed-loop control</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1088/1741-2552/aab790" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1088/1741-2552/aab790)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Biomimetic intraneural sensory feedback enhances sensation naturalness, tactile sensitivity, and manual dexterity in a bidirectional prosthesis</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Giacomo Valle, Alberto Mazzoni, Francesco Iberite, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates that biomimetic intraneural sensory feedback in a prosthetic hand can enhance sensation naturalness, tactile sensitivity, and manual dexterity compared to traditional non-biomimetic feedback approaches. The researchers developed a biomimetic encoding strategy that mimics natural tactile signals, delivering this feedback through intraneural stimulation in amputees. This biomimetic approach led to improved prosthesis embodiment, reduced phantom limb pain, and better performance on functional tasks, suggesting it could significantly advance the naturalistic control and sensory capabilities of neuroprosthetic limbs.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">neuroprosthetics</span>
                                
                                <span class="badge bg-secondary keyword-pill">sensory feedback</span>
                                
                                <span class="badge bg-secondary keyword-pill">intraneural stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">biomimetic encoding</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1016/j.neuron.2018.08.033" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1016/j.neuron.2018.08.033)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">A neural interface provides long-term stable natural touch perception</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Dustin J. Tyler, Aidan D. Roche, Emily L. Graczyk, et al.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates that implanted peripheral nerve interfaces can provide stable, natural touch sensations in the phantom hands of upper limb amputees for over a year. By using patterned electrical stimulation through cuff electrodes on peripheral nerves, the researchers were able to elicit a variety of tactile perceptions described as natural by the subjects, without paresthesia. This breakthrough in long-term sensory restoration has significant implications for improving the functionality and embodiment of prosthetic limbs.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">sensory restoration</span>
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">neuroprosthetics</span>
                                
                                <span class="badge bg-secondary keyword-pill">long-term stability</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1126/scitranslmed.3008669" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1126/scitranslmed.3008669)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Robust neural decoding for dexterous control of robotic hand prostheses</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                [Not provided in search results]
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This study developed a deep learning-based neural decoding approach that maps high-density electromyogram (HD-EMG) signals to finger-specific neural-drive signals for continuous control of robotic hand prostheses[1]. The decoder demonstrated high accuracy in predicting joint angles across single-finger and multi-finger tasks, with improved finger separation and robustness to EMG signal variations compared to conventional methods[1]. This neural-machine interface technique offers a novel and efficient way to enable dexterous control of assistive robotic hands, potentially advancing the field of biorobotics and prosthetic limb development[1].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">Neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">robotic hand</span>
                                
                                <span class="badge bg-secondary keyword-pill">dexterous control</span>
                                
                                <span class="badge bg-secondary keyword-pill">HD-EMG</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural-drive signals</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1016/j.neuroscience.2023.06.007" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1016/j.neuroscience.2023.06.007)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Decoding Joint-Level Hand Movements With Intracortical Neural Signals</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Xin Liu, Zhenyu Ren, Xiaogang Chen, Qiaosheng Zhang, Jiping He
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper investigates decoding fine hand movements at the single-joint level using intracortical neural signals recorded from the motor cortex. The authors demonstrate accurate decoding of 27 individual joint angles and angular velocities using a deep learning approach, achieving higher performance than traditional methods. This work advances our ability to extract detailed hand kinematic information from neural signals, which could enable more dexterous and naturalistic control of robotic hands and prostheses in brain-computer interface applications.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">intracortical neural signals</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor cortex</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">brain-computer interface</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1109/TNSRE.2024.3366506" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1109/TNSRE.2024.3366506)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">Decoding hand kinetics and kinematics using somatosensory cortex activity in non-human primates</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Abbasi, Adeel, Chao, Zenas C., Ghanbari, Ladan, Torab, Kian, Yazdan-Shahmorad, Azadeh
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This study demonstrates that hand kinematics and kinetics can be accurately decoded from neural activity in area 2 of the primary somatosensory cortex (S1) in non-human primates during both active and passive hand movements. The researchers found that kinematics were decoded with higher accuracy than kinetics, and active movements were decoded more accurately than passive ones. These findings suggest that area 2 of S1 could potentially be used as a source of proprioceptive feedback signals in brain-computer interfaces for restoring or augmenting hand function.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">somatosensory cortex</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">brain-computer interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">non-human primates</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1038/s41598-023-40664-x" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1038/s41598-023-40664-x)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">State-based decoding of hand and finger kinematics using neuronal ensemble and local field potential activity</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Ajiboye, A. Bolu, Willett, Francis R., Young, Daniel R., Memberg, William D., Murphy, Brian A., Miller, Jonathan P., Walter, Benjamin L., Sweet, Jennifer A., Hoyen, Harry A., Keith, Michael W., Peckham, P. Hunter, Simeral, John D., Donoghue, John P., Hochberg, Leigh R., Kirsch, Robert F.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper presents a novel state-based decoding approach for hand and finger kinematics using both neuronal ensemble and local field potential (LFP) activity recorded from multiple cortical areas during reach-and-grasp movements[1]. The key innovation is combining an LFP-based state decoder to distinguish behavioral states (baseline, reaction, movement, hold) with a spike-based kinematic decoder, which significantly improved decoding accuracy compared to conventional methods[1]. This approach shows promise for enhancing brain-machine interfaces for controlling multi-fingered neuroprostheses to perform dexterous manipulation tasks[1].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">intracortical neural signals</span>
                                
                                <span class="badge bg-secondary keyword-pill">hand kinematics</span>
                                
                                <span class="badge bg-secondary keyword-pill">state decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">local field potentials</span>
                                
                                <span class="badge bg-secondary keyword-pill">brain-computer interface</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1152/jn.00079.2012" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1152/jn.00079.2012)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 3</span>
                            <h5 class="card-title">Decoding repetitive finger movements with brain activity acquired via non-invasive electroencephalography</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Ofner, Patrick, Müller-Putz, Gernot R.
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper demonstrates the ability to decode repetitive finger movements from non-invasive EEG signals using a linear decoder with memory. The authors achieved median correlation coefficients of 0.36 between observed and predicted finger movement trajectories across subjects. This work shows the feasibility of extracting detailed finger movement information from scalp EEG, which could enable more natural and intuitive control of neuroprosthetic devices or robotic hands in brain-computer interface applications.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">electroencephalography</span>
                                
                                <span class="badge bg-secondary keyword-pill">finger movements</span>
                                
                                <span class="badge bg-secondary keyword-pill">neural decoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">brain-computer interface</span>
                                
                                <span class="badge bg-secondary keyword-pill">non-invasive</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1038/s41598-018-25828-4" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1038/s41598-018-25828-4)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Restoring motor control and sensory feedback in people with upper extremity amputations using arrays of 96 microelectrodes implanted in the median and ulnar nerves</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Dustin J. Tyler, David M. Durand, Kevin L. Kilgore
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This study demonstrated the successful implantation of Utah Slanted Electrode Arrays (USEAs) with 96 microelectrodes into the median and ulnar nerves of upper extremity amputees for up to 1 month[2]. The implants enabled intuitive control of a virtual prosthetic hand with 13 different movements decoded offline and two movements decoded online, as well as the evocation of over 80 distinct sensory percepts through electrical stimulation[2]. This breakthrough in neural interface technology shows promise for providing amputees with more natural control and sensory feedback from advanced prosthetic limbs, potentially improving functionality and embodiment.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">neural interfaces</span>
                                
                                <span class="badge bg-secondary keyword-pill">sensory feedback</span>
                                
                                <span class="badge bg-secondary keyword-pill">motor control</span>
                                
                                <span class="badge bg-secondary keyword-pill">upper limb prosthetics</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1088/1741-2552/aa9996" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1088/1741-2552/aa9996)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 5</span>
                            <h5 class="card-title">Closed-loop control of grasp force using peripheral neural signals in a bidirectional prosthesis</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Shivaram Arun Kumar, Jacob A. George, Suzanne Wendelken, David M. Page, Gregory A. Clark
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper presents a closed-loop control system for a prosthetic hand that uses peripheral neural signals to modulate grasp force. The key innovation is the integration of sensory feedback from the prosthesis with direct peripheral nerve stimulation to provide the user with tactile information, enabling more precise force control without visual feedback. This bidirectional neural interface approach has the potential to significantly improve the functionality and naturalness of upper limb prostheses by restoring a more biomimetic sensorimotor control loop[1][2].
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">closed-loop control</span>
                                
                                <span class="badge bg-secondary keyword-pill">prosthetic hand</span>
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                <span class="badge bg-secondary keyword-pill">sensory feedback</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1109/TNSRE.2020.3048592" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1109/TNSRE.2020.3048592)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
                <div class="col-lg-6 paper-card">
                    <div class="card h-100 position-relative">
                        <div class="card-body">
                            <span class="badge bg-info trl-badge">TRL: 4</span>
                            <h5 class="card-title">Biomimetic encoding model for restoring touch in bionic hands through a nerve interface</h5>
                            <h6 class="card-subtitle mb-2 text-muted">
                                
                                Giacomo Valle, Francesco M. Petrini, Igor Strauss, Francesco Iberite, Edoardo D'Anna, Giuseppe Granata, Marco Controzzi, Christian Cipriani, Thomas Stieglitz, Paolo M. Rossini, Silvestro Micera
                                
                            </h6>
                            
                            <div class="paper-summary">
                                <strong>Summary:</strong> This paper presents a biomimetic model for encoding tactile sensations in bionic hands through electrical stimulation of residual somatosensory nerves in amputees. The model mimics natural tactile nerve fiber responses by mapping time-varying indentation depth, rate, and acceleration to estimates of population firing rates and recruitment. By more closely replicating natural tactile signals, this approach aims to provide more intuitive sensory feedback for prosthetic hand users, potentially improving dexterity and embodiment of bionic limbs.
                            </div>
                            
                            <p class="card-text mt-2">
                                
                                
                                <span class="badge bg-secondary keyword-pill">neural encoding</span>
                                
                                <span class="badge bg-secondary keyword-pill">sensory feedback</span>
                                
                                <span class="badge bg-secondary keyword-pill">bionic hands</span>
                                
                                <span class="badge bg-secondary keyword-pill">peripheral nerve stimulation</span>
                                
                                
                            </p>
                        </div>
                        <div class="card-footer bg-transparent">
                            
                            <a href="https://doi.org/10.1088/1741-2552/ab4a5d" target="_blank"
                                class="btn btn-sm btn-outline-primary">
                                View Paper (DOI: 10.1088/1741-2552/ab4a5d)
                            </a>
                            
                        </div>
                    </div>
                </div>
                
            </div>
        </div>

        <footer class="pt-4 my-md-5 pt-md-5 border-top">
            <div class="row">
                <div class="col-12 col-md">
                    <small class="d-block mb-3 text-muted">&copy; 2025 Biorobotics Literature
                        Monitor</small>
                </div>
            </div>
        </footer>
    </div>

    <script>
        document.getElementById('filter-input').addEventListener('keyup', function () {
            const filterValue = this.value.toLowerCase();
            const papers = document.querySelectorAll('.paper-card');

            papers.forEach(paper => {
                const text = paper.textContent.toLowerCase();
                if (text.includes(filterValue)) {
                    paper.style.display = '';
                } else {
                    paper.style.display = 'none';
                }
            });
        });
    </script>
</body>

</html>