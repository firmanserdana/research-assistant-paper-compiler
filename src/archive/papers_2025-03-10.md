# Research Papers Compilation - March 10, 2025

## Summary
This compilation contains 9 new papers in biorobotics research.

## Emg Decoding On Spinal Cord Injured Patients (2 papers)

### Fusion of EEG and EMG signals for detecting pre-movement intentions in sitting and standing

**Authors:** [Not provided in search results]

**DOI:** 10.3389/fnins.2025.1532099

**TRL:** 4

**Keywords:** EEG-EMG fusion, functional connectivity, motor intention detection, spinal cord injury, rehabilitation

**Summary:** This study proposes a novel multimodal fusion method based on EEG-EMG functional connectivity to detect sitting and standing intentions before movement execution. The mutual information-based EEG-EMG network achieved 94.33% accuracy in healthy subjects and 87.54% in spinal cord injury patients, outperforming single-modality approaches. By enabling early and accurate detection of motor intentions, this method has the potential to improve the responsiveness and effectiveness of rehabilitation devices and neuroprostheses for individuals with movement disorders.

---

### Robust neural decoding for dexterous control of robotic hand prostheses

**Authors:** [Not provided in search results]

**DOI:** 10.1016/j.neuroscience.2023.06.007

**TRL:** 5

**Keywords:** Neural decoding, robotic hand, dexterous control, HD-EMG, neural-drive signals

**Summary:** This study developed a deep learning-based neural decoding approach that maps high-density electromyogram (HD-EMG) signals to finger-specific neural-drive signals for continuous control of robotic hand prostheses[1]. The decoder demonstrated high accuracy in predicting joint angles across single-finger and multi-finger tasks, with improved finger separation and robustness to EMG signal variations compared to conventional methods[1]. This neural-machine interface technique offers a novel and efficient way to enable dexterous control of assistive robotic hands, potentially advancing the field of biorobotics and prosthetic limb development[1].

---

## Intracortical Decoding On Hand And Finger Kinematics (4 papers)

### Decoding Joint-Level Hand Movements With Intracortical Neural Signals

**Authors:** Xin Liu; Zhenyu Ren; Xiaogang Chen; Qiaosheng Zhang; Jiping He

**DOI:** 10.1109/TNSRE.2024.3366506

**TRL:** 4

**Keywords:** intracortical neural signals, hand kinematics, motor cortex, neural decoding, brain-computer interface

**Summary:** This paper investigates decoding fine hand movements at the single-joint level using intracortical neural signals recorded from the motor cortex. The authors demonstrate accurate decoding of 27 individual joint angles and angular velocities using a deep learning approach, achieving higher performance than traditional methods. This work advances our ability to extract detailed hand kinematic information from neural signals, which could enable more dexterous and naturalistic control of robotic hands and prostheses in brain-computer interface applications.

---

### Decoding hand kinetics and kinematics using somatosensory cortex activity in non-human primates

**Authors:** Abbasi, Adeel; Chao, Zenas C.; Ghanbari, Ladan; Torab, Kian; Yazdan-Shahmorad, Azadeh

**DOI:** 10.1038/s41598-023-40664-x

**TRL:** 3

**Keywords:** somatosensory cortex, hand kinematics, neural decoding, brain-computer interface, non-human primates

**Summary:** This study demonstrates that hand kinematics and kinetics can be accurately decoded from neural activity in area 2 of the primary somatosensory cortex (S1) in non-human primates during both active and passive hand movements. The researchers found that kinematics were decoded with higher accuracy than kinetics, and active movements were decoded more accurately than passive ones. These findings suggest that area 2 of S1 could potentially be used as a source of proprioceptive feedback signals in brain-computer interfaces for restoring or augmenting hand function.

---

### State-based decoding of hand and finger kinematics using neuronal ensemble and local field potential activity

**Authors:** Ajiboye, A. Bolu; Willett, Francis R.; Young, Daniel R.; Memberg, William D.; Murphy, Brian A.; Miller, Jonathan P.; Walter, Benjamin L.; Sweet, Jennifer A.; Hoyen, Harry A.; Keith, Michael W.; Peckham, P. Hunter; Simeral, John D.; Donoghue, John P.; Hochberg, Leigh R.; Kirsch, Robert F.

**DOI:** 10.1152/jn.00079.2012

**TRL:** 4

**Keywords:** intracortical neural signals, hand kinematics, state decoding, local field potentials, brain-computer interface

**Summary:** This paper presents a novel state-based decoding approach for hand and finger kinematics using both neuronal ensemble and local field potential (LFP) activity recorded from multiple cortical areas during reach-and-grasp movements[1]. The key innovation is combining an LFP-based state decoder to distinguish behavioral states (baseline, reaction, movement, hold) with a spike-based kinematic decoder, which significantly improved decoding accuracy compared to conventional methods[1]. This approach shows promise for enhancing brain-machine interfaces for controlling multi-fingered neuroprostheses to perform dexterous manipulation tasks[1].

---

### Decoding repetitive finger movements with brain activity acquired via non-invasive electroencephalography

**Authors:** Ofner, Patrick; MÃ¼ller-Putz, Gernot R.

**DOI:** 10.1038/s41598-018-25828-4

**TRL:** 3

**Keywords:** electroencephalography, finger movements, neural decoding, brain-computer interface, non-invasive

**Summary:** This paper demonstrates the ability to decode repetitive finger movements from non-invasive EEG signals using a linear decoder with memory. The authors achieved median correlation coefficients of 0.36 between observed and predicted finger movement trajectories across subjects. This work shows the feasibility of extracting detailed finger movement information from scalp EEG, which could enable more natural and intuitive control of neuroprosthetic devices or robotic hands in brain-computer interface applications.

---

## Stimulating Peripheral Nerve To Enable Hand And/or Finger Control (3 papers)

### Restoring motor control and sensory feedback in people with upper extremity amputations using arrays of 96 microelectrodes implanted in the median and ulnar nerves

**Authors:** Dustin J. Tyler; David M. Durand; Kevin L. Kilgore

**DOI:** 10.1088/1741-2552/aa9996

**TRL:** 5

**Keywords:** neural interfaces, sensory feedback, motor control, upper limb prosthetics

**Summary:** This study demonstrated the successful implantation of Utah Slanted Electrode Arrays (USEAs) with 96 microelectrodes into the median and ulnar nerves of upper extremity amputees for up to 1 month[2]. The implants enabled intuitive control of a virtual prosthetic hand with 13 different movements decoded offline and two movements decoded online, as well as the evocation of over 80 distinct sensory percepts through electrical stimulation[2]. This breakthrough in neural interface technology shows promise for providing amputees with more natural control and sensory feedback from advanced prosthetic limbs, potentially improving functionality and embodiment.

---

### Closed-loop control of grasp force using peripheral neural signals in a bidirectional prosthesis

**Authors:** Shivaram Arun Kumar; Jacob A. George; Suzanne Wendelken; David M. Page; Gregory A. Clark

**DOI:** 10.1109/TNSRE.2020.3048592

**TRL:** 5

**Keywords:** closed-loop control, prosthetic hand, peripheral nerve stimulation, sensory feedback

**Summary:** This paper presents a closed-loop control system for a prosthetic hand that uses peripheral neural signals to modulate grasp force. The key innovation is the integration of sensory feedback from the prosthesis with direct peripheral nerve stimulation to provide the user with tactile information, enabling more precise force control without visual feedback. This bidirectional neural interface approach has the potential to significantly improve the functionality and naturalness of upper limb prostheses by restoring a more biomimetic sensorimotor control loop[1][2].

---

### Biomimetic encoding model for restoring touch in bionic hands through a nerve interface

**Authors:** Giacomo Valle; Francesco M. Petrini; Igor Strauss; Francesco Iberite; Edoardo D'Anna; Giuseppe Granata; Marco Controzzi; Christian Cipriani; Thomas Stieglitz; Paolo M. Rossini; Silvestro Micera

**DOI:** 10.1088/1741-2552/ab4a5d

**TRL:** 4

**Keywords:** neural encoding, sensory feedback, bionic hands, peripheral nerve stimulation

**Summary:** This paper presents a biomimetic model for encoding tactile sensations in bionic hands through electrical stimulation of residual somatosensory nerves in amputees. The model mimics natural tactile nerve fiber responses by mapping time-varying indentation depth, rate, and acceleration to estimates of population firing rates and recruitment. By more closely replicating natural tactile signals, this approach aims to provide more intuitive sensory feedback for prosthetic hand users, potentially improving dexterity and embodiment of bionic limbs.

---

